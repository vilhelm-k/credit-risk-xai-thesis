{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "header",
   "metadata": {},
   "source": [
    "# ML Model Comparison: LightGBM vs CatBoost\n",
    "\n",
    "Compare LightGBM and CatBoost on credit risk prediction using the same data and comparable hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.metrics import roc_auc_score, log_loss, brier_score_loss\n",
    "from sklearn.model_selection import train_test_split\n",
    "from IPython.core.display import HTML\n",
    "\n",
    "PROJ_ROOT = Path.cwd().parent\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJ_ROOT))\n",
    "\n",
    "from credit_risk_xai.config import FEATURE_CACHE_PATH, ACTIVE_FEATURES\n",
    "from credit_risk_xai.features.engineer import prepare_modeling_data\n",
    "from credit_risk_xai.modeling import compute_ece"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-header",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "load-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(FEATURE_CACHE_PATH)\n",
    "df = df[\n",
    "    (df[\"ser_aktiv\"] == 1) & \n",
    "    (df[\"sme_category\"].isin([\"Small\", \"Medium\"])) & \n",
    "    (df[\"knc_kncfall\"] == 1) &\n",
    "    (df[\"bransch_borsbransch_konv\"] != \"40.0\")\n",
    "]\n",
    "\n",
    "X, y = prepare_modeling_data(df)\n",
    "print(f\"Data: {len(X):,} samples, {X.shape[1]} features\")\n",
    "print(f\"Default rate: {y.mean()*100:.2f}%\")\n",
    "print(f\"Class imbalance: {(y==0).sum()/(y==1).sum():.0f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-data",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Identify categorical features for CatBoost\n",
    "cat_features = [col for col in X.columns if X[col].dtype.name == 'category']\n",
    "cat_indices = [X.columns.get_loc(col) for col in cat_features]\n",
    "\n",
    "print(f\"Train: {len(X_train):,}, Val: {len(X_val):,}\")\n",
    "print(f\"Categorical features: {cat_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "models-header",
   "metadata": {},
   "source": [
    "## 2. Train Models\n",
    "\n",
    "Using comparable settings between LightGBM and CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-lgbm",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM with tuned hyperparameters\n",
    "lgbm_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"n_estimators\": 10_000,\n",
    "    \"metric\": \"logloss\",\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": -1,\n",
    "    \"learning_rate\": 0.0567,\n",
    "    \"num_leaves\": 214,\n",
    "    \"max_depth\": 6,\n",
    "    \"min_child_samples\": 97,\n",
    "    \"min_child_weight\": 0.308,\n",
    "    \"reg_alpha\": 4.764,\n",
    "    \"reg_lambda\": 9.83e-05,\n",
    "    \"min_split_gain\": 0.846,\n",
    "    \"subsample\": 0.826,\n",
    "    \"subsample_freq\": 3,\n",
    "    \"colsample_bytree\": 0.505,\n",
    "}\n",
    "\n",
    "lgbm_model = lgb.LGBMClassifier(**lgbm_params)\n",
    "lgbm_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50, verbose=False),\n",
    "        lgb.log_evaluation(period=50)\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(f\"LightGBM best iteration: {lgbm_model.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "train-catboost",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CatBoost with default settings\n",
    "catboost_params = {\n",
    "    \"iterations\": 10_000,\n",
    "    \"random_seed\": 42,\n",
    "    \"verbose\": 50,\n",
    "    \"early_stopping_rounds\": 50,\n",
    "    \"use_best_model\": True,\n",
    "}\n",
    "\n",
    "catboost_model = CatBoostClassifier(**catboost_params)\n",
    "catboost_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=(X_val, y_val),\n",
    "    cat_features=cat_indices,\n",
    ")\n",
    "\n",
    "print(f\"CatBoost best iteration: {catboost_model.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eval-header",
   "metadata": {},
   "source": [
    "## 3. Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "evaluate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions\n",
    "lgbm_proba = lgbm_model.predict_proba(X_val)[:, 1]\n",
    "catboost_proba = catboost_model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "# Compute metrics\n",
    "results = {\n",
    "    'Model': ['LightGBM', 'CatBoost', '\u0394 (LGBM - CB)'],\n",
    "    'AUC': [\n",
    "        roc_auc_score(y_val, lgbm_proba),\n",
    "        roc_auc_score(y_val, catboost_proba),\n",
    "        0\n",
    "    ],\n",
    "    'Log Loss': [\n",
    "        log_loss(y_val, lgbm_proba),\n",
    "        log_loss(y_val, catboost_proba),\n",
    "        0\n",
    "    ],\n",
    "    'Brier Score': [\n",
    "        brier_score_loss(y_val, lgbm_proba),\n",
    "        brier_score_loss(y_val, catboost_proba),\n",
    "        0\n",
    "    ],\n",
    "    'ECE': [\n",
    "        compute_ece(y_val, lgbm_proba),\n",
    "        compute_ece(y_val, catboost_proba),\n",
    "        0\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Compute deltas\n",
    "for col in ['AUC', 'Log Loss', 'Brier Score', 'ECE']:\n",
    "    results[col][2] = results[col][0] - results[col][1]\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "HTML(results_df.to_html(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "visualize",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Calibration curves\n",
    "ax = axes[0]\n",
    "for name, proba, color in [('LightGBM', lgbm_proba, 'steelblue'), ('CatBoost', catboost_proba, 'darkorange')]:\n",
    "    fraction_pos, mean_pred = calibration_curve(y_val, proba, n_bins=50, strategy='quantile')\n",
    "    ece = compute_ece(y_val, proba)\n",
    "    ax.plot(mean_pred, fraction_pos, 's-', label=f'{name} (ECE={ece:.4f})', color=color, linewidth=2)\n",
    "\n",
    "ax.plot([0, 1], [0, 1], 'k--', alpha=0.5, label='Perfect calibration')\n",
    "ax.set_xlabel('Mean predicted probability')\n",
    "ax.set_ylabel('Fraction of positives')\n",
    "ax.set_title('Calibration Curves')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "# Prediction distribution\n",
    "ax = axes[1]\n",
    "ax.hist(lgbm_proba, bins=50, alpha=0.5, label='LightGBM', color='steelblue', density=True)\n",
    "ax.hist(catboost_proba, bins=50, alpha=0.5, label='CatBoost', color='darkorange', density=True)\n",
    "ax.set_xlabel('Predicted probability')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Prediction Distributions')\n",
    "ax.legend()\n",
    "ax.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feature-importance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare feature importances\n",
    "lgbm_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'lgbm': lgbm_model.feature_importances_\n",
    "})\n",
    "\n",
    "catboost_importance = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'catboost': catboost_model.feature_importances_\n",
    "})\n",
    "\n",
    "importance_comparison = lgbm_importance.merge(catboost_importance, on='feature')\n",
    "importance_comparison['lgbm_rank'] = importance_comparison['lgbm'].rank(ascending=False)\n",
    "importance_comparison['catboost_rank'] = importance_comparison['catboost'].rank(ascending=False)\n",
    "importance_comparison['rank_diff'] = importance_comparison['lgbm_rank'] - importance_comparison['catboost_rank']\n",
    "\n",
    "HTML(importance_comparison.to_html(index=False))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}