{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Quality Audit\n",
    "\n",
    "Comprehensive analysis of feature engineering pipeline data quality:\n",
    "- Data types and memory efficiency\n",
    "- Extreme outliers and impossible values\n",
    "- Near-zero division issues\n",
    "- Categorical feature handling\n",
    "- Missing value patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nfrom pathlib import Path\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nPROJ_ROOT = Path.cwd().parent\nif str(PROJ_ROOT) not in sys.path:\n    sys.path.append(str(PROJ_ROOT))\n\nfrom credit_risk_xai.config import FEATURE_CACHE_PATH, FEATURES_FOR_MODEL, CATEGORICAL_COLS\nfrom credit_risk_xai.features.engineer import prepare_modeling_data\nfrom credit_risk_xai.plotting import set_thesis_style, FIGSIZE, COLORS, save_figure, despine\n\n# Initialize thesis-quality plotting style\nset_thesis_style(use_tex=True)\n\nFIGURES_DIR = PROJ_ROOT / \"figures\"\n\n%matplotlib inline"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data and Basic Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total records: 12,473,668\n",
      "After filters: 341,134\n",
      "\n",
      "Memory usage:\n",
      "  Full dataset: 4.32 GB\n",
      "  Filtered: 124.52 MB\n",
      "\n",
      "Modeling data: 316,663 rows × 40 features\n",
      "Target distribution: {np.int8(0): 310079, np.int8(1): 6584}\n"
     ]
    }
   ],
   "source": [
    "# Load feature-engineered dataset\n",
    "df = pd.read_parquet(FEATURE_CACHE_PATH)\n",
    "\n",
    "# Apply standard filters\n",
    "df_filtered = df[\n",
    "    (df['ser_aktiv'] == 1) & \n",
    "    (df['sme_category'].isin(['Small', 'Medium'])) & \n",
    "    (df['knc_kncfall'] == 1) &\n",
    "    (df[\"bransch_borsbransch_konv\"] != \"40.0\")\n",
    "]\n",
    "\n",
    "print(f\"Total records: {len(df):,}\")\n",
    "print(f\"After filters: {len(df_filtered):,}\")\n",
    "print(f\"\\nMemory usage:\")\n",
    "print(f\"  Full dataset: {df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "print(f\"  Filtered: {df_filtered.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "# Get modeling features\n",
    "X, y = prepare_modeling_data(df_filtered)\n",
    "print(f\"\\nModeling data: {len(X):,} rows × {len(X.columns)} features\")\n",
    "print(f\"Target distribution: {y.value_counts().to_dict()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duplicates = df_filtered[\n",
    "    (df_filtered['target'] == 1) &\n",
    "    (df_filtered['ny_omsf'] == 0.0)\n",
    "    ]\n",
    "df_duplicates.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Type Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "DATA TYPE ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "Data type distribution:\n",
      "float32     37\n",
      "Int16        1\n",
      "category     1\n",
      "uint8        1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "CATEGORICAL FEATURES ANALYSIS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "         feature current_dtype is_category  unique_values null_pct\n",
      "sni_group_3digit      category           ✓            267     0.0%\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "DTYPE EFFICIENCY ISSUES\n",
      "----------------------------------------------------------------------------------------------------\n",
      "  company_age: Using Int16, but range [0, 155] fits in uint8\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"DATA TYPE ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Analyze dtypes\n",
    "dtype_summary = X.dtypes.value_counts()\n",
    "print(\"\\nData type distribution:\")\n",
    "print(dtype_summary)\n",
    "\n",
    "# Check categorical dtypes\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"CATEGORICAL FEATURES ANALYSIS\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "categorical_status = []\n",
    "for col in CATEGORICAL_COLS:\n",
    "    if col in X.columns:\n",
    "        is_category = X[col].dtype.name == 'category'\n",
    "        n_unique = X[col].nunique()\n",
    "        categorical_status.append({\n",
    "            'feature': col,\n",
    "            'current_dtype': str(X[col].dtype),\n",
    "            'is_category': '✓' if is_category else '✗',\n",
    "            'unique_values': n_unique,\n",
    "            'null_pct': f\"{100 * X[col].isna().sum() / len(X):.1f}%\"\n",
    "        })\n",
    "\n",
    "cat_df = pd.DataFrame(categorical_status)\n",
    "print(cat_df.to_string(index=False))\n",
    "\n",
    "# Dtype efficiency check\n",
    "print(\"\\n\" + \"-\" * 100)\n",
    "print(\"DTYPE EFFICIENCY ISSUES\")\n",
    "print(\"-\" * 100)\n",
    "\n",
    "for col in X.columns:\n",
    "    dtype = X[col].dtype\n",
    "    \n",
    "    # Check if using oversized int\n",
    "    if dtype == 'Int16' or dtype == 'int16':\n",
    "        min_val, max_val = X[col].min(), X[col].max()\n",
    "        if min_val >= 0 and max_val <= 255:\n",
    "            print(f\"  {col}: Using {dtype}, but range [{min_val}, {max_val}] fits in uint8\")\n",
    "    \n",
    "    # Check if using float64 unnecessarily\n",
    "    if dtype == 'float64':\n",
    "        print(f\"  {col}: Using float64 (could use float32 if precision not critical)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Distribution Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "DESCRIPTIVE STATISTICS (All Features)\n",
      "====================================================================================================\n",
      "                                   count         mean            std           min            1%         5%        25%        50%        75%           95%           99%           max   null_pct  outliers_5std\n",
      "company_age                     316663.0    16.158822      14.170954           0.0           0.0        1.0        6.0       12.0       22.0          44.0          64.0         155.0   0.000000            739\n",
      "ny_kapomsh                      316580.0     3.007218       44.97625           0.0      0.105611   0.634699   1.526489   2.404384   3.581129      6.564929     10.170048       17743.0   0.026211             11\n",
      "ny_rs                           316495.0     0.056635       7.662149     -0.000006           0.0        0.0   0.002528   0.012045    0.02744      0.058005      0.147204   3150.600098   0.053053             22\n",
      "ny_skuldgrd                     303334.0     9.132657     323.417267 -12658.608398      0.108042   0.340034   0.990363   2.038015    4.57099     19.660551     71.599533  111224.84375   4.209207            109\n",
      "ny_solid                        303334.0     0.353753       0.216567     -0.059608      0.013755   0.048393   0.179482   0.329105   0.502359      0.745976      0.901721      6.270142   4.209207              8\n",
      "ny_avkegkap                     303331.0    -0.024591      10.786812  -2141.280029     -6.134139  -0.856913   0.063521    0.25889   0.522646      1.027137      1.423858     868.44928   4.210154            360\n",
      "ny_kasslikv                     316477.0     2.850031     241.732544    -16.441668      0.136821   0.331058   0.773438   1.153005   1.670284        3.4149      8.325063       99820.0   0.058738             35\n",
      "ny_nettomarg                    316173.0    -1.089594     138.531738      -57531.0     -0.568978  -0.077037    0.00355   0.031467   0.077698      0.200613      0.386467        2882.0   0.154739             55\n",
      "ny_omspanst                     312251.0   2581.76416   20954.632812           0.0          74.0      327.0      687.0     1073.0     1811.0        5340.0       26992.0     5343808.0   1.393279            600\n",
      "ny_foradlvpanst                 312258.0   645.281555    3991.074707      -72878.0           4.0      167.0      356.0      477.0      646.0        1188.0   3202.429932     1602064.0   1.391069            369\n",
      "ny_omsf                         295547.0     4.776306     917.031128          -1.0     -0.449484  -0.201431  -0.011834    0.07368   0.230197       1.21073      6.883006      458444.0   6.668288             32\n",
      "ny_anstf                        291135.0     0.173737       1.103585          -1.0     -0.368421  -0.166667        0.0        0.0   0.142857      0.666667           2.4         175.0   8.061567           1149\n",
      "log_br10_eksu                   303405.0     7.532709       1.549358          -0.0      4.110874   4.976734    6.52503   7.510978   8.492491     10.109802     11.494331     18.597965   4.186785             67\n",
      "log_br07b_kabasu                316160.0     6.307346       2.408327           0.0           0.0   0.693147   5.241747   6.836259   7.916078      9.364605     10.522579     16.668621   0.158844              0\n",
      "log_bslov_antanst               316663.0     2.805792       0.637956           0.0           0.0   2.397895   2.484907    2.70805   3.091043       3.89182       4.59512      5.298317   0.000000              0\n",
      "log_rr15_resar                  265316.0     5.947984       1.952663          -0.0           0.0    1.94591   4.990433   6.200509   7.235619      8.637107      9.806315     15.628114  16.215030              0\n",
      "ratio_depreciation_cost         316173.0     0.103252      16.876459     -0.352612          -0.0       -0.0   0.004136   0.012223   0.034277      0.121352      0.233637        8961.0   0.154739             29\n",
      "ratio_cash_interest_cov         294095.0  -379.170471    3568.752441  -837572.9375  -6012.294922    -1508.0    -103.75 -13.508982  -1.283726     -0.003012           0.0       93259.0   7.126819            588\n",
      "ratio_cash_liquidity            316372.0     1.287074      54.694996        -117.0           0.0   0.000349   0.072283   0.363376   0.856462      2.405716      6.661152       16047.5   0.091896             82\n",
      "ratio_short_term_debt_share     316408.0     0.933269        0.19533     -9.186916      0.223021   0.554857   0.975769        1.0        1.0           1.0           1.0     55.447674   0.080527             34\n",
      "ratio_retained_earnings_equity  316560.0     0.547482      17.860685  -3174.557617     -2.064815   -0.02815   0.238601   0.584191   0.801392      1.130892      3.425992   8334.269531   0.032527            159\n",
      "dividend_yield                  316559.0     0.114954        0.71639         -21.0           0.0        0.0        0.0        0.0   0.131079      0.625922      0.920392         384.0   0.032842             12\n",
      "dso_days                        316137.0   175.806335   16873.929688     -268.5849      1.924323   5.232345  29.883482  51.310757  73.284264    142.607224    494.432098     6664535.0   0.166107             39\n",
      "dpo_days                        298570.0    63.575565    3119.736084   -212.269485           0.0   3.581316  20.755541  34.332024  51.245693    108.061577    335.639069     1547600.0   5.713645             37\n",
      "rr01_ntoms_yoy_abs              297373.0  3429.483398   45015.214844   -11453845.0 -22702.400391    -5385.0     -172.0     1212.0     4055.0  18415.599609  60751.761719     5700568.0   6.091649            513\n",
      "rr07_rorresul_yoy_pct           296640.0    -0.757392     321.355621     -151220.0    -22.775562  -3.697854  -0.633656  -0.027778   0.615323         4.875     23.563744       48605.5   6.323126             88\n",
      "ny_solid_yoy_diff               282219.0     0.007767       0.121402    -33.676025     -0.305701  -0.134492   -0.02615   0.009176   0.048956      0.143165      0.273652      5.657239  10.877179            973\n",
      "ratio_cash_liquidity_yoy_pct    285293.0     6.073195     208.269058  -2874.525146          -1.0  -0.917213  -0.339519        0.0   0.463304      4.711377     65.299324  54937.570312   9.906430            231\n",
      "ratio_cash_liquidity_yoy_abs    296656.0     0.027403      58.338936 -15988.076172     -2.212575  -0.587839  -0.099845        0.0   0.138244      0.661548      2.240918  15846.033203   6.318073             93\n",
      "dso_days_yoy_diff               295405.0  -304.263245  119674.210938   -63519440.0    -313.46048 -50.080143  -8.978512  -0.341158   6.657623     32.913368     98.046219     6662011.0   6.713130             19\n",
      "inventory_days_yoy_diff         279904.0   -50.787868    7366.563965  -1971269.375   -139.102509  -27.14345  -1.255213        0.0   0.924105     23.289314     85.076317    918047.875  11.608240             83\n",
      "dpo_days_yoy_diff               279922.0   -22.755764    2486.131592     -603162.5   -240.558945  -49.79361 -10.060544  -0.451276   7.234199     34.237728     91.339035      468660.0  11.602555             79\n",
      "current_ratio_yoy_pct           296612.0     0.958911     332.957062    -43.239998      -0.68444   -0.36232    -0.0975   0.011485   0.143688      0.560605      1.800489   178418.9375   6.331968              6\n",
      "revenue_cagr_3y                 249849.0     0.218708       0.819153      -0.93771     -0.218541  -0.091917   0.012863   0.076311   0.193189      0.854315      2.698445     77.030075  21.099402           1231\n",
      "profit_cagr_3y                  185668.0     0.382783       1.116088     -0.952314     -0.791742  -0.528429  -0.103302   0.142841   0.496725      2.023884      5.215889     53.021603  41.367321           1353\n",
      "revenue_drawdown_5y             231554.0    -0.116652       0.172272          -1.0     -0.839707  -0.468635  -0.166276  -0.045563        0.0           0.0           0.0           0.0  26.876838           1268\n",
      "dpo_days_trend_3y               259553.0   -34.400414    6617.320312   -2863017.75   -180.962173 -32.533424  -6.421152  -0.309584   4.757596     20.123577     51.069382      234330.0  18.034946             29\n",
      "event_count_last_5y             316663.0     0.013901       0.215228           0.0           0.0        0.0        0.0        0.0        0.0           0.0           0.0           5.0   0.000000            839\n",
      "term_spread                     236598.0     0.422641       0.572849     -0.657058     -0.657058  -0.657058   0.219558    0.41075   0.693833      1.616875      1.616875      1.616875  25.283977              0\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"DESCRIPTIVE STATISTICS (All Features)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Get numeric columns only\n",
    "numeric_cols = X.select_dtypes(include=[np.number]).columns\n",
    "desc = X[numeric_cols].describe(percentiles=[0.01, 0.05, 0.25, 0.5, 0.75, 0.95, 0.99]).T\n",
    "\n",
    "# Add null percentage\n",
    "desc['null_pct'] = 100 * X[numeric_cols].isna().sum() / len(X)\n",
    "\n",
    "# Add outlier count (beyond 5 std devs)\n",
    "outlier_counts = []\n",
    "for col in numeric_cols:\n",
    "    values = X[col].dropna()\n",
    "    if len(values) > 0:\n",
    "        mean, std = values.mean(), values.std()\n",
    "        if std > 0:\n",
    "            outliers = (np.abs(values - mean) > 5 * std).sum()\n",
    "        else:\n",
    "            outliers = 0\n",
    "    else:\n",
    "        outliers = 0\n",
    "    outlier_counts.append(outliers)\n",
    "\n",
    "desc['outliers_5std'] = outlier_counts\n",
    "\n",
    "print(desc.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Near-Zero Division Issues\n",
    "\n",
    "Identify features with extreme values likely caused by division by near-zero denominators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "NEAR-ZERO DIVISION ANALYSIS\n",
      "====================================================================================================\n",
      "\n",
      "dso_days:\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 316,137 | Null: 526 (0.2%)\n",
      "  Min: -268.58 | Max: 6664535.00\n",
      "  Mean: 175.81 | Median: 51.31\n",
      "  P1: 1.92 | P99: 494.43\n",
      "  In reasonable range [0, 365]: 98.6%\n",
      "  Outside reasonable range: 4,415 obs (1.4%)\n",
      "  ⚠ EXTREME HIGH (>1365): 1,111 obs\n",
      "    Worst 5: [6.664535e+06 4.720545e+06 3.343765e+06 1.843250e+06 1.572420e+06]\n",
      "\n",
      "dpo_days:\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 298,570 | Null: 18,093 (5.7%)\n",
      "  Min: -212.27 | Max: 1547600.00\n",
      "  Mean: 63.58 | Median: 34.33\n",
      "  P1: 0.00 | P99: 335.64\n",
      "  In reasonable range [0, 365]: 99.1%\n",
      "  Outside reasonable range: 2,795 obs (0.9%)\n",
      "  ⚠ EXTREME HIGH (>1365): 412 obs\n",
      "    Worst 5: [1.5476000e+06 4.6866000e+05 3.8589625e+05 1.7556500e+05 1.5056250e+05]\n",
      "\n",
      "ratio_cash_liquidity:\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 316,372 | Null: 291 (0.1%)\n",
      "  Min: -117.00 | Max: 16047.50\n",
      "  Mean: 1.29 | Median: 0.36\n",
      "  P1: 0.00 | P99: 6.66\n",
      "  In reasonable range [0, 10]: 99.3%\n",
      "  Outside reasonable range: 2,278 obs (0.7%)\n",
      "  ⚠ EXTREME HIGH (>1010): 27 obs\n",
      "    Worst 5: [16047.5    14520.286   9341.143   9202.      8170.6514]\n",
      "\n",
      "ratio_cash_interest_cov:\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 294,095 | Null: 22,568 (7.1%)\n",
      "  Min: -837572.94 | Max: 93259.00\n",
      "  Mean: -379.17 | Median: -13.51\n",
      "  P1: -6012.30 | P99: 0.00\n",
      "  In reasonable range [-100, 100]: 74.6%\n",
      "  Outside reasonable range: 74,684 obs (25.4%)\n",
      "  ⚠ EXTREME LOW (<-1100): 19,202 obs\n",
      "    Worst 5: [-837572.94 -693354.   -537767.56 -454364.3  -425566.  ]\n",
      "  ⚠ EXTREME HIGH (>1100): 1 obs\n",
      "    Worst 5: [93259.]\n",
      "\n",
      "rr07_rorresul_yoy_pct:\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 296,640 | Null: 20,023 (6.3%)\n",
      "  Min: -151220.00 | Max: 48605.50\n",
      "  Mean: -0.76 | Median: -0.03\n",
      "  P1: -22.78 | P99: 23.56\n",
      "  In reasonable range [-100, 100]: 99.5%\n",
      "  Outside reasonable range: 1,538 obs (0.5%)\n",
      "  ⚠ EXTREME LOW (<-1100): 76 obs\n",
      "    Worst 5: [-151220.   -34190.   -21282.   -16579.5  -13587. ]\n",
      "  ⚠ EXTREME HIGH (>1100): 52 obs\n",
      "    Worst 5: [48605.5   32181.    19079.334 13097.     6741.7  ]\n",
      "\n",
      "ratio_cash_liquidity_yoy_pct:\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 285,293 | Null: 31,370 (9.9%)\n",
      "  Min: -2874.53 | Max: 54937.57\n",
      "  Mean: 6.07 | Median: 0.00\n",
      "  P1: -1.00 | P99: 65.30\n",
      "  In reasonable range [-100, 100]: 99.2%\n",
      "  Outside reasonable range: 2,141 obs (0.8%)\n",
      "  ⚠ EXTREME LOW (<-1100): 1 obs\n",
      "    Worst 5: [-2874.5251]\n",
      "  ⚠ EXTREME HIGH (>1100): 222 obs\n",
      "    Worst 5: [54937.57  38512.99  36126.02  32901.883 19530.104]\n",
      "\n",
      "current_ratio_yoy_pct:\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 296,612 | Null: 20,051 (6.3%)\n",
      "  Min: -43.24 | Max: 178418.94\n",
      "  Mean: 0.96 | Median: 0.01\n",
      "  P1: -0.68 | P99: 1.80\n",
      "  In reasonable range [-100, 100]: 100.0%\n",
      "  Outside reasonable range: 86 obs (0.0%)\n",
      "  ⚠ EXTREME HIGH (>1100): 9 obs\n",
      "    Worst 5: [178418.94    30536.117    8126.942    4706.8325   2658.1619]\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"NEAR-ZERO DIVISION ANALYSIS\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Features known to have division operations\n",
    "division_features = {\n",
    "    'dso_days': {'numerator': 'br06g_kfordsu', 'denominator': 'rr01_ntoms', 'reasonable_range': (0, 365)},\n",
    "    'dpo_days': {'numerator': 'br13a_ksklev', 'denominator': 'rr06a_prodkos', 'reasonable_range': (0, 365)},\n",
    "    'ratio_cash_liquidity': {'numerator': 'br08_omstgsu', 'denominator': 'br13_ksksu', 'reasonable_range': (0, 10)},\n",
    "    'ratio_cash_interest_cov': {'numerator': None, 'denominator': None, 'reasonable_range': (-100, 100)},\n",
    "    'rr07_rorresul_yoy_pct': {'numerator': None, 'denominator': 'prev_year_value', 'reasonable_range': (-100, 100)},\n",
    "    'ratio_cash_liquidity_yoy_pct': {'numerator': None, 'denominator': 'prev_year_value', 'reasonable_range': (-100, 100)},\n",
    "    'current_ratio_yoy_pct': {'numerator': None, 'denominator': 'prev_year_value', 'reasonable_range': (-100, 100)},\n",
    "}\n",
    "\n",
    "for feature, info in division_features.items():\n",
    "    if feature not in X.columns:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    values = X[feature].dropna()\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"  Count: {len(values):,} | Null: {X[feature].isna().sum():,} ({100*X[feature].isna().sum()/len(X):.1f}%)\")\n",
    "    print(f\"  Min: {values.min():.2f} | Max: {values.max():.2f}\")\n",
    "    print(f\"  Mean: {values.mean():.2f} | Median: {values.median():.2f}\")\n",
    "    print(f\"  P1: {values.quantile(0.01):.2f} | P99: {values.quantile(0.99):.2f}\")\n",
    "    \n",
    "    # Check reasonable range\n",
    "    reasonable_min, reasonable_max = info['reasonable_range']\n",
    "    in_range = (values >= reasonable_min) & (values <= reasonable_max)\n",
    "    pct_in_range = 100 * in_range.sum() / len(values)\n",
    "    \n",
    "    print(f\"  In reasonable range [{reasonable_min}, {reasonable_max}]: {pct_in_range:.1f}%\")\n",
    "    print(f\"  Outside reasonable range: {(~in_range).sum():,} obs ({100*(~in_range).sum()/len(values):.1f}%)\")\n",
    "    \n",
    "    # Extreme values\n",
    "    extreme_low = values < (reasonable_min - 1000)\n",
    "    extreme_high = values > (reasonable_max + 1000)\n",
    "    \n",
    "    if extreme_low.sum() > 0:\n",
    "        print(f\"  ⚠ EXTREME LOW (<{reasonable_min - 1000}): {extreme_low.sum():,} obs\")\n",
    "        print(f\"    Worst 5: {values[extreme_low].nsmallest(5).values}\")\n",
    "    \n",
    "    if extreme_high.sum() > 0:\n",
    "        print(f\"  ⚠ EXTREME HIGH (>{reasonable_max + 1000}): {extreme_high.sum():,} obs\")\n",
    "        print(f\"    Worst 5: {values[extreme_high].nlargest(5).values}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Denominator Analysis\n",
    "\n",
    "Check the distributions of denominators to understand near-zero division issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "DENOMINATOR ANALYSIS (for division-based features)\n",
      "====================================================================================================\n",
      "\n",
      "rr01_ntoms: Revenue (used in DSO calculation)\n",
      "--------------------------------------------------------------------------------\n",
      "  Count: 341,126\n",
      "  Min: 0.00 | Max: 11403721.00\n",
      "  Mean: 36412.36 | Median: 18232.00\n",
      "\n",
      "  Zero: 564 (0.17%)\n",
      "  |value| < 1: 564 (0.17%)\n",
      "  |value| < 10: 625 (0.18%)\n",
      "  Negative: 0 (0.00%)\n",
      "\n",
      "  ⚠ WOULD EXCLUDE with threshold=10.0: 625 (0.2%)\n"
     ]
    }
   ],
   "source": [
    "print(\"=\" * 100)\n",
    "print(\"DENOMINATOR ANALYSIS (for division-based features)\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "# Check key denominators\n",
    "denominators = {\n",
    "    'rr01_ntoms': 'Revenue (used in DSO calculation)',\n",
    "    'rr06a_prodkos': 'Production costs (used in DPO calculation)',\n",
    "    'br13_ksksu': 'Current liabilities (used in cash liquidity ratio)',\n",
    "}\n",
    "\n",
    "for denom_col, description in denominators.items():\n",
    "    if denom_col not in df_filtered.columns:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{denom_col}: {description}\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    values = df_filtered[denom_col].dropna()\n",
    "    \n",
    "    # Basic stats\n",
    "    print(f\"  Count: {len(values):,}\")\n",
    "    print(f\"  Min: {values.min():.2f} | Max: {values.max():.2f}\")\n",
    "    print(f\"  Mean: {values.mean():.2f} | Median: {values.median():.2f}\")\n",
    "    \n",
    "    # Check for near-zero and negative\n",
    "    zero_count = (values == 0).sum()\n",
    "    near_zero_1 = (values.abs() < 1).sum()\n",
    "    near_zero_10 = (values.abs() < 10).sum()\n",
    "    negative = (values < 0).sum()\n",
    "    \n",
    "    print(f\"\\n  Zero: {zero_count:,} ({100*zero_count/len(values):.2f}%)\")\n",
    "    print(f\"  |value| < 1: {near_zero_1:,} ({100*near_zero_1/len(values):.2f}%)\")\n",
    "    print(f\"  |value| < 10: {near_zero_10:,} ({100*near_zero_10/len(values):.2f}%)\")\n",
    "    print(f\"  Negative: {negative:,} ({100*negative/len(values):.2f}%)\")\n",
    "    \n",
    "    # Recommended threshold\n",
    "    if 'ntoms' in denom_col:  # Revenue\n",
    "        threshold = 10.0\n",
    "    else:\n",
    "        threshold = 1.0\n",
    "    \n",
    "    below_threshold = (values.abs() < threshold).sum()\n",
    "    print(f\"\\n  ⚠ WOULD EXCLUDE with threshold={threshold}: {below_threshold:,} ({100*below_threshold/len(values):.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualization: Extreme Value Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Plot distributions of problematic features\nproblematic_features = [\n    'dso_days', 'dpo_days', 'ratio_cash_liquidity', \n    'rr07_rorresul_yoy_pct', 'ratio_cash_liquidity_yoy_pct'\n]\n\nfig, axes = plt.subplots(2, 3, figsize=(FIGSIZE['standalone'][0], 3.5))\naxes = axes.flatten()\n\nfor idx, feature in enumerate(problematic_features):\n    if feature not in X.columns or idx >= len(axes):\n        continue\n    \n    ax = axes[idx]\n    values = X[feature].dropna()\n    \n    # Use percentile range for visualization\n    p1, p99 = values.quantile([0.01, 0.99])\n    filtered_values = values[(values >= p1) & (values <= p99)]\n    \n    # Histogram\n    ax.hist(filtered_values, bins=50, alpha=0.7, edgecolor='white', linewidth=0.3,\n            color=COLORS['lgbm'])\n    ax.set_title(feature.replace('_', r'\\_'), fontsize=8)\n    ax.set_xlabel('Value', fontsize=7)\n    ax.set_ylabel('Frequency', fontsize=7)\n    ax.tick_params(labelsize=6)\n    \n    # Add stats text\n    stats_text = f\"P1--P99: [{p1:.1f}, {p99:.1f}]\\nOutside: {(~values.between(p1, p99)).sum():,}\"\n    ax.text(0.98, 0.98, stats_text, transform=ax.transAxes,\n            verticalalignment='top', horizontalalignment='right',\n            bbox=dict(boxstyle='round', facecolor='white', alpha=0.8, edgecolor='#cccccc'),\n            fontsize=5)\n    \n    despine(ax)\n\n# Hide extra subplot\nif len(problematic_features) < len(axes):\n    axes[-1].axis('off')\n\nplt.tight_layout()\nsave_figure(fig, FIGURES_DIR / 'feature_distributions_audit.pdf')\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary and Recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "SUMMARY: REQUIRED FIXES\n",
      "====================================================================================================\n",
      "\n",
      "1. CATEGORICAL DTYPES\n",
      "--------------------------------------------------------------------------------\n",
      "  ✓ All categorical features properly encoded\n",
      "\n",
      "2. NEAR-ZERO DIVISION ISSUES\n",
      "--------------------------------------------------------------------------------\n",
      "  Recommend implementing threshold-based NaN conversion in _safe_div():\n",
      "    - min_abs_denom=1.0 for most ratios (1k SEK)\n",
      "    - min_abs_denom=10.0 for revenue-based metrics (10k SEK)\n",
      "\n",
      "  Expected impact:\n",
      "    - DSO: ~0.2% → NaN (revenue < 10k)\n",
      "\n",
      "3. DATA TYPE OPTIMIZATION\n",
      "--------------------------------------------------------------------------------\n",
      "  • event_count_last_5y: uint8 → uint8 (range 0-5)\n",
      "\n",
      "====================================================================================================\n",
      "\n",
      "✓ Data quality audit complete. Proceed with fixes in engineer.py\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*100)\n",
    "print(\"SUMMARY: REQUIRED FIXES\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "print(\"\\n1. CATEGORICAL DTYPES\")\n",
    "print(\"-\" * 80)\n",
    "cat_not_encoded = [col for col in CATEGORICAL_COLS if col in X.columns and X[col].dtype.name != 'category']\n",
    "if cat_not_encoded:\n",
    "    print(f\"  ✗ {len(cat_not_encoded)} categorical features not using category dtype:\")\n",
    "    for col in cat_not_encoded:\n",
    "        print(f\"    - {col}: {X[col].dtype}\")\n",
    "else:\n",
    "    print(\"  ✓ All categorical features properly encoded\")\n",
    "\n",
    "print(\"\\n2. NEAR-ZERO DIVISION ISSUES\")\n",
    "print(\"-\" * 80)\n",
    "print(\"  Recommend implementing threshold-based NaN conversion in _safe_div():\")\n",
    "print(\"    - min_abs_denom=1.0 for most ratios (1k SEK)\")\n",
    "print(\"    - min_abs_denom=10.0 for revenue-based metrics (10k SEK)\")\n",
    "print(\"\\n  Expected impact:\")\n",
    "\n",
    "# Estimate impact for key denominators\n",
    "if 'rr01_ntoms' in df_filtered.columns:\n",
    "    revenue_below_10 = (df_filtered['rr01_ntoms'].abs() < 10).sum()\n",
    "    print(f\"    - DSO: ~{100*revenue_below_10/len(df_filtered):.1f}% → NaN (revenue < 10k)\")\n",
    "\n",
    "if 'rr06a_prodkos' in df_filtered.columns:\n",
    "    prodcost_below_1 = (df_filtered['rr06a_prodkos'].abs() < 1).sum()\n",
    "    print(f\"    - DPO: ~{100*prodcost_below_1/len(df_filtered):.1f}% → NaN (prod costs < 1k)\")\n",
    "\n",
    "if 'br13_ksksu' in df_filtered.columns:\n",
    "    liab_below_1 = (df_filtered['br13_ksksu'].abs() < 1).sum()\n",
    "    print(f\"    - Cash liquidity ratio: ~{100*liab_below_1/len(df_filtered):.1f}% → NaN (liabilities < 1k)\")\n",
    "\n",
    "print(\"\\n3. DATA TYPE OPTIMIZATION\")\n",
    "print(\"-\" * 80)\n",
    "if 'event_count_last_5y' in X.columns:\n",
    "    print(f\"  • event_count_last_5y: {X['event_count_last_5y'].dtype} → uint8 (range 0-5)\")\n",
    "float64_cols = [col for col in X.columns if X[col].dtype == 'float64']\n",
    "if float64_cols:\n",
    "    print(f\"  • {len(float64_cols)} features using float64 could use float32\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*100)\n",
    "print(\"\\n✓ Data quality audit complete. Proceed with fixes in engineer.py\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}