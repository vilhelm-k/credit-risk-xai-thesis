{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "\n",
    "PROJ_ROOT = Path.cwd().parent\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJ_ROOT))\n",
    "\n",
    "from credit_risk_xai.modeling.train import DEFAULT_PARAMS\n",
    "\n",
    "from credit_risk_xai.config import FEATURE_CACHE_PATH, FEATURES_FOR_MODEL\n",
    "from credit_risk_xai.features.engineer import prepare_modeling_data\n",
    "\n",
    "from sklearn.calibration import calibration_curve\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_calibration_curve(y_true, y_pred_proba, n_bins=10, model_name=\"Model\"):\n",
    "    fraction_of_positives, mean_predicted_value = calibration_curve(\n",
    "        y_true, y_pred_proba, n_bins=n_bins, strategy='uniform'\n",
    "    )\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=model_name)\n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\")\n",
    "\n",
    "\n",
    "    plt.xlabel(\"Mean predicted probability\")\n",
    "    plt.ylabel(\"Fraction of positives\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Calibration Curve - {model_name}\")\n",
    "    plt.show()\n",
    "    \n",
    "    # ECE (Expected Calibration Error)\n",
    "    ece = np.mean(np.abs(fraction_of_positives - mean_predicted_value))\n",
    "    print(f\"ECE: {ece:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09cbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter data\n",
    "MIN_REVENUE_KSEK = 1_000\n",
    "df = pd.read_parquet(FEATURE_CACHE_PATH)\n",
    "df = df[\n",
    "    (df[\"ser_aktiv\"] == 1) \n",
    "    & (df[\"sme_category\"].isin([\"Small\", \"Medium\"])) \n",
    "    & (df[\"knc_kncfall\"] == 1)\n",
    "    & (df[\"bransch_borsbransch_konv\"] != \"40.0\")\n",
    "]\n",
    "X, y = prepare_modeling_data(df)\n",
    "\n",
    "print(f\"Features: {X.shape[1]} | Samples: {len(X):,}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Imbalance: {(y==0).sum()/(y==1).sum():.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f5ce0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from credit_risk_xai.features.engineer import prepare_modeling_data\n",
    "from credit_risk_xai.modeling.train import run_lightgbm_training\n",
    "\n",
    "X, y = prepare_modeling_data(df)\n",
    "\n",
    "results = run_lightgbm_training(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    dataset_description=\"ser_aktiv==1 & SME\u2208{Small,Medium} & knc_kncfall==1\",  # optional note for W&B\n",
    "    use_wandb=False,\n",
    "    wandb_project=\"credit-risk-xai\",\n",
    "    wandb_run_name=\"lgbm_finalish_prune\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htjbzby6qel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "model = results[\"model\"]\n",
    "X_train = results[\"X_train\"]\n",
    "X_val = results[\"X_val\"]\n",
    "y_train = results[\"y_train\"]\n",
    "y_val = results[\"y_val\"]\n",
    "y_pred_proba = results[\"y_val_proba\"]\n",
    "y_pred = (y_pred_proba >= 0.5).astype(int)\n",
    "\n",
    "auc = roc_auc_score(y_val, y_pred_proba)\n",
    "pr_auc = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))\n",
    "\n",
    "plot_calibration_curve(y_val, y_pred_proba, model_name=\"Predicted Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yijb3okzet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance analysis\n",
    "from credit_risk_xai.modeling import get_feature_importance, plot_feature_importance, analyze_feature_groups\n",
    "from credit_risk_xai.config import (\n",
    "    RATIO_FEATURE_NAMES, \n",
    "    LIQUIDITY_EFFICIENCY_FEATURES, \n",
    "    TREND_FEATURE_NAMES, \n",
    "    CRISIS_FEATURE_NAMES, \n",
    "    MACRO_FEATURE_NAMES\n",
    ")\n",
    "\n",
    "# 1. Get LightGBM feature importance (using gain)\n",
    "importance_df = get_feature_importance(model, X_train, importance_type='gain', top_n=None)\n",
    "print(\"Top Features (by Gain):\")\n",
    "print(importance_df.to_string(index=False))\n",
    "\n",
    "# 2. Visualize feature importance\n",
    "plot_feature_importance(importance_df, top_n=20, show=True)\n",
    "\n",
    "# 3. Analyze by feature groups\n",
    "feature_groups = {\n",
    "    \"RATIO\": RATIO_FEATURE_NAMES,\n",
    "    \"LIQUIDITY_EFFICIENCY\": LIQUIDITY_EFFICIENCY_FEATURES,\n",
    "    \"TREND\": TREND_FEATURE_NAMES,\n",
    "    \"CRISIS\": CRISIS_FEATURE_NAMES,\n",
    "    \"MACRO\": MACRO_FEATURE_NAMES,\n",
    "}\n",
    "\n",
    "group_stats = analyze_feature_groups(model, X_train, feature_groups, importance_type='gain')\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Feature Group Importance Analysis\")\n",
    "print(\"=\"*80)\n",
    "print(group_stats.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aymh1btlp4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis\n",
    "from credit_risk_xai.modeling import get_shap_feature_importance, compute_shap_values\n",
    "import shap\n",
    "\n",
    "# 1. Compute SHAP-based feature importance\n",
    "sample_size = min(10_000, len(X_val))\n",
    "shap_importance = get_shap_feature_importance(model, X_val, max_samples=sample_size, top_n=None)\n",
    "\n",
    "print(\"Top Features (by SHAP):\")\n",
    "print(shap_importance.to_string(index=False))\n",
    "\n",
    "# 2. Compare native importance vs SHAP\n",
    "comparison = importance_df.merge(shap_importance, on='feature', how='inner')\n",
    "comparison['importance_rank'] = comparison['importance'].rank(ascending=False)\n",
    "comparison['shap_rank'] = comparison['mean_abs_shap'].rank(ascending=False)\n",
    "comparison['rank_diff'] = abs(comparison['importance_rank'] - comparison['shap_rank'])\n",
    "comparison = comparison.sort_values('rank_diff', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"Features with Largest Rank Difference (Gain vs SHAP)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison[['feature', 'importance', 'importance_rank', 'mean_abs_shap', 'shap_rank', 'rank_diff']].head(15).to_string(index=False))\n",
    "\n",
    "# 3. Generate SHAP summary plot\n",
    "print(f\"\\nGenerating SHAP summary plot on {sample_size:,} samples...\")\n",
    "explainer, shap_values, X_sample = compute_shap_values(model, X_val, max_samples=sample_size)\n",
    "\n",
    "# Handle binary classification\n",
    "if isinstance(shap_values, list):\n",
    "    shap_values = shap_values[1]\n",
    "\n",
    "shap.summary_plot(shap_values, X_sample, max_display=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "p7f7u3yx29l",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis by financial statement source\n",
    "from credit_risk_xai.modeling import (\n",
    "    get_feature_correlations_by_source,\n",
    "    find_high_correlations,\n",
    "    plot_correlation_heatmap,\n",
    "    summarize_within_group_correlations\n",
    ")\n",
    "from credit_risk_xai.config import FEATURE_GROUPS_BY_SOURCE\n",
    "\n",
    "# 1. Summary of within-group correlations\n",
    "print(\"=\" * 90)\n",
    "print(\"WITHIN-GROUP CORRELATION SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "group_summary = summarize_within_group_correlations(X_train, FEATURE_GROUPS_BY_SOURCE)\n",
    "print(group_summary.to_string(index=False))\n",
    "\n",
    "# 2. Compute correlations for each group\n",
    "corr_by_source = get_feature_correlations_by_source(X_train, FEATURE_GROUPS_BY_SOURCE)\n",
    "\n",
    "# 3. Find and display high correlations in each group\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"HIGH CORRELATIONS BY GROUP (|r| > 0.7)\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for group_name in [\"MACRO\", \"DERIVED_RATIOS\", \"WORKING_CAPITAL\", \"OPERATIONAL\"]:\n",
    "    if group_name not in corr_by_source:\n",
    "        continue\n",
    "    \n",
    "    high_corrs = find_high_correlations(corr_by_source[group_name], threshold=0.7, top_n=50)\n",
    "    \n",
    "    if len(high_corrs) > 0:\n",
    "        print(f\"\\n{group_name} - Top 50 Correlated Pairs:\")\n",
    "        print(high_corrs.to_string(index=False))\n",
    "    else:\n",
    "        print(f\"\\n{group_name} - No correlations above 0.7\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iuo07uiluzp",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 1: FAST FEATURE ANALYSIS - Cell 1\n",
    "# Low Variance Detection + High Multicollinearity Detection\n",
    "# ============================================================================\n",
    "\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from credit_risk_xai.modeling import find_high_correlations\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"FEATURE PRUNING ANALYSIS - PHASE 1: FAST ANALYSIS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# 1. LOW VARIANCE FEATURES\n",
    "print(\"\\n1. LOW VARIANCE DETECTION\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "def identify_low_variance_features(X, threshold=0.01):\n",
    "    \"\"\"Identify features with near-zero variance.\"\"\"\n",
    "    variances = X.var()\n",
    "    low_var_features = variances[variances < threshold].sort_values()\n",
    "    return pd.DataFrame({\n",
    "        'feature': low_var_features.index,\n",
    "        'variance': low_var_features.values\n",
    "    })\n",
    "\n",
    "low_var_df = identify_low_variance_features(X_train, threshold=0.01)\n",
    "print(f\"Features with variance < 0.01: {len(low_var_df)}\")\n",
    "if len(low_var_df) > 0:\n",
    "    print(\"\\nLow variance features:\")\n",
    "    print(low_var_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\u2713 No low variance features found\")\n",
    "\n",
    "# 2. HIGH MULTICOLLINEARITY (Feature-Feature)\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"2. MULTICOLLINEARITY DETECTION\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Compute full correlation matrix\n",
    "corr_matrix = X_train.corr()\n",
    "\n",
    "# Find high correlations at multiple thresholds\n",
    "high_corr_90 = find_high_correlations(corr_matrix, threshold=0.90, top_n=None)\n",
    "high_corr_85 = find_high_correlations(corr_matrix, threshold=0.85, top_n=None)\n",
    "\n",
    "print(f\"Feature pairs with |corr| > 0.90: {len(high_corr_90)}\")\n",
    "print(f\"Feature pairs with |corr| > 0.85: {len(high_corr_85)}\")\n",
    "\n",
    "if len(high_corr_85) > 0:\n",
    "    print(\"\\nMost correlated feature pairs (|r| > 0.85):\")\n",
    "    print(high_corr_85.to_string(index=False))\n",
    "else:\n",
    "    print(\"\u2713 No highly correlated pairs above 0.85\")\n",
    "\n",
    "# 3. STORE FINDINGS\n",
    "features_to_investigate = {\n",
    "    'low_variance': low_var_df['feature'].tolist() if len(low_var_df) > 0 else [],\n",
    "    'high_multicollinearity_85': list(set(\n",
    "        high_corr_85['feature_1'].tolist() + high_corr_85['feature_2'].tolist()\n",
    "    )) if len(high_corr_85) > 0 else [],\n",
    "    'high_multicollinearity_90': list(set(\n",
    "        high_corr_90['feature_1'].tolist() + high_corr_90['feature_2'].tolist()\n",
    "    )) if len(high_corr_90) > 0 else []\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"SUMMARY - Features Flagged for Investigation\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"Low variance: {len(features_to_investigate['low_variance'])}\")\n",
    "print(f\"High multicollinearity (>0.85): {len(features_to_investigate['high_multicollinearity_85'])}\")\n",
    "print(f\"High multicollinearity (>0.90): {len(features_to_investigate['high_multicollinearity_90'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lkalwyyvc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 1: FAST FEATURE ANALYSIS - Cell 2\n",
    "# Consolidate All Analyses into Master DataFrame\n",
    "# ============================================================================\n",
    "\n",
    "from credit_risk_xai.modeling.explain import analyze_correlation_with_target\n",
    "\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"CONSOLIDATING ALL FEATURE ANALYSES\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Merge all importance metrics we already have\n",
    "target_corr = analyze_correlation_with_target(X_train, y_train, method='pearson', top_n=50)\n",
    "\n",
    "master_df = (\n",
    "    importance_df  # tree-based (from earlier cell)\n",
    "    .merge(shap_importance[['feature', 'mean_abs_shap']], on='feature', how='left')\n",
    "    .merge(target_corr[['feature', 'correlation']], on='feature', how='left')\n",
    ")\n",
    "\n",
    "# Rename columns for clarity\n",
    "master_df = master_df.rename(columns={\n",
    "    'importance': 'tree_importance',\n",
    "    'mean_abs_shap': 'shap_importance',\n",
    "    'correlation': 'target_corr'\n",
    "})\n",
    "\n",
    "# Add variance\n",
    "master_df['variance'] = master_df['feature'].apply(lambda f: X_train[f].var())\n",
    "\n",
    "# Add flags for each removal criterion\n",
    "master_df['is_low_variance'] = master_df['feature'].isin(features_to_investigate.get('low_variance', []))\n",
    "master_df['is_multicollinear_85'] = master_df['feature'].isin(features_to_investigate.get('high_multicollinearity_85', []))\n",
    "master_df['is_multicollinear_90'] = master_df['feature'].isin(features_to_investigate.get('high_multicollinearity_90', []))\n",
    "\n",
    "# Identify low importance features (bottom 20% in both SHAP and tree importance)\n",
    "shap_threshold_20 = master_df['shap_importance'].quantile(0.20)\n",
    "tree_threshold_20 = master_df['tree_importance'].quantile(0.20)\n",
    "\n",
    "master_df['is_low_shap'] = master_df['shap_importance'] < shap_threshold_20\n",
    "master_df['is_low_tree'] = master_df['tree_importance'] < tree_threshold_20\n",
    "master_df['is_low_both'] = master_df['is_low_shap'] & master_df['is_low_tree']\n",
    "\n",
    "# Count \"red flags\" for each feature\n",
    "flag_cols = ['is_low_variance', 'is_multicollinear_85', 'is_low_shap', 'is_low_tree']\n",
    "master_df['red_flag_count'] = master_df[flag_cols].sum(axis=1)\n",
    "\n",
    "# Sort by red flags (most problematic first)\n",
    "master_df = master_df.sort_values('red_flag_count', ascending=False)\n",
    "\n",
    "# Display summary\n",
    "print(f\"\\nTotal features analyzed: {len(master_df)}\")\n",
    "print(f\"Features with 3+ red flags: {(master_df['red_flag_count'] >= 3).sum()}\")\n",
    "print(f\"Features with 2+ red flags: {(master_df['red_flag_count'] >= 2).sum()}\")\n",
    "print(f\"Features with 1+ red flags: {(master_df['red_flag_count'] >= 1).sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 90)\n",
    "print(\"Top 20 features with most red flags:\")\n",
    "print(\"-\" * 90)\n",
    "display_cols = ['feature', 'tree_importance', 'shap_importance', 'target_corr', 'variance', 'red_flag_count']\n",
    "print(master_df[display_cols].head(20).to_string(index=False))\n",
    "\n",
    "# Save for manual review\n",
    "master_df.to_csv('feature_analysis_master.csv', index=False)\n",
    "print(f\"\\n\u2713 Saved master analysis to: feature_analysis_master.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"RED FLAG BREAKDOWN\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"Low variance (<0.01): {master_df['is_low_variance'].sum()}\")\n",
    "print(f\"Multicollinear (>0.85): {master_df['is_multicollinear_85'].sum()}\")\n",
    "print(f\"Low SHAP (bottom 20%): {master_df['is_low_shap'].sum()}\")\n",
    "print(f\"Low tree importance (bottom 20%): {master_df['is_low_tree'].sum()}\")\n",
    "print(f\"Low in BOTH importance metrics: {master_df['is_low_both'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nxvf05uyddi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 1: FAST FEATURE ANALYSIS - Cell 3\n",
    "# Resolve Multicollinearity Pairs - Keep Feature with Higher SHAP\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"RESOLVING MULTICOLLINEARITY PAIRS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "def resolve_multicollinearity_pairs(corr_pairs_df, master_df, strategy='shap'):\n",
    "    \"\"\"\n",
    "    For each highly correlated pair, keep the better feature.\n",
    "    \n",
    "    Args:\n",
    "        corr_pairs_df: DataFrame with columns ['feature_1', 'feature_2', 'correlation']\n",
    "        master_df: Master feature analysis DataFrame\n",
    "        strategy: 'shap', 'tree', or 'target_corr'\n",
    "    \n",
    "    Returns:\n",
    "        List of features to drop\n",
    "    \"\"\"\n",
    "    if len(corr_pairs_df) == 0:\n",
    "        return []\n",
    "    \n",
    "    features_to_drop = []\n",
    "    importance_col = {\n",
    "        'shap': 'shap_importance',\n",
    "        'tree': 'tree_importance',\n",
    "        'target_corr': 'target_corr'\n",
    "    }[strategy]\n",
    "    \n",
    "    for idx, row in corr_pairs_df.iterrows():\n",
    "        feat1, feat2 = row['feature_1'], row['feature_2']\n",
    "        \n",
    "        # Skip if already marked for removal\n",
    "        if feat1 in features_to_drop or feat2 in features_to_drop:\n",
    "            continue\n",
    "        \n",
    "        # Get metrics for both\n",
    "        metrics1 = master_df[master_df['feature'] == feat1].iloc[0]\n",
    "        metrics2 = master_df[master_df['feature'] == feat2].iloc[0]\n",
    "        \n",
    "        # Decision: keep feature with higher importance\n",
    "        val1 = metrics1[importance_col]\n",
    "        val2 = metrics2[importance_col]\n",
    "        \n",
    "        if pd.isna(val1):\n",
    "            val1 = 0\n",
    "        if pd.isna(val2):\n",
    "            val2 = 0\n",
    "        \n",
    "        if val1 >= val2:\n",
    "            features_to_drop.append(feat2)\n",
    "            print(f\"Drop '{feat2}' (keep '{feat1}') | {importance_col}: {val2:.6f} vs {val1:.6f} | corr: {row['correlation']:.3f}\")\n",
    "        else:\n",
    "            features_to_drop.append(feat1)\n",
    "            print(f\"Drop '{feat1}' (keep '{feat2}') | {importance_col}: {val1:.6f} vs {val2:.6f} | corr: {row['correlation']:.3f}\")\n",
    "    \n",
    "    return features_to_drop\n",
    "\n",
    "# Resolve multicollinearity using SHAP importance (as per user preference)\n",
    "print(f\"\\nResolving {len(high_corr_85)} highly correlated pairs (|r| > 0.85)...\")\n",
    "print(\"Strategy: Keep feature with HIGHER SHAP importance\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "multicollinearity_drops = resolve_multicollinearity_pairs(\n",
    "    high_corr_85, \n",
    "    master_df, \n",
    "    strategy='shap'\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(f\"\u2713 Resolved {len(high_corr_85)} pairs \u2192 {len(multicollinearity_drops)} features to drop\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zn3pfro1mtc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 2: PROGRESSIVE PRUNING - Cell 4\n",
    "# Round 1: Conservative Pruning\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"PHASE 2: PROGRESSIVE FEATURE PRUNING\")\n",
    "print(\"=\" * 90)\n",
    "print(\"\\nROUND 1: CONSERVATIVE PRUNING\")\n",
    "print(\"-\" * 90)\n",
    "print(\"Removal criteria:\")\n",
    "print(\"  - Near-zero variance features\")\n",
    "print(\"  - One feature from each highly correlated pair (|r| > 0.85)\")\n",
    "print(\"  - Features with 3+ red flags\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Build conservative removal list\n",
    "automatic_removal = master_df[master_df['red_flag_count'] >= 3]['feature'].tolist()\n",
    "\n",
    "conservative_removal_list = list(set(\n",
    "    features_to_investigate.get('low_variance', []) +\n",
    "    multicollinearity_drops +\n",
    "    automatic_removal\n",
    "))\n",
    "\n",
    "print(f\"\\nRemoval breakdown:\")\n",
    "print(f\"  - Low variance: {len(features_to_investigate.get('low_variance', []))}\")\n",
    "print(f\"  - Multicollinearity: {len(multicollinearity_drops)}\")\n",
    "print(f\"  - Multiple red flags (3+): {len(automatic_removal)}\")\n",
    "print(f\"\\nTotal features to remove: {len(conservative_removal_list)}\")\n",
    "print(f\"Features remaining: {X_train.shape[1] - len(conservative_removal_list)}\")\n",
    "print(f\"Reduction: {100 * len(conservative_removal_list) / X_train.shape[1]:.1f}%\")\n",
    "\n",
    "# Create pruned dataset\n",
    "features_conservative = [f for f in X_train.columns if f not in conservative_removal_list]\n",
    "X_train_conservative = X_train[features_conservative]\n",
    "X_val_conservative = X_val[features_conservative]\n",
    "\n",
    "# Retrain model with same hyperparameters\n",
    "print(\"\\n\" + \"-\" * 90)\n",
    "print(\"Retraining model with conservative feature set...\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "lgbm_conservative = lgb.LGBMClassifier(**DEFAULT_PARAMS)\n",
    "lgbm_conservative.fit(\n",
    "    X_train_conservative, y_train,\n",
    "    eval_set=[(X_val_conservative, y_val)],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[lgb.log_evaluation(100), lgb.early_stopping(50)]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba_conservative = lgbm_conservative.predict_proba(X_val_conservative)[:, 1]\n",
    "y_pred_conservative = (y_pred_proba_conservative >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "auc_conservative = roc_auc_score(y_val, y_pred_proba_conservative)\n",
    "pr_auc_conservative = average_precision_score(y_val, y_pred_proba_conservative)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"CONSERVATIVE MODEL PERFORMANCE\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"ROC-AUC:  {auc_conservative:.6f} (baseline: {auc:.6f}, \u0394: {auc_conservative - auc:+.6f})\")\n",
    "print(f\"PR-AUC:   {pr_auc_conservative:.6f} (baseline: {pr_auc:.6f}, \u0394: {pr_auc_conservative - pr_auc:+.6f})\")\n",
    "print(f\"\\nFeatures: {len(features_conservative)} (from {X_train.shape[1]})\")\n",
    "print(f\"Reduction: {100 * len(conservative_removal_list) / X_train.shape[1]:.1f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_conservative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "iwadojgronq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 2: PROGRESSIVE PRUNING - Cell 5\n",
    "# Round 2: Moderate Pruning\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"ROUND 2: MODERATE PRUNING\")\n",
    "print(\"-\" * 90)\n",
    "print(\"Additional removal criteria:\")\n",
    "print(\"  - Features in bottom 20% of BOTH SHAP and tree importance\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Add features that are low in both importance metrics\n",
    "low_both_features = master_df[master_df['is_low_both']]['feature'].tolist()\n",
    "\n",
    "moderate_removal_list = list(set(\n",
    "    conservative_removal_list +\n",
    "    low_both_features\n",
    "))\n",
    "\n",
    "print(f\"\\nAdding {len(low_both_features)} features with low importance in both metrics\")\n",
    "print(f\"Total features to remove: {len(moderate_removal_list)}\")\n",
    "print(f\"Features remaining: {X_train.shape[1] - len(moderate_removal_list)}\")\n",
    "print(f\"Reduction: {100 * len(moderate_removal_list) / X_train.shape[1]:.1f}%\")\n",
    "\n",
    "# Create moderate pruned dataset\n",
    "features_moderate = [f for f in X_train.columns if f not in moderate_removal_list]\n",
    "X_train_moderate = X_train[features_moderate]\n",
    "X_val_moderate = X_val[features_moderate]\n",
    "\n",
    "print(\"\\n\" + \"-\" * 90)\n",
    "print(\"Retraining model with moderate feature set...\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "lgbm_moderate = lgb.LGBMClassifier(**DEFAULT_PARAMS)\n",
    "lgbm_moderate.fit(\n",
    "    X_train_moderate, y_train,\n",
    "    eval_set=[(X_val_moderate, y_val)],\n",
    "    eval_metric='logloss',\n",
    "    callbacks=[lgb.log_evaluation(100), lgb.early_stopping(50)]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred_proba_moderate = lgbm_moderate.predict_proba(X_val_moderate)[:, 1]\n",
    "y_pred_moderate = (y_pred_proba_moderate >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "auc_moderate = roc_auc_score(y_val, y_pred_proba_moderate)\n",
    "pr_auc_moderate = average_precision_score(y_val, y_pred_proba_moderate)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"MODERATE MODEL PERFORMANCE\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"ROC-AUC:  {auc_moderate:.6f} (baseline: {auc:.6f}, \u0394: {auc_moderate - auc:+.6f})\")\n",
    "print(f\"PR-AUC:   {pr_auc_moderate:.6f} (baseline: {pr_auc:.6f}, \u0394: {pr_auc_moderate - pr_auc:+.6f})\")\n",
    "print(f\"\\nFeatures: {len(features_moderate)} (from {X_train.shape[1]})\")\n",
    "print(f\"Reduction: {100 * len(moderate_removal_list) / X_train.shape[1]:.1f}%\")\n",
    "\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, y_pred_moderate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3nb4r0tlas2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 2: PROGRESSIVE PRUNING - Cell 6\n",
    "# Round 3: Top-K Pruning Tests (Aggressive)\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"ROUND 3: TOP-K FEATURE SELECTION (AGGRESSIVE)\")\n",
    "print(\"-\" * 90)\n",
    "print(\"Testing different feature set sizes by keeping only top-K features by SHAP importance\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Sort features by SHAP importance\n",
    "shap_ranked = master_df.sort_values('shap_importance', ascending=False)\n",
    "\n",
    "# Store results for different K values\n",
    "topk_results = {}\n",
    "\n",
    "for top_k in [60, 50, 40, 30]:\n",
    "    print(f\"\\n{'='*90}\")\n",
    "    print(f\"Testing TOP-{top_k} features by SHAP importance\")\n",
    "    print('-'*90)\n",
    "    \n",
    "    # Select top K features\n",
    "    features_topk = shap_ranked.head(top_k)['feature'].tolist()\n",
    "    \n",
    "    X_train_topk = X_train[features_topk]\n",
    "    X_val_topk = X_val[features_topk]\n",
    "    \n",
    "    # Train model (silent mode)\n",
    "    lgbm_topk = lgb.LGBMClassifier(**DEFAULT_PARAMS)\n",
    "    lgbm_topk.fit(\n",
    "        X_train_topk, y_train,\n",
    "        eval_set=[(X_val_topk, y_val)],\n",
    "        eval_metric='logloss',\n",
    "        callbacks=[lgb.log_evaluation(0), lgb.early_stopping(50)]  # Silent\n",
    "    )\n",
    "    \n",
    "    # Evaluate\n",
    "    y_pred_proba_topk = lgbm_topk.predict_proba(X_val_topk)[:, 1]\n",
    "    y_pred_topk = (y_pred_proba_topk >= 0.5).astype(int)\n",
    "    \n",
    "    auc_topk = roc_auc_score(y_val, y_pred_proba_topk)\n",
    "    pr_auc_topk = average_precision_score(y_val, y_pred_proba_topk)\n",
    "    \n",
    "    # Store results\n",
    "    topk_results[f'top_{top_k}'] = {\n",
    "        'model': lgbm_topk,\n",
    "        'features': features_topk,\n",
    "        'X_train': X_train_topk,\n",
    "        'X_val': X_val_topk,\n",
    "        'y_pred_proba': y_pred_proba_topk,\n",
    "        'y_pred': y_pred_topk,\n",
    "        'auc': auc_topk,\n",
    "        'pr_auc': pr_auc_topk,\n",
    "        'num_features': top_k\n",
    "    }\n",
    "    \n",
    "    print(f\"ROC-AUC:  {auc_topk:.6f} (\u0394 from baseline: {auc_topk - auc:+.6f})\")\n",
    "    print(f\"PR-AUC:   {pr_auc_topk:.6f} (\u0394 from baseline: {pr_auc_topk - pr_auc:+.6f})\")\n",
    "    print(f\"Features: {top_k} ({100 * (X_train.shape[1] - top_k) / X_train.shape[1]:.1f}% reduction)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"\u2713 Top-K testing complete\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yb6ufrvksn7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 2: PROGRESSIVE PRUNING - Cell 7\n",
    "# Performance Comparison & Decision Point\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"COMPREHENSIVE PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Compile all results\n",
    "comparison_data = {\n",
    "    'Approach': [\n",
    "        'Baseline (105 features)',\n",
    "        'Conservative Pruning',\n",
    "        'Moderate Pruning',\n",
    "        'Top-50 SHAP',\n",
    "        'Top-40 SHAP',\n",
    "        'Top-30 SHAP'\n",
    "    ],\n",
    "    'Num_Features': [\n",
    "        X_train.shape[1],\n",
    "        len(features_conservative),\n",
    "        len(features_moderate),\n",
    "        50, 40, 30\n",
    "    ],\n",
    "    'ROC_AUC': [\n",
    "        auc,\n",
    "        auc_conservative,\n",
    "        auc_moderate,\n",
    "        topk_results['top_50']['auc'],\n",
    "        topk_results['top_40']['auc'],\n",
    "        topk_results['top_30']['auc']\n",
    "    ],\n",
    "    'PR_AUC': [\n",
    "        pr_auc,\n",
    "        pr_auc_conservative,\n",
    "        pr_auc_moderate,\n",
    "        topk_results['top_50']['pr_auc'],\n",
    "        topk_results['top_40']['pr_auc'],\n",
    "        topk_results['top_30']['pr_auc']\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df['Feature_Reduction_%'] = 100 * (X_train.shape[1] - comparison_df['Num_Features']) / X_train.shape[1]\n",
    "comparison_df['AUC_Delta'] = comparison_df['ROC_AUC'] - auc\n",
    "comparison_df['PR_AUC_Delta'] = comparison_df['PR_AUC'] - pr_auc\n",
    "\n",
    "print(\"\\n\" + comparison_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Plot 1: AUC vs Feature Count\n",
    "axes[0].scatter(comparison_df['Num_Features'], comparison_df['ROC_AUC'], s=100, alpha=0.7)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    axes[0].annotate(\n",
    "        row['Approach'].replace(' ', '\\n'), \n",
    "        (row['Num_Features'], row['ROC_AUC']),\n",
    "        fontsize=8, ha='center', va='bottom'\n",
    "    )\n",
    "axes[0].axhline(y=auc, color='red', linestyle='--', alpha=0.5, label='Baseline AUC')\n",
    "axes[0].set_xlabel('Number of Features')\n",
    "axes[0].set_ylabel('ROC-AUC')\n",
    "axes[0].set_title('ROC-AUC vs Number of Features')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot 2: Feature Reduction vs Performance Loss\n",
    "axes[1].scatter(comparison_df['Feature_Reduction_%'], -comparison_df['AUC_Delta'] * 1000, s=100, alpha=0.7)\n",
    "for idx, row in comparison_df.iterrows():\n",
    "    if idx > 0:  # Skip baseline\n",
    "        axes[1].annotate(\n",
    "            row['Approach'].split()[0], \n",
    "            (row['Feature_Reduction_%'], -row['AUC_Delta'] * 1000),\n",
    "            fontsize=8, ha='center', va='bottom'\n",
    "        )\n",
    "axes[1].axhline(y=0, color='green', linestyle='--', alpha=0.5, label='No performance loss')\n",
    "axes[1].set_xlabel('Feature Reduction (%)')\n",
    "axes[1].set_ylabel('AUC Loss (\u00d71000)')\n",
    "axes[1].set_title('Performance Loss vs Feature Reduction')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Decision guidance\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"RECOMMENDATION & DECISION GUIDANCE\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Find best tradeoffs\n",
    "best_auc = comparison_df.iloc[comparison_df['ROC_AUC'].idxmax()]\n",
    "best_reduction = comparison_df[comparison_df['Feature_Reduction_%'] > 20].iloc[\n",
    "    comparison_df[comparison_df['Feature_Reduction_%'] > 20]['AUC_Delta'].idxmax()\n",
    "]\n",
    "\n",
    "print(f\"\\n\u2713 Best AUC: {best_auc['Approach']} ({best_auc['ROC_AUC']:.6f})\")\n",
    "print(f\"\u2713 Best balance (>20% reduction): {best_reduction['Approach']}\")\n",
    "print(f\"  - {best_reduction['Num_Features']} features ({best_reduction['Feature_Reduction_%']:.1f}% reduction)\")\n",
    "print(f\"  - AUC: {best_reduction['ROC_AUC']:.6f} (\u0394: {best_reduction['AUC_Delta']:+.6f})\")\n",
    "\n",
    "print(\"\\n\" + \"-\" * 90)\n",
    "print(\"Next step: Choose your preferred approach and run the final analysis cells\")\n",
    "print(\"Recommendation: Conservative or Moderate if AUC loss < 0.001\")\n",
    "print(\"               Top-K if you need maximum interpretability and AUC loss is acceptable\")\n",
    "print(\"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000870d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "moderate_removal_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2wbmd9firfy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 3: FINAL MODEL ANALYSIS - Cell 8\n",
    "# Select Final Model & Re-analyze Feature Set\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"PHASE 3: FINAL MODEL SELECTION & ANALYSIS\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# USER DECISION: Choose which model to use as final\n",
    "# Options: 'conservative', 'moderate', 'top_50', 'top_40', 'top_30'\n",
    "FINAL_MODEL_CHOICE = 'conservative'  # \u2190 CHANGE THIS based on comparison results\n",
    "\n",
    "print(f\"\\nSelected approach: {FINAL_MODEL_CHOICE.upper()}\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Map choice to results\n",
    "model_map = {\n",
    "    'conservative': {\n",
    "        'model': lgbm_conservative,\n",
    "        'features': features_conservative,\n",
    "        'X_train': X_train_conservative,\n",
    "        'X_val': X_val_conservative,\n",
    "        'y_pred_proba': y_pred_proba_conservative,\n",
    "        'removal_list': conservative_removal_list,\n",
    "        'auc': auc_conservative,\n",
    "        'pr_auc': pr_auc_conservative\n",
    "    },\n",
    "    'moderate': {\n",
    "        'model': lgbm_moderate,\n",
    "        'features': features_moderate,\n",
    "        'X_train': X_train_moderate,\n",
    "        'X_val': X_val_moderate,\n",
    "        'y_pred_proba': y_pred_proba_moderate,\n",
    "        'removal_list': moderate_removal_list,\n",
    "        'auc': auc_moderate,\n",
    "        'pr_auc': pr_auc_moderate\n",
    "    },\n",
    "    'top_50': topk_results['top_50'],\n",
    "    'top_40': topk_results['top_40'],\n",
    "    'top_30': topk_results['top_30']\n",
    "}\n",
    "\n",
    "final_model_data = model_map[FINAL_MODEL_CHOICE]\n",
    "final_model = final_model_data['model']\n",
    "final_features = final_model_data['features']\n",
    "final_X_train = final_model_data['X_train']\n",
    "final_X_val = final_model_data['X_val']\n",
    "final_y_pred_proba = final_model_data['y_pred_proba']\n",
    "\n",
    "print(f\"Final feature count: {len(final_features)}\")\n",
    "print(f\"Reduction: {100 * (X_train.shape[1] - len(final_features)) / X_train.shape[1]:.1f}%\")\n",
    "print(f\"ROC-AUC: {final_model_data['auc']:.6f}\")\n",
    "print(f\"PR-AUC: {final_model_data['pr_auc']:.6f}\")\n",
    "\n",
    "# 1. FEATURE IMPORTANCE FOR FINAL MODEL\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"FEATURE IMPORTANCE - FINAL MODEL\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "final_importance_df = pd.DataFrame({\n",
    "    'feature': final_model.feature_name_,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 30 features:\")\n",
    "print(final_importance_df.head(30).to_string(index=False))\n",
    "\n",
    "# Plot top features\n",
    "from credit_risk_xai.modeling import plot_feature_importance\n",
    "plot_feature_importance(final_importance_df, top_n=25, title=f\"Top 25 Features - {FINAL_MODEL_CHOICE.upper()} Model\")\n",
    "\n",
    "# Importance concentration\n",
    "top10_importance = final_importance_df.head(10)['importance'].sum() / final_importance_df['importance'].sum()\n",
    "top20_importance = final_importance_df.head(20)['importance'].sum() / final_importance_df['importance'].sum()\n",
    "\n",
    "print(f\"\\n\u2713 Top 10 features account for {top10_importance * 100:.1f}% of total importance\")\n",
    "print(f\"\u2713 Top 20 features account for {top20_importance * 100:.1f}% of total importance\")\n",
    "\n",
    "# 2. RE-CHECK CORRELATION ANALYSIS\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"CORRELATION CHECK - FINAL MODEL\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Re-check feature-feature correlation in final set\n",
    "final_corr_matrix = final_X_train.corr()\n",
    "remaining_high_corr = find_high_correlations(final_corr_matrix, threshold=0.80, top_n=None)\n",
    "\n",
    "print(f\"Remaining feature pairs with |corr| > 0.80: {len(remaining_high_corr)}\")\n",
    "if len(remaining_high_corr) > 0:\n",
    "    print(\"\\n\u26a0\ufe0f  WARNING: Still have correlated features:\")\n",
    "    print(remaining_high_corr.head(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\u2713 No highly correlated feature pairs remain!\")\n",
    "\n",
    "# 3. FEATURE GROUP BREAKDOWN\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"FEATURE GROUP ANALYSIS - FINAL MODEL\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "from credit_risk_xai.config import FEATURE_GROUPS_BY_SOURCE\n",
    "\n",
    "# Count features by group in final set\n",
    "group_counts = {}\n",
    "for group_name, group_features in FEATURE_GROUPS_BY_SOURCE.items():\n",
    "    count = len([f for f in final_features if f in group_features])\n",
    "    total = len(group_features)\n",
    "    group_counts[group_name] = {\n",
    "        'kept': count,\n",
    "        'total': total,\n",
    "        'retention_%': 100 * count / total if total > 0 else 0\n",
    "    }\n",
    "\n",
    "group_breakdown = pd.DataFrame(group_counts).T.reset_index()\n",
    "group_breakdown.columns = ['Group', 'Kept', 'Total', 'Retention_%']\n",
    "group_breakdown = group_breakdown.sort_values('Kept', ascending=False)\n",
    "\n",
    "print(group_breakdown.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ja0mh4t1p8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 3: FINAL MODEL ANALYSIS - Cell 9\n",
    "# Calibration Curves - Baseline vs Final Model\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"CALIBRATION ANALYSIS - BASELINE vs FINAL MODEL\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# Plot calibration curves for comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Baseline model calibration\n",
    "from sklearn.calibration import calibration_curve\n",
    "\n",
    "fraction_baseline, mean_pred_baseline = calibration_curve(\n",
    "    y_val, y_pred_proba, n_bins=100, strategy='quantile'\n",
    ")\n",
    "ece_baseline = np.mean(np.abs(fraction_baseline - mean_pred_baseline))\n",
    "\n",
    "axes[0].plot(mean_pred_baseline, fraction_baseline, \"s-\", label=\"Baseline Model\", linewidth=2)\n",
    "axes[0].plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\", alpha=0.5)\n",
    "axes[0].set_xlabel(\"Mean predicted probability\")\n",
    "axes[0].set_ylabel(\"Fraction of positives\")\n",
    "axes[0].set_title(f\"Baseline Model (105 features)\\nECE: {ece_baseline:.4f}\")\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Final model calibration\n",
    "fraction_final, mean_pred_final = calibration_curve(\n",
    "    y_val, final_y_pred_proba, n_bins=100, strategy='quantile'\n",
    ")\n",
    "ece_final = np.mean(np.abs(fraction_final - mean_pred_final))\n",
    "\n",
    "axes[1].plot(mean_pred_final, fraction_final, \"s-\", label=f\"{FINAL_MODEL_CHOICE.upper()} Model\", linewidth=2, color='orange')\n",
    "axes[1].plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\", alpha=0.5)\n",
    "axes[1].set_xlabel(\"Mean predicted probability\")\n",
    "axes[1].set_ylabel(\"Fraction of positives\")\n",
    "axes[1].set_title(f\"{FINAL_MODEL_CHOICE.upper()} Model ({len(final_features)} features)\\nECE: {ece_final:.4f}\")\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Comparison\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"CALIBRATION COMPARISON\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"Baseline ECE:  {ece_baseline:.4f}\")\n",
    "print(f\"Final ECE:     {ece_final:.4f}\")\n",
    "print(f\"\u0394 ECE:         {ece_final - ece_baseline:+.4f}\")\n",
    "\n",
    "if abs(ece_final - ece_baseline) < 0.001:\n",
    "    print(\"\\n\u2713 Calibration is virtually unchanged\")\n",
    "elif ece_final < ece_baseline:\n",
    "    print(\"\\n\u2713 Calibration improved after feature pruning\")\n",
    "else:\n",
    "    print(\"\\n\u26a0\ufe0f  Calibration slightly worse (may need recalibration)\")\n",
    "\n",
    "# Side-by-side overlay\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(mean_pred_baseline, fraction_baseline, \"s-\", label=f\"Baseline (ECE: {ece_baseline:.4f})\", linewidth=2, alpha=0.7)\n",
    "plt.plot(mean_pred_final, fraction_final, \"o-\", label=f\"{FINAL_MODEL_CHOICE.upper()} (ECE: {ece_final:.4f})\", linewidth=2, alpha=0.7)\n",
    "plt.plot([0, 1], [0, 1], \"k--\", label=\"Perfect calibration\", alpha=0.5)\n",
    "plt.xlabel(\"Mean predicted probability\", fontsize=12)\n",
    "plt.ylabel(\"Fraction of positives\", fontsize=12)\n",
    "plt.title(\"Calibration Curve Comparison\", fontsize=14)\n",
    "plt.legend(fontsize=11)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0w2ektzbb6q",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PHASE 3: FINAL MODEL ANALYSIS - Cell 10\n",
    "# Export Results & Documentation\n",
    "# ============================================================================\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"EXPORTING RESULTS & DOCUMENTATION\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "# 1. CREATE FEATURE REMOVAL REPORT\n",
    "print(\"\\n1. Creating feature removal report...\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "# Identify which features were removed and why\n",
    "if FINAL_MODEL_CHOICE in ['conservative', 'moderate']:\n",
    "    removal_list = final_model_data['removal_list']\n",
    "    \n",
    "    removal_report = []\n",
    "    for feat in removal_list:\n",
    "        feat_info = master_df[master_df['feature'] == feat].iloc[0]\n",
    "        \n",
    "        reasons = []\n",
    "        if feat_info['is_low_variance']:\n",
    "            reasons.append('Low variance')\n",
    "        if feat_info['is_multicollinear_85']:\n",
    "            reasons.append('Multicollinear (|r|>0.85)')\n",
    "        if feat_info['is_low_shap']:\n",
    "            reasons.append('Low SHAP importance (bottom 20%)')\n",
    "        if feat_info['is_low_tree']:\n",
    "            reasons.append('Low tree importance (bottom 20%)')\n",
    "        \n",
    "        removal_report.append({\n",
    "            'feature': feat,\n",
    "            'removal_reason': '; '.join(reasons) if reasons else 'Part of correlated pair',\n",
    "            'tree_importance': feat_info['tree_importance'],\n",
    "            'shap_importance': feat_info['shap_importance'],\n",
    "            'target_corr': feat_info['target_corr'],\n",
    "            'variance': feat_info['variance'],\n",
    "            'red_flag_count': feat_info['red_flag_count']\n",
    "        })\n",
    "    \n",
    "    removal_report_df = pd.DataFrame(removal_report).sort_values('red_flag_count', ascending=False)\n",
    "    removal_report_df.to_csv('feature_removal_report.csv', index=False)\n",
    "    print(f\"\u2713 Saved feature removal report: feature_removal_report.csv ({len(removal_report_df)} features)\")\n",
    "\n",
    "# 2. EXPORT FINAL FEATURE LIST\n",
    "print(\"\\n2. Exporting final feature list...\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "final_features_df = pd.DataFrame({\n",
    "    'feature': sorted(final_features),\n",
    "    'feature_type': [final_X_train[f].dtype for f in sorted(final_features)]\n",
    "})\n",
    "final_features_df.to_csv('final_feature_list.csv', index=False)\n",
    "print(f\"\u2713 Saved final feature list: final_feature_list.csv ({len(final_features)} features)\")\n",
    "\n",
    "# Feature type breakdown\n",
    "print(\"\\nFeature type breakdown:\")\n",
    "print(final_features_df['feature_type'].value_counts().to_string())\n",
    "\n",
    "# 3. EXPORT AS PYTHON CONSTANT\n",
    "print(\"\\n3. Exporting as Python constant...\")\n",
    "print(\"-\" * 90)\n",
    "\n",
    "with open('final_features.py', 'w') as f:\n",
    "    f.write(\"# Auto-generated feature list after pruning\\n\")\n",
    "    f.write(f\"# Generated on: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}\\n\")\n",
    "    f.write(f\"# Pruning approach: {FINAL_MODEL_CHOICE.upper()}\\n\")\n",
    "    f.write(f\"# Original features: {X_train.shape[1]}\\n\")\n",
    "    f.write(f\"# Final features: {len(final_features)}\\n\")\n",
    "    f.write(f\"# Reduction: {100 * (X_train.shape[1] - len(final_features)) / X_train.shape[1]:.1f}%\\n\")\n",
    "    f.write(f\"# ROC-AUC: {final_model_data['auc']:.6f}\\n\")\n",
    "    f.write(f\"# PR-AUC: {final_model_data['pr_auc']:.6f}\\n\\n\")\n",
    "    f.write(\"FINAL_FEATURES = [\\n\")\n",
    "    for feat in sorted(final_features):\n",
    "        f.write(f\"    '{feat}',\\n\")\n",
    "    f.write(\"]\\n\")\n",
    "\n",
    "print(\"\u2713 Saved Python constant: final_features.py\")\n",
    "\n",
    "# 4. SUMMARY STATISTICS\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "summary_stats = {\n",
    "    'Metric': [\n",
    "        'Original Features',\n",
    "        'Final Features',\n",
    "        'Features Removed',\n",
    "        'Reduction %',\n",
    "        '',\n",
    "        'Baseline ROC-AUC',\n",
    "        'Final ROC-AUC',\n",
    "        'AUC Change',\n",
    "        '',\n",
    "        'Baseline PR-AUC',\n",
    "        'Final PR-AUC',\n",
    "        'PR-AUC Change',\n",
    "        '',\n",
    "        'Baseline ECE',\n",
    "        'Final ECE',\n",
    "        'ECE Change'\n",
    "    ],\n",
    "    'Value': [\n",
    "        X_train.shape[1],\n",
    "        len(final_features),\n",
    "        X_train.shape[1] - len(final_features),\n",
    "        f\"{100 * (X_train.shape[1] - len(final_features)) / X_train.shape[1]:.1f}%\",\n",
    "        '',\n",
    "        f\"{auc:.6f}\",\n",
    "        f\"{final_model_data['auc']:.6f}\",\n",
    "        f\"{final_model_data['auc'] - auc:+.6f}\",\n",
    "        '',\n",
    "        f\"{pr_auc:.6f}\",\n",
    "        f\"{final_model_data['pr_auc']:.6f}\",\n",
    "        f\"{final_model_data['pr_auc'] - pr_auc:+.6f}\",\n",
    "        '',\n",
    "        f\"{ece_baseline:.4f}\",\n",
    "        f\"{ece_final:.4f}\",\n",
    "        f\"{ece_final - ece_baseline:+.4f}\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "print(\"\\n\" + summary_df.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_df.to_csv('feature_pruning_summary.csv', index=False)\n",
    "print(\"\\n\u2713 Saved summary: feature_pruning_summary.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)\n",
    "print(\"\u2713 FEATURE PRUNING COMPLETE!\")\n",
    "print(\"=\" * 90)\n",
    "print(f\"\\nApproach used: {FINAL_MODEL_CHOICE.upper()}\")\n",
    "print(f\"Final model: {len(final_features)} features ({100 * (X_train.shape[1] - len(final_features)) / X_train.shape[1]:.1f}% reduction)\")\n",
    "print(f\"Performance: AUC {final_model_data['auc']:.6f} (\u0394 {final_model_data['auc'] - auc:+.6f})\")\n",
    "print(\"\\nGenerated files:\")\n",
    "print(\"  - feature_analysis_master.csv\")\n",
    "print(\"  - feature_removal_report.csv\")\n",
    "print(\"  - final_feature_list.csv\")\n",
    "print(\"  - final_features.py\")\n",
    "print(\"  - feature_pruning_summary.csv\")\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203d609d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conservative_removal_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}