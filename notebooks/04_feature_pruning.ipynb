{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc4a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# COMPREHENSIVE FEATURE SELECTION PIPELINE\n",
    "# State-of-the-Art Methods for Credit Risk XAI\n",
    "# ========================================\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import shap\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "from sklearn.calibration import calibration_curve\n",
    "from sklearn.feature_selection import RFECV\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from scipy.spatial.distance import squareform\n",
    "\n",
    "# Project imports\n",
    "PROJ_ROOT = Path.cwd().parent\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJ_ROOT))\n",
    "\n",
    "from credit_risk_xai.modeling.train import DEFAULT_PARAMS, FEATURES_FOR_MODEL\n",
    "from credit_risk_xai.config import FEATURE_CACHE_PATH, FEATURE_GROUPS_BY_SOURCE\n",
    "from credit_risk_xai.features.engineer import prepare_modeling_data\n",
    "from credit_risk_xai.modeling.train import run_lightgbm_training\n",
    "\n",
    "# Visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print(\"\u2713 Imports complete\")\n",
    "print(f\"\u2713 Total features in config: {len(FEATURES_FOR_MODEL)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16c401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PHASE 1: DATA LOADING & BASELINE MODEL\n",
    "# ========================================\n",
    "\n",
    "print(\"Loading data...\")\n",
    "df = pd.read_parquet(FEATURE_CACHE_PATH)\n",
    "df = df[\n",
    "      (df[\"ser_aktiv\"] == 1) \n",
    "    & (df[\"sme_category\"].isin([\"Small\", \"Medium\"])) \n",
    "    & (df[\"knc_kncfall\"] == 1)\n",
    "    & (df[\"bransch_borsbransch_konv\"] != \"40.0\")\n",
    "]\n",
    "X, y = prepare_modeling_data(df)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"DATASET SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Features: {X.shape[1]}\")\n",
    "print(f\"Samples: {len(X):,}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Imbalance ratio: {(y==0).sum()/(y==1).sum():.1f}:1\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Store original feature list\n",
    "ORIGINAL_FEATURES = X.columns.tolist()\n",
    "print(f\"Original feature set: {len(ORIGINAL_FEATURES)} features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be7ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train baseline model on all 54 features\n",
    "print(\"Training baseline model on all 54 features...\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "baseline_results = run_lightgbm_training(\n",
    "    X=X,\n",
    "    y=y,\n",
    "    dataset_description=\"Baseline - All 54 Features\",\n",
    "    use_wandb=False,\n",
    ")\n",
    "\n",
    "# Extract baseline metrics\n",
    "baseline_model = baseline_results[\"model\"]\n",
    "baseline_X_train = baseline_results[\"X_train\"]\n",
    "baseline_X_val = baseline_results[\"X_val\"]\n",
    "baseline_y_train = baseline_results[\"y_train\"]\n",
    "baseline_y_val = baseline_results[\"y_val\"]\n",
    "baseline_y_pred_proba = baseline_results[\"y_val_proba\"]\n",
    "\n",
    "baseline_auc = roc_auc_score(baseline_y_val, baseline_y_pred_proba)\n",
    "baseline_pr_auc = average_precision_score(baseline_y_val, baseline_y_pred_proba)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BASELINE PERFORMANCE (54 features)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"ROC-AUC:  {baseline_auc:.4f}\")\n",
    "print(f\"PR-AUC:   {baseline_pr_auc:.4f}\")\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "osy6coomlgq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data types and standardize before VIF calculation\n",
    "print(\"Checking data types...\")\n",
    "print(f\"\\nData types:\\n{baseline_X_train.dtypes.value_counts()}\")\n",
    "\n",
    "# Standardize all columns to float64 for VIF calculation\n",
    "print(\"\\nStandardizing all features to float64...\")\n",
    "baseline_X_train_clean = baseline_X_train.copy()\n",
    "\n",
    "for col in baseline_X_train_clean.columns:\n",
    "    # Convert to numeric, handling nullable dtypes\n",
    "    baseline_X_train_clean[col] = pd.to_numeric(baseline_X_train_clean[col], errors='coerce').astype(np.float64)\n",
    "\n",
    "# Replace inf with nan\n",
    "baseline_X_train_clean = baseline_X_train_clean.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "print(f\"\u2713 All features converted to float64\")\n",
    "print(f\"Data types after conversion:\\n{baseline_X_train_clean.dtypes.value_counts()}\")\n",
    "\n",
    "# Check for columns with all NaN (these should be removed)\n",
    "all_nan_cols = baseline_X_train_clean.columns[baseline_X_train_clean.isna().all()].tolist()\n",
    "if all_nan_cols:\n",
    "    print(f\"\\n\u26a0 Columns with all NaN values (will be excluded from VIF): {all_nan_cols}\")\n",
    "    baseline_X_train_clean = baseline_X_train_clean.drop(columns=all_nan_cols)\n",
    "\n",
    "# Fill remaining NaN with median\n",
    "print(\"\\nFilling NaN values with column medians...\")\n",
    "for col in baseline_X_train_clean.columns:\n",
    "    if baseline_X_train_clean[col].isna().any():\n",
    "        median_val = baseline_X_train_clean[col].median()\n",
    "        if np.isnan(median_val):\n",
    "            median_val = 0.0\n",
    "        baseline_X_train_clean[col] = baseline_X_train_clean[col].fillna(median_val)\n",
    "\n",
    "print(f\"\u2713 Data preparation complete\")\n",
    "print(f\"Features ready for VIF: {len(baseline_X_train_clean.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6182da8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PHASE 2: VIF + GLOBAL MULTICOLLINEARITY ANALYSIS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PHASE 2: VIF + MULTICOLLINEARITY DETECTION\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Simple VIF calculation function (data is already cleaned)\n",
    "def calculate_vif_simple(X_df):\n",
    "    \"\"\"Calculate VIF for all features (assumes data is already clean float64).\"\"\"\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_df.columns\n",
    "    vif_values = []\n",
    "    \n",
    "    for i in range(len(X_df.columns)):\n",
    "        try:\n",
    "            vif = variance_inflation_factor(X_df.values, i)\n",
    "            # Handle inf/nan VIF values\n",
    "            if np.isinf(vif) or np.isnan(vif):\n",
    "                vif = 999999.0  # Large but finite number for inf VIF\n",
    "            vif_values.append(vif)\n",
    "        except:\n",
    "            vif_values.append(999999.0)\n",
    "    \n",
    "    vif_data[\"VIF\"] = vif_values\n",
    "    return vif_data.sort_values(\"VIF\", ascending=False)\n",
    "\n",
    "# Iterative VIF removal\n",
    "def remove_high_vif_features(X_df, threshold=10, max_iterations=15):\n",
    "    \"\"\"Iteratively remove features with VIF > threshold.\"\"\"\n",
    "    iteration = 0\n",
    "    removed_features = []\n",
    "    \n",
    "    while iteration < max_iterations:\n",
    "        vif_df = calculate_vif_simple(X_df)\n",
    "        max_vif = vif_df[\"VIF\"].max()\n",
    "        \n",
    "        # Check if all VIF values are below threshold\n",
    "        if max_vif <= threshold:\n",
    "            print(f\"\u2713 Convergence reached after {iteration} iterations\")\n",
    "            break\n",
    "        \n",
    "        # Remove feature with highest VIF\n",
    "        feature_to_remove = vif_df.iloc[0][\"Feature\"]\n",
    "        removed_features.append((feature_to_remove, max_vif))\n",
    "        \n",
    "        if max_vif >= 999999.0:\n",
    "            print(f\"  Iteration {iteration+1}: Removing '{feature_to_remove}' (VIF=inf)\")\n",
    "        else:\n",
    "            print(f\"  Iteration {iteration+1}: Removing '{feature_to_remove}' (VIF={max_vif:.2f})\")\n",
    "        \n",
    "        X_df = X_df.drop(columns=[feature_to_remove])\n",
    "        iteration += 1\n",
    "    \n",
    "    return X_df, removed_features, vif_df\n",
    "\n",
    "# Calculate initial VIF using cleaned data\n",
    "print(\"Calculating VIF for all features (using cleaned data)...\")\n",
    "initial_vif = calculate_vif_simple(baseline_X_train_clean)\n",
    "\n",
    "print(f\"\\nTop 10 features by VIF:\")\n",
    "for idx, row in initial_vif.head(10).iterrows():\n",
    "    vif_val = row['VIF']\n",
    "    if vif_val >= 999999.0:\n",
    "        print(f\"{row['Feature']:30s}  inf\")\n",
    "    else:\n",
    "        print(f\"{row['Feature']:30s}  {vif_val:.2f}\")\n",
    "\n",
    "# Iteratively remove high VIF features\n",
    "print(f\"\\nRemoving features with VIF > 10...\")\n",
    "X_train_vif, vif_removed_features, final_vif = remove_high_vif_features(\n",
    "    baseline_X_train_clean.copy(), \n",
    "    threshold=10\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"VIF REMOVAL SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Features removed: {len(vif_removed_features)}\")\n",
    "print(f\"Features remaining: {len(X_train_vif.columns)}\")\n",
    "if len(vif_removed_features) > 0:\n",
    "    print(f\"\\nRemoved features:\")\n",
    "    for feat, vif_val in vif_removed_features:\n",
    "        if vif_val >= 999999.0:\n",
    "            print(f\"  - {feat} (VIF=inf)\")\n",
    "        else:\n",
    "            print(f\"  - {feat} (VIF={vif_val:.2f})\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Store VIF-selected features\n",
    "VIF_SELECTED_FEATURES = X_train_vif.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4783af13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute global correlation matrix and hierarchical clustering\n",
    "print(\"Computing global correlation matrix across all features...\")\n",
    "corr_matrix = baseline_X_train.corr().abs()\n",
    "\n",
    "# Hierarchical clustering of features\n",
    "print(\"Performing hierarchical clustering of features...\")\n",
    "corr_condensed = squareform(1 - corr_matrix)\n",
    "linkage_matrix = linkage(corr_condensed, method='average')\n",
    "\n",
    "# Visualize dendrogram\n",
    "plt.figure(figsize=(20, 8))\n",
    "dendrogram(linkage_matrix, labels=baseline_X_train.columns, leaf_rotation=90, leaf_font_size=8)\n",
    "plt.title('Hierarchical Clustering of Features (by Correlation)', fontsize=14)\n",
    "plt.xlabel('Feature')\n",
    "plt.ylabel('Distance (1 - |correlation|)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Identify highly correlated feature pairs (correlation > 0.85)\n",
    "high_corr_pairs = []\n",
    "for i in range(len(corr_matrix.columns)):\n",
    "    for j in range(i+1, len(corr_matrix.columns)):\n",
    "        if corr_matrix.iloc[i, j] > 0.85:\n",
    "            high_corr_pairs.append({\n",
    "                'Feature1': corr_matrix.columns[i],\n",
    "                'Feature2': corr_matrix.columns[j],\n",
    "                'Correlation': corr_matrix.iloc[i, j]\n",
    "            })\n",
    "\n",
    "high_corr_df = pd.DataFrame(high_corr_pairs).sort_values('Correlation', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"HIGH CORRELATION PAIRS (|r| > 0.85)\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Found {len(high_corr_df)} feature pairs with correlation > 0.85\")\n",
    "if len(high_corr_df) > 0:\n",
    "    print(f\"\\nTop 15 pairs:\")\n",
    "    print(high_corr_df.head(15).to_string(index=False))\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b6aa1z0bt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PHASE 3: STABILITY SELECTION\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PHASE 3: STABILITY SELECTION (BOOTSTRAP)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "def stability_selection_bootstrap(X_df, y_series, n_iterations=50, sample_fraction=0.8, top_k=35):\n",
    "    \"\"\"\n",
    "    Perform stability selection using bootstrap sampling.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    X_df : pd.DataFrame\n",
    "        Feature matrix\n",
    "    y_series : pd.Series\n",
    "        Target variable\n",
    "    n_iterations : int\n",
    "        Number of bootstrap iterations\n",
    "    sample_fraction : float\n",
    "        Fraction of data to sample in each iteration\n",
    "    top_k : int\n",
    "        Number of top features to select in each iteration\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    stability_scores : pd.Series\n",
    "        Percentage of iterations each feature was selected\n",
    "    \"\"\"\n",
    "    n_samples = len(X_df)\n",
    "    sample_size = int(n_samples * sample_fraction)\n",
    "    feature_selection_counts = {col: 0 for col in X_df.columns}\n",
    "    \n",
    "    print(f\"Running {n_iterations} bootstrap iterations...\")\n",
    "    print(f\"Sample size: {sample_size:,} ({sample_fraction*100:.0f}% of data)\")\n",
    "    print(f\"Selecting top {top_k} features per iteration\\n\")\n",
    "    \n",
    "    for i in range(n_iterations):\n",
    "        if (i+1) % 20 == 0:\n",
    "            print(f\"  Iteration {i+1}/{n_iterations}...\")\n",
    "        \n",
    "        # Bootstrap sample with train/val split for early stopping\n",
    "        sample_idx = np.random.choice(n_samples, sample_size, replace=True)\n",
    "        X_sample = X_df.iloc[sample_idx]\n",
    "        y_sample = y_series.iloc[sample_idx]\n",
    "        \n",
    "        # Split bootstrap sample into train/val for early stopping\n",
    "        train_idx, val_idx = train_test_split(\n",
    "            np.arange(len(X_sample)), \n",
    "            test_size=0.2, \n",
    "            stratify=y_sample, \n",
    "            random_state=42+i\n",
    "        )\n",
    "        X_train_boot = X_sample.iloc[train_idx]\n",
    "        y_train_boot = y_sample.iloc[train_idx]\n",
    "        X_val_boot = X_sample.iloc[val_idx]\n",
    "        y_val_boot = y_sample.iloc[val_idx]\n",
    "        \n",
    "        # Train model with early stopping\n",
    "        model = lgb.LGBMClassifier(**DEFAULT_PARAMS)\n",
    "        model.fit(\n",
    "            X_train_boot, y_train_boot,\n",
    "            eval_set=[(X_val_boot, y_val_boot)],\n",
    "            eval_metric='logloss',\n",
    "            callbacks=[lgb.log_evaluation(0), lgb.early_stopping(50)]\n",
    "        )\n",
    "        \n",
    "        # Get SHAP values on the full bootstrap sample\n",
    "        explainer = shap.TreeExplainer(model)\n",
    "        shap_values = explainer.shap_values(X_sample)\n",
    "        mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "        \n",
    "        # Select top-k features by SHAP importance\n",
    "        feature_importance = pd.Series(mean_abs_shap, index=X_df.columns)\n",
    "        top_features = feature_importance.nlargest(top_k).index\n",
    "        \n",
    "        # Increment selection counts\n",
    "        for feat in top_features:\n",
    "            feature_selection_counts[feat] += 1\n",
    "    \n",
    "    # Calculate stability scores (percentage of selections)\n",
    "    stability_scores = pd.Series(feature_selection_counts) / n_iterations * 100\n",
    "    return stability_scores.sort_values(ascending=False)\n",
    "\n",
    "# Run stability selection on full feature set\n",
    "stability_scores = stability_selection_bootstrap(\n",
    "    baseline_X_train, \n",
    "    baseline_y_train, \n",
    "    n_iterations=50,\n",
    "    sample_fraction=0.8,\n",
    "    top_k=35\n",
    ")\n",
    "\n",
    "# Select features with stability >= 70%\n",
    "stability_threshold = 70\n",
    "stable_features = stability_scores[stability_scores >= stability_threshold].index.tolist()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"STABILITY SELECTION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Stability threshold: {stability_threshold}%\")\n",
    "print(f\"Features selected: {len(stable_features)}\")\n",
    "print(f\"\\nTop 20 features by stability:\")\n",
    "print(stability_scores.head(20))\n",
    "print(f\"\\nBottom 10 features by stability:\")\n",
    "print(stability_scores.tail(10))\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Store stability-selected features\n",
    "STABILITY_SELECTED_FEATURES = stable_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bkz3crbzjq9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PHASE 3B: BORUTA FEATURE SELECTION\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PHASE 3B: BORUTA ALL-RELEVANT FEATURES\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "from boruta import BorutaPy\n",
    "\n",
    "# Run Boruta on cleaned data (no NaN values)\n",
    "print(\"Running Boruta feature selection...\")\n",
    "print(\"This identifies all features that are statistically relevant (not just the best subset)\")\n",
    "\n",
    "# Create a fresh unfitted estimator for Boruta (it will fit internally)\n",
    "# Use simpler params without early stopping for Boruta's internal fitting\n",
    "boruta_params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"n_estimators\": 750,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"num_leaves\": 31,\n",
    "    \"subsample\": 0.8,\n",
    "    \"colsample_bytree\": 0.8,\n",
    "    \"random_state\": 42,\n",
    "    \"n_jobs\": -1,\n",
    "    \"verbosity\": -1,\n",
    "    \"is_unbalance\": False,\n",
    "    \"metric\": \"logloss\",\n",
    "}\n",
    "\n",
    "boruta_estimator = lgb.LGBMClassifier(**boruta_params)\n",
    "\n",
    "boruta_selector = BorutaPy(\n",
    "    estimator=boruta_estimator,\n",
    "    max_iter=100,  # Maximum iterations\n",
    "    perc=90,\n",
    "    random_state=42,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Convert to numpy arrays (handle pandas nullable dtypes)\n",
    "X_boruta = baseline_X_train_clean.values\n",
    "y_boruta = np.array(baseline_y_train, dtype=np.int32)\n",
    "\n",
    "# Fit Boruta\n",
    "boruta_selector.fit(X_boruta, y_boruta)\n",
    "\n",
    "# Get selected features\n",
    "boruta_selected_mask = boruta_selector.support_\n",
    "boruta_tentative_mask = boruta_selector.support_weak_\n",
    "BORUTA_SELECTED_FEATURES = baseline_X_train_clean.columns[boruta_selected_mask].tolist()\n",
    "boruta_tentative_features = baseline_X_train_clean.columns[boruta_tentative_mask].tolist()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"BORUTA SELECTION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Confirmed features: {len(BORUTA_SELECTED_FEATURES)}\")\n",
    "print(f\"Tentative features: {len(boruta_tentative_features)}\")\n",
    "print(f\"Rejected features: {len(baseline_X_train_clean.columns) - len(BORUTA_SELECTED_FEATURES) - len(boruta_tentative_features)}\")\n",
    "\n",
    "print(f\"\\nConfirmed features:\")\n",
    "for feat in BORUTA_SELECTED_FEATURES:\n",
    "    print(f\"  - {feat}\")\n",
    "\n",
    "if len(boruta_tentative_features) > 0:\n",
    "    print(f\"\\nTentative features:\")\n",
    "    for feat in boruta_tentative_features:\n",
    "        print(f\"  - {feat}\")\n",
    "\n",
    "print(f\"{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0qz6gqqrq94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PHASE 4: SHAP RANKING & CONSENSUS SELECTION\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PHASE 4: SHAP RANKING & CONSENSUS\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# First, calculate SHAP values for baseline model to get SHAP importance\n",
    "print(\"Computing SHAP values for feature ranking...\")\n",
    "explainer = shap.TreeExplainer(baseline_model)\n",
    "shap_values = explainer.shap_values(baseline_X_train)\n",
    "\n",
    "# Calculate mean absolute SHAP values (main effects)\n",
    "mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "shap_importance = pd.Series(mean_abs_shap, index=baseline_X_train.columns).sort_values(ascending=False)\n",
    "\n",
    "print(\"\u2713 SHAP values computed\\n\")\n",
    "print(\"Top 20 features by mean |SHAP|:\")\n",
    "print(shap_importance.head(20))\n",
    "\n",
    "# Select top features by SHAP importance\n",
    "SHAP_SELECTED_FEATURES = shap_importance.nlargest(35).index.tolist()\n",
    "print(f\"\\nSHAP-selected features (top 35): {len(SHAP_SELECTED_FEATURES)}\")\n",
    "\n",
    "# Create comprehensive comparison dataframe\n",
    "all_features = baseline_X_train.columns.tolist()\n",
    "\n",
    "comparison_df = pd.DataFrame({\n",
    "    'Feature': all_features,\n",
    "    'VIF_Selected': [f in VIF_SELECTED_FEATURES for f in all_features],\n",
    "    'Stability_Selected': [f in STABILITY_SELECTED_FEATURES for f in all_features],\n",
    "    'Boruta_Selected': [f in BORUTA_SELECTED_FEATURES for f in all_features],\n",
    "    'SHAP_Selected': [f in SHAP_SELECTED_FEATURES for f in all_features],\n",
    "})\n",
    "\n",
    "# Add numeric metrics\n",
    "comparison_df['Stability_Score'] = comparison_df['Feature'].map(stability_scores)\n",
    "comparison_df['SHAP_Importance'] = comparison_df['Feature'].map(shap_importance)\n",
    "comparison_df['VIF'] = comparison_df['Feature'].map(\n",
    "    dict(zip(initial_vif['Feature'], initial_vif['VIF']))\n",
    ")\n",
    "\n",
    "# Calculate consensus score (number of methods selecting this feature)\n",
    "# Now using 4 methods: VIF, Stability, Boruta, SHAP\n",
    "comparison_df['Consensus_Score'] = (\n",
    "    comparison_df['VIF_Selected'].astype(int) +\n",
    "    comparison_df['Stability_Selected'].astype(int) +\n",
    "    comparison_df['Boruta_Selected'].astype(int) +\n",
    "    comparison_df['SHAP_Selected'].astype(int)\n",
    ")\n",
    "\n",
    "# Sort by consensus score and SHAP importance\n",
    "comparison_df = comparison_df.sort_values(['Consensus_Score', 'SHAP_Importance'], ascending=[False, False])\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FEATURE SELECTION COMPARISON\")\n",
    "print(\"=\"*60)\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "# Select consensus features (\u22653 methods agree - majority of 4 methods)\n",
    "CONSENSUS_FEATURES = comparison_df[comparison_df['Consensus_Score'] >= 3]['Feature'].tolist()\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"CONSENSUS SELECTION SUMMARY\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Consensus threshold: \u22653 methods (majority)\")\n",
    "print(f\"Features selected: {len(CONSENSUS_FEATURES)}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Venn diagram analysis\n",
    "from matplotlib_venn import venn3, venn2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Venn 1: Stability vs Boruta vs SHAP (3 main methods)\n",
    "set_stability = set(STABILITY_SELECTED_FEATURES)\n",
    "set_boruta = set(BORUTA_SELECTED_FEATURES)\n",
    "set_shap = set(SHAP_SELECTED_FEATURES)\n",
    "venn3([set_stability, set_boruta, set_shap],\n",
    "      set_labels=('Stability', 'Boruta', 'SHAP'),\n",
    "      ax=axes[0])\n",
    "axes[0].set_title('Feature Selection Method Overlap\\n(Stability vs Boruta vs SHAP)', fontsize=12)\n",
    "\n",
    "# Venn 2: VIF vs Consensus (3+ methods)\n",
    "set_vif = set(VIF_SELECTED_FEATURES)\n",
    "consensus_features = comparison_df[comparison_df['Consensus_Score'] >= 3]['Feature'].tolist()\n",
    "set_consensus = set(consensus_features)\n",
    "venn2([set_vif, set_consensus],\n",
    "      set_labels=('VIF', 'Consensus (3+ methods)'),\n",
    "      ax=axes[1])\n",
    "axes[1].set_title('VIF vs Consensus Selection', fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flr7o0r1cke",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PHASE 5: FINAL PRUNING WITH RFECV\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PHASE 5: FINAL PRUNING WITH RFECV\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Custom LightGBM estimator for RFECV\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "\n",
    "class LGBMEstimator(BaseEstimator, ClassifierMixin):\n",
    "    \"\"\"LightGBM wrapper for sklearn compatibility with early stopping.\"\"\"\n",
    "    \n",
    "    def __init__(self, params=None):\n",
    "        self.params = params or DEFAULT_PARAMS\n",
    "        self.model = None\n",
    "        self.feature_importances_ = None\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        # Split for early stopping\n",
    "        X_train, X_val, y_train, y_val = train_test_split(\n",
    "            X, y, test_size=0.2, stratify=y, random_state=42\n",
    "        )\n",
    "        \n",
    "        self.model = lgb.LGBMClassifier(**self.params)\n",
    "        self.model.fit(\n",
    "            X_train, y_train,\n",
    "            eval_set=[(X_val, y_val)],\n",
    "            eval_metric='logloss',\n",
    "            callbacks=[lgb.log_evaluation(0), lgb.early_stopping(50)]\n",
    "        )\n",
    "        self.feature_importances_ = self.model.feature_importances_\n",
    "        return self\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        if self.model is None:\n",
    "            raise ValueError(\"Model not fitted yet\")\n",
    "        return self.model.predict_proba(X)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Prepare data for RFECV using consensus features\n",
    "X_consensus = baseline_X_train[CONSENSUS_FEATURES]\n",
    "y_consensus = baseline_y_train\n",
    "\n",
    "print(f\"Starting with {len(CONSENSUS_FEATURES)} consensus features\")\n",
    "print(f\"Target: Find optimal feature count in 25-30 range\")\n",
    "print(f\"Metric: ROC-AUC (baseline: {baseline_auc:.4f})\\n\")\n",
    "\n",
    "# Test different feature counts\n",
    "test_feature_counts = list(range(25, 36, 5)) + [len(CONSENSUS_FEATURES)]  # Test 25, 30, 35, and current count\n",
    "rfecv_results = []\n",
    "\n",
    "for n_features in test_feature_counts:\n",
    "    if n_features > len(CONSENSUS_FEATURES):\n",
    "        continue\n",
    "    \n",
    "    print(f\"Testing with {n_features} features...\")\n",
    "    \n",
    "    # Use stratified 3-fold CV for speed\n",
    "    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
    "    \n",
    "    # Manual RFE since RFECV might be slow\n",
    "    current_features = CONSENSUS_FEATURES.copy()\n",
    "    feature_ranking = []\n",
    "    \n",
    "    while len(current_features) > n_features:\n",
    "        # Train model on current features\n",
    "        X_current = baseline_X_train[current_features]\n",
    "        estimator = LGBMEstimator()\n",
    "        estimator.fit(X_current, baseline_y_train)\n",
    "        \n",
    "        # Get feature importances\n",
    "        importances = pd.Series(\n",
    "            estimator.feature_importances_,\n",
    "            index=current_features\n",
    "        ).sort_values()\n",
    "        \n",
    "        # Remove least important feature\n",
    "        least_important = importances.index[0]\n",
    "        current_features.remove(least_important)\n",
    "        feature_ranking.append(least_important)\n",
    "    \n",
    "    # Evaluate with CV using ROC-AUC\n",
    "    cv_scores = []\n",
    "    for train_idx, val_idx in cv.split(baseline_X_train, baseline_y_train):\n",
    "        X_train_cv = baseline_X_train.iloc[train_idx][current_features]\n",
    "        y_train_cv = baseline_y_train.iloc[train_idx]\n",
    "        X_val_cv = baseline_X_train.iloc[val_idx][current_features]\n",
    "        y_val_cv = baseline_y_train.iloc[val_idx]\n",
    "        \n",
    "        estimator = LGBMEstimator()\n",
    "        estimator.fit(X_train_cv, y_train_cv)\n",
    "        y_pred_proba = estimator.predict_proba(X_val_cv)[:, 1]\n",
    "        \n",
    "        # Use ROC-AUC instead of PR-AUC\n",
    "        roc_auc = roc_auc_score(y_val_cv, y_pred_proba)\n",
    "        cv_scores.append(roc_auc)\n",
    "    \n",
    "    mean_score = np.mean(cv_scores)\n",
    "    std_score = np.std(cv_scores)\n",
    "    \n",
    "    rfecv_results.append({\n",
    "        'n_features': n_features,\n",
    "        'selected_features': current_features,\n",
    "        'mean_roc_auc': mean_score,\n",
    "        'std_roc_auc': std_score\n",
    "    })\n",
    "    \n",
    "    print(f\"  \u2192 ROC-AUC: {mean_score:.4f} \u00b1 {std_score:.4f}\")\n",
    "\n",
    "# Select optimal feature count\n",
    "rfecv_df = pd.DataFrame(rfecv_results).sort_values('mean_roc_auc', ascending=False)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"RFECV RESULTS\")\n",
    "print(f\"{'='*60}\")\n",
    "print(rfecv_df[['n_features', 'mean_roc_auc', 'std_roc_auc']].to_string(index=False))\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Select best performing feature set\n",
    "optimal_result = rfecv_df.iloc[0]\n",
    "FINAL_SELECTED_FEATURES = optimal_result['selected_features']\n",
    "optimal_n_features = optimal_result['n_features']\n",
    "\n",
    "print(f\"Optimal feature count: {optimal_n_features}\")\n",
    "print(f\"Expected ROC-AUC: {optimal_result['mean_roc_auc']:.4f} \u00b1 {optimal_result['std_roc_auc']:.4f}\")\n",
    "print(f\"\\nFinal selected features:\")\n",
    "for i, feat in enumerate(FINAL_SELECTED_FEATURES, 1):\n",
    "    print(f\"  {i:2d}. {feat}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blt6vlx4pqs",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PHASE 8: XAI INTERPRETABILITY CHECKS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"PHASE 8: INTERPRETABILITY & MONOTONICITY CHECKS\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Train final model on selected features\n",
    "print(f\"Training final model on {len(FINAL_SELECTED_FEATURES)} selected features...\")\n",
    "X_final = X[FINAL_SELECTED_FEATURES]\n",
    "\n",
    "final_model_results = run_lightgbm_training(\n",
    "    X=X_final,\n",
    "    y=y,\n",
    "    dataset_description=f\"Final Model - {len(FINAL_SELECTED_FEATURES)} Features\",\n",
    "    use_wandb=False,\n",
    ")\n",
    "\n",
    "final_model = final_model_results[\"model\"]\n",
    "X_final_train = final_model_results[\"X_train\"]\n",
    "X_final_val = final_model_results[\"X_val\"]\n",
    "y_final_train = final_model_results[\"y_train\"]\n",
    "y_final_val = final_model_results[\"y_val\"]\n",
    "y_final_pred_proba = final_model_results[\"y_val_proba\"]\n",
    "\n",
    "final_pr_auc = average_precision_score(y_final_val, y_final_pred_proba)\n",
    "final_roc_auc = roc_auc_score(y_final_val, y_final_pred_proba)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FINAL MODEL PERFORMANCE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Features: {len(FINAL_SELECTED_FEATURES)}\")\n",
    "print(f\"ROC-AUC:  {final_roc_auc:.4f} (baseline: {baseline_auc:.4f})\")\n",
    "print(f\"PR-AUC:   {final_pr_auc:.4f} (baseline: {baseline_pr_auc:.4f})\")\n",
    "print(f\"\u0394 ROC-AUC: {final_roc_auc - baseline_auc:+.4f}\")\n",
    "print(f\"\u0394 PR-AUC:  {final_pr_auc - baseline_pr_auc:+.4f}\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Compute SHAP values for final model\n",
    "print(\"Computing SHAP values for interpretability analysis...\")\n",
    "final_explainer = shap.TreeExplainer(final_model)\n",
    "final_shap_values = final_explainer.shap_values(X_final_train)\n",
    "\n",
    "# SHAP summary plot (bar)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "shap.summary_plot(final_shap_values, X_final_train, plot_type=\"bar\", show=False, max_display=20)\n",
    "axes[0].set_title(f\"Top 20 Features by SHAP Importance ({len(FINAL_SELECTED_FEATURES)} features)\", fontsize=12)\n",
    "\n",
    "# SHAP summary plot (beeswarm)\n",
    "shap.summary_plot(final_shap_values, X_final_train, show=False, max_display=20)\n",
    "axes[1].set_title(\"SHAP Value Distribution (Top 20 Features)\", fontsize=12)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Check feature group diversity\n",
    "from credit_risk_xai.config import FEATURE_GROUPS_BY_SOURCE, CATEGORICAL_COLS\n",
    "\n",
    "feature_group_counts = {}\n",
    "for group_name, group_features in FEATURE_GROUPS_BY_SOURCE.items():\n",
    "    count = len([f for f in FINAL_SELECTED_FEATURES if f in group_features])\n",
    "    if count > 0:\n",
    "        feature_group_counts[group_name] = count\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FEATURE GROUP DIVERSITY\")\n",
    "print(f\"{'='*60}\")\n",
    "for group, count in sorted(feature_group_counts.items(), key=lambda x: x[1], reverse=True):\n",
    "    pct = count / len(FINAL_SELECTED_FEATURES) * 100\n",
    "    print(f\"{group:20s}: {count:2d} features ({pct:5.1f}%)\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Flag potentially problematic features for manual review\n",
    "print(\"Checking for counter-intuitive relationships...\")\n",
    "counter_intuitive_flags = []\n",
    "\n",
    "# Calculate correlation with target for numeric features only\n",
    "numeric_features = [f for f in FINAL_SELECTED_FEATURES if f not in CATEGORICAL_COLS]\n",
    "X_final_train_numeric = X_final_train[numeric_features]\n",
    "target_correlations = X_final_train_numeric.corrwith(y_final_train)\n",
    "\n",
    "for feat in numeric_features[:20]:  # Check top 20 numeric features\n",
    "    # Get SHAP dependence\n",
    "    feat_idx = list(X_final_train.columns).index(feat)\n",
    "    shap_values_feat = final_shap_values[:, feat_idx]\n",
    "    \n",
    "    # Convert feature values to numeric (handle any remaining categorical encodings)\n",
    "    feature_values = pd.to_numeric(X_final_train[feat], errors='coerce').fillna(0).values\n",
    "    \n",
    "    # Check for monotonicity using correlation\n",
    "    try:\n",
    "        shap_feature_corr = np.corrcoef(feature_values, shap_values_feat)[0, 1]\n",
    "        \n",
    "        # Flag if SHAP relationship is weak or counter to expected\n",
    "        if abs(shap_feature_corr) < 0.3:\n",
    "            counter_intuitive_flags.append({\n",
    "                'Feature': feat,\n",
    "                'SHAP_Feature_Corr': shap_feature_corr,\n",
    "                'Target_Corr': target_correlations[feat],\n",
    "                'Flag': 'Non-monotonic relationship'\n",
    "            })\n",
    "    except:\n",
    "        # Skip features that cause errors\n",
    "        continue\n",
    "\n",
    "if len(counter_intuitive_flags) > 0:\n",
    "    flags_df = pd.DataFrame(counter_intuitive_flags)\n",
    "    print(f\"\\n\u26a0 Features flagged for manual review ({len(flags_df)}):\")\n",
    "    print(flags_df.to_string(index=False))\n",
    "else:\n",
    "    print(\"\u2713 No concerning non-monotonic relationships detected\")\n",
    "\n",
    "print(f\"\\n{'='*60}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f81eeab",
   "metadata": {},
   "source": [
    "# Summary & Next Steps\n",
    "\n",
    "## Feature Selection Pipeline Results\n",
    "\n",
    "This notebook implements a streamlined 5-phase feature selection pipeline:\n",
    "\n",
    "1. **Phase 1: Baseline Model** (54 features)\n",
    "2. **Phase 2: VIF Multicollinearity Removal** (max 15 iterations)\n",
    "3. **Phase 3: Stability Selection** (50 bootstrap iterations, top 35 per iteration)\n",
    "4. **Phase 4: SHAP Ranking & Consensus** (2+ method agreement)\n",
    "5. **Phase 5: Final Pruning with RFECV** (target: 25-30 features)\n",
    "\n",
    "## Key Changes from Previous Version\n",
    "\n",
    "- **Added 14 features**: OCF (5), Leverage (2), Macro (5), Categorical (2)\n",
    "- **Starting features**: 54 (40 original + 14 re-added post-leakage fix)\n",
    "- **Target**: 25-30 final features (46-54% reduction)\n",
    "- **Performance target**: PR-AUC \u2265 0.6450 (maintain within 0.005 of 0.6500 baseline)\n",
    "\n",
    "## Optimizations for Speed\n",
    "\n",
    "- Bootstrap iterations: 100 \u2192 50 (2x faster)\n",
    "- VIF max iterations: 20 \u2192 15\n",
    "- Removed: Boruta, SHAP interactions, extensive strategy testing\n",
    "- **Estimated speedup**: 2-3x faster execution\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Update `config.py` with final selected features\n",
    "2. Update `engineered_features.md` documentation\n",
    "3. Re-train production model with new feature set\n",
    "4. Validate no data leakage patterns remain (check SHAP for \"all YoY = 0\" clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hs0lf271ol",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# PERFORMANCE COMPARISON ACROSS METHODS\n",
    "# ========================================\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"FEATURE SELECTION METHOD COMPARISON\")\n",
    "print(f\"{'='*60}\\n\")\n",
    "\n",
    "# Helper function to evaluate a feature set\n",
    "def evaluate_feature_set(features, X_data, y_data, description):\n",
    "    \"\"\"Train and evaluate model on given feature set.\"\"\"\n",
    "    X_subset = X_data[features]\n",
    "    \n",
    "    results = run_lightgbm_training(\n",
    "        X=X_subset,\n",
    "        y=y_data,\n",
    "        dataset_description=description,\n",
    "        use_wandb=False,\n",
    "    )\n",
    "    \n",
    "    y_pred_proba = results[\"y_val_proba\"]\n",
    "    y_val = results[\"y_val\"]\n",
    "    \n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    pr_auc = average_precision_score(y_val, y_pred_proba)\n",
    "    \n",
    "    return {\n",
    "        'n_features': len(features),\n",
    "        'roc_auc': roc_auc,\n",
    "        'pr_auc': pr_auc,\n",
    "        'description': description\n",
    "    }\n",
    "\n",
    "# Collect performance for each method\n",
    "print(\"Evaluating feature selection methods...\\n\")\n",
    "\n",
    "comparison_results = []\n",
    "\n",
    "# 1. Baseline (all 54 features) - already computed\n",
    "comparison_results.append({\n",
    "    'Method': 'Baseline',\n",
    "    'n_features': 54,\n",
    "    'roc_auc': baseline_auc,\n",
    "    'pr_auc': baseline_pr_auc,\n",
    "    'description': 'All features (no selection)'\n",
    "})\n",
    "\n",
    "# 2. VIF-selected features\n",
    "print(\"Evaluating VIF-selected features...\")\n",
    "vif_perf = evaluate_feature_set(VIF_SELECTED_FEATURES, X, y, \"VIF-Selected\")\n",
    "comparison_results.append({\n",
    "    'Method': 'VIF',\n",
    "    'n_features': vif_perf['n_features'],\n",
    "    'roc_auc': vif_perf['roc_auc'],\n",
    "    'pr_auc': vif_perf['pr_auc'],\n",
    "    'description': 'VIF < 10 (multicollinearity removal)'\n",
    "})\n",
    "\n",
    "# 3. Stability-selected features\n",
    "print(\"Evaluating Stability-selected features...\")\n",
    "stab_perf = evaluate_feature_set(STABILITY_SELECTED_FEATURES, X, y, \"Stability-Selected\")\n",
    "comparison_results.append({\n",
    "    'Method': 'Stability',\n",
    "    'n_features': stab_perf['n_features'],\n",
    "    'roc_auc': stab_perf['roc_auc'],\n",
    "    'pr_auc': stab_perf['pr_auc'],\n",
    "    'description': 'Bootstrap stability \u226570%'\n",
    "})\n",
    "\n",
    "# 4. Boruta-selected features\n",
    "print(\"Evaluating Boruta-selected features...\")\n",
    "boruta_perf = evaluate_feature_set(BORUTA_SELECTED_FEATURES, X, y, \"Boruta-Selected\")\n",
    "comparison_results.append({\n",
    "    'Method': 'Boruta',\n",
    "    'n_features': boruta_perf['n_features'],\n",
    "    'roc_auc': boruta_perf['roc_auc'],\n",
    "    'pr_auc': boruta_perf['pr_auc'],\n",
    "    'description': 'All-relevant features (confirmed)'\n",
    "})\n",
    "\n",
    "# 5. SHAP-selected features\n",
    "print(\"Evaluating SHAP-selected features...\")\n",
    "shap_perf = evaluate_feature_set(SHAP_SELECTED_FEATURES, X, y, \"SHAP-Selected\")\n",
    "comparison_results.append({\n",
    "    'Method': 'SHAP',\n",
    "    'n_features': shap_perf['n_features'],\n",
    "    'roc_auc': shap_perf['roc_auc'],\n",
    "    'pr_auc': shap_perf['pr_auc'],\n",
    "    'description': 'Top 35 by SHAP importance'\n",
    "})\n",
    "\n",
    "# 6. Consensus features\n",
    "print(\"Evaluating Consensus features...\")\n",
    "cons_perf = evaluate_feature_set(CONSENSUS_FEATURES, X, y, \"Consensus\")\n",
    "comparison_results.append({\n",
    "    'Method': 'Consensus',\n",
    "    'n_features': cons_perf['n_features'],\n",
    "    'roc_auc': cons_perf['roc_auc'],\n",
    "    'pr_auc': cons_perf['pr_auc'],\n",
    "    'description': '\u22653 methods agree'\n",
    "})\n",
    "\n",
    "# 7. Final RFECV (25 features) - from RFECV results\n",
    "rfecv_25 = rfecv_df[rfecv_df['n_features'] == 25].iloc[0]\n",
    "comparison_results.append({\n",
    "    'Method': 'RFECV-25',\n",
    "    'n_features': 25,\n",
    "    'roc_auc': rfecv_25['mean_roc_auc'],\n",
    "    'pr_auc': None,  # Not computed during RFECV\n",
    "    'description': 'RFECV optimized (25 features)'\n",
    "})\n",
    "\n",
    "# 8. Final selected (optimal from RFECV) - already computed in Phase 8\n",
    "comparison_results.append({\n",
    "    'Method': 'Final',\n",
    "    'n_features': len(FINAL_SELECTED_FEATURES),\n",
    "    'roc_auc': final_roc_auc,\n",
    "    'pr_auc': final_pr_auc,\n",
    "    'description': f'RFECV optimized ({len(FINAL_SELECTED_FEATURES)} features)'\n",
    "})\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_table = pd.DataFrame(comparison_results)\n",
    "\n",
    "# Calculate deltas from baseline\n",
    "comparison_table['\u0394 ROC-AUC'] = comparison_table['roc_auc'] - baseline_auc\n",
    "comparison_table['\u0394 PR-AUC'] = comparison_table['pr_auc'] - baseline_pr_auc\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"PERFORMANCE COMPARISON TABLE\")\n",
    "print(f\"{'='*80}\")\n",
    "print(comparison_table[['Method', 'n_features', 'roc_auc', 'pr_auc', '\u0394 ROC-AUC', '\u0394 PR-AUC']].to_string(index=False))\n",
    "print(f\"{'='*80}\\n\")\n",
    "\n",
    "# Visualization: Feature count vs Performance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Plot 1: ROC-AUC vs Feature Count\n",
    "ax1 = axes[0]\n",
    "for idx, row in comparison_table.iterrows():\n",
    "    color = 'red' if row['Method'] == 'Final' else 'blue' if row['Method'] == 'Baseline' else 'gray'\n",
    "    size = 150 if row['Method'] in ['Final', 'Baseline'] else 80\n",
    "    alpha = 1.0 if row['Method'] in ['Final', 'Baseline'] else 0.6\n",
    "    \n",
    "    ax1.scatter(row['n_features'], row['roc_auc'], \n",
    "               s=size, c=color, alpha=alpha, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    # Add labels for key points\n",
    "    if row['Method'] in ['Final', 'Baseline', 'RFECV-25']:\n",
    "        ax1.annotate(f\"{row['Method']}\\n({row['n_features']} feat)\", \n",
    "                    (row['n_features'], row['roc_auc']),\n",
    "                    xytext=(10, -10), textcoords='offset points',\n",
    "                    fontsize=9, ha='left',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "ax1.axhline(y=baseline_auc, color='blue', linestyle='--', alpha=0.5, label='Baseline')\n",
    "ax1.set_xlabel('Number of Features', fontsize=12)\n",
    "ax1.set_ylabel('ROC-AUC', fontsize=12)\n",
    "ax1.set_title('ROC-AUC vs Feature Count', fontsize=14, fontweight='bold')\n",
    "ax1.grid(True, alpha=0.3)\n",
    "ax1.legend()\n",
    "\n",
    "# Plot 2: PR-AUC vs Feature Count (excluding None values)\n",
    "ax2 = axes[1]\n",
    "pr_auc_data = comparison_table[comparison_table['pr_auc'].notna()]\n",
    "\n",
    "for idx, row in pr_auc_data.iterrows():\n",
    "    color = 'red' if row['Method'] == 'Final' else 'blue' if row['Method'] == 'Baseline' else 'gray'\n",
    "    size = 150 if row['Method'] in ['Final', 'Baseline'] else 80\n",
    "    alpha = 1.0 if row['Method'] in ['Final', 'Baseline'] else 0.6\n",
    "    \n",
    "    ax2.scatter(row['n_features'], row['pr_auc'], \n",
    "               s=size, c=color, alpha=alpha, edgecolors='black', linewidth=1.5)\n",
    "    \n",
    "    # Add labels for key points\n",
    "    if row['Method'] in ['Final', 'Baseline']:\n",
    "        ax2.annotate(f\"{row['Method']}\\n({row['n_features']} feat)\", \n",
    "                    (row['n_features'], row['pr_auc']),\n",
    "                    xytext=(10, -10), textcoords='offset points',\n",
    "                    fontsize=9, ha='left',\n",
    "                    bbox=dict(boxstyle='round,pad=0.3', facecolor='yellow', alpha=0.7))\n",
    "\n",
    "ax2.axhline(y=baseline_pr_auc, color='blue', linestyle='--', alpha=0.5, label='Baseline')\n",
    "ax2.set_xlabel('Number of Features', fontsize=12)\n",
    "ax2.set_ylabel('PR-AUC', fontsize=12)\n",
    "ax2.set_title('PR-AUC vs Feature Count', fontsize=14, fontweight='bold')\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Summary statistics\n",
    "print(\"\\nKEY INSIGHTS:\")\n",
    "print(f\"\u2022 Baseline (54 features): ROC-AUC={baseline_auc:.4f}, PR-AUC={baseline_pr_auc:.4f}\")\n",
    "print(f\"\u2022 Final ({len(FINAL_SELECTED_FEATURES)} features): ROC-AUC={final_roc_auc:.4f}, PR-AUC={final_pr_auc:.4f}\")\n",
    "print(f\"\u2022 Feature reduction: {54 - len(FINAL_SELECTED_FEATURES)} features removed ({(54 - len(FINAL_SELECTED_FEATURES))/54*100:.1f}%)\")\n",
    "print(f\"\u2022 Performance change: ROC-AUC {final_roc_auc - baseline_auc:+.4f}, PR-AUC {final_pr_auc - baseline_pr_auc:+.4f}\")\n",
    "print(f\"\u2022 Most selective method: {comparison_table.loc[comparison_table['n_features'].idxmin(), 'Method']} ({comparison_table['n_features'].min()} features)\")\n",
    "print(f\"\u2022 Best ROC-AUC: {comparison_table['roc_auc'].max():.4f} ({comparison_table.loc[comparison_table['roc_auc'].idxmax(), 'Method']})\")\n",
    "print(f\"\\n{'='*80}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cdc556",
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_SELECTED_FEATURES"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}