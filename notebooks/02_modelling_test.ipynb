{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c5f8c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, classification_report, confusion_matrix\n",
    "\n",
    "PROJ_ROOT = Path.cwd().parent\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJ_ROOT))\n",
    "\n",
    "from credit_risk_xai.config import FEATURE_CACHE_PATH\n",
    "from credit_risk_xai.features.engineer import prepare_modeling_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e09cbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and filter data\n",
    "MIN_REVENUE_KSEK = 1_000\n",
    "df = pd.read_parquet(FEATURE_CACHE_PATH)\n",
    "df = df[(df[\"ser_aktiv\"] == 1) & (df[\"rr01_ntoms\"] >= MIN_REVENUE_KSEK)]\n",
    "X, y = prepare_modeling_data(df)\n",
    "\n",
    "print(f\"Features: {X.shape[1]} | Samples: {len(X):,}\")\n",
    "print(f\"Target distribution:\\n{y.value_counts()}\")\n",
    "print(f\"Imbalance: {(y==0).sum()/(y==1).sum():.1f}:1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ilr63x4ki4k",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/val split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "print(f\"Train: {len(X_train):,} | Val: {len(X_val):,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dl9w9d98jqe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train LightGBM\n",
    "scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "model = lgb.LGBMClassifier(\n",
    "    n_estimators=10000,\n",
    "    learning_rate=0.05,\n",
    "    num_leaves=31,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    scale_pos_weight=scale_pos_weight,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    verbose=-1\n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "    eval_metric='auc',\n",
    "    callbacks=[lgb.early_stopping(50, verbose=True), lgb.log_evaluation(100)]\n",
    ")\n",
    "\n",
    "print(f\"\\nBest iteration: {model.best_iteration_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "htjbzby6qel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate\n",
    "y_pred = model.predict(X_val)\n",
    "y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "auc = roc_auc_score(y_val, y_pred_proba)\n",
    "pr_auc = average_precision_score(y_val, y_pred_proba)\n",
    "\n",
    "print(f\"AUC: {auc:.4f}\")\n",
    "print(f\"PR-AUC: {pr_auc:.4f}\\n\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_val, y_pred))\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yijb3okzet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': model.feature_name_,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"Top 20 Features:\")\n",
    "print(importance_df.head(20).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aymh1btlp4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SHAP analysis (optional - uncomment to run)\n",
    "# import shap\n",
    "# sample_size = min(5000, len(X_val))\n",
    "# X_sample = X_val.sample(n=sample_size, random_state=42)\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_sample)\n",
    "# if isinstance(shap_values, list):\n",
    "#     shap_values = shap_values[1]\n",
    "# shap.summary_plot(shap_values, X_sample)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
