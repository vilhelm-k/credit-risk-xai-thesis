{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "331555c8",
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import glob\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import xgboost as xgb\n",
        "from xgboost.callback import EarlyStopping\n",
        "import lightgbm as lgb\n",
        "import time\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "if str(PROJECT_ROOT) not in sys.path:\n",
        "    sys.path.append(str(PROJECT_ROOT))\n",
        "\n",
        "from src.config import (\n",
        "    COLS_TO_LOAD,\n",
        "    FEATURES_FOR_MODEL,\n",
        "    MACRO_FEATURE_NAMES,\n",
        "    MACRO_FEATURE_PRIORITIES,\n",
        "    SME_CATEGORIES,\n",
        "    CATEGORICAL_COLS,\n",
        "    MIN_REVENUE_KSEK,\n",
        ")\n",
        "from src.macro_features import load_macro_data\n",
        "from src.feature_engineering import (\n",
        "    create_engineered_features,\n",
        "    apply_modeling_filters,\n",
        "    create_target_variable,\n",
        "    prepare_modeling_data,\n",
        ")\n",
        "from src.data_loading import load_serrano_base\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "3c6f2f46",
      "metadata": {},
      "outputs": [],
      "source": [
        "# COLUMN DEFINITIONS\n",
        "# ============================================================================\n",
        "\n",
        "from src.config import (\n",
        "    BASE_COLS as base_cols,\n",
        "    NY_COLS as ny_cols,\n",
        "    KEPT_RAW_COLS as kept_raw_cols,\n",
        "    RR_SOURCE_COLS as rr_source_cols,\n",
        "    BR_SOURCE_COLS as br_source_cols,\n",
        "    COLS_TO_LOAD as cols_to_load,\n",
        "    RATIO_FEATURE_NAMES as ratio_feature_names,\n",
        "    LIQUIDITY_EFFICIENCY_FEATURES as liquidity_efficiency_features,\n",
        "    TREND_FEATURE_NAMES as trend_feature_names,\n",
        "    CRISIS_FEATURE_NAMES as crisis_feature_names,\n",
        "    MACRO_FEATURE_NAMES as macro_feature_names,\n",
        "    MACRO_FEATURE_PRIORITIES as macro_feature_priorities,\n",
        "    ENGINEERED_FEATURE_NAMES as engineered_feature_names,\n",
        "    CATEGORICAL_COLS as categorical_cols,\n",
        "    SME_CATEGORIES as sme_categories,\n",
        "    FEATURES_FOR_MODEL as features_for_model,\n",
        ")\n",
        "\n",
        "print(f\"Columns to load: {len(cols_to_load)}\")\n",
        "print(f\"Total engineered features registered: {len(engineered_feature_names)}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dkdcg1rbthi",
      "metadata": {},
      "outputs": [],
      "source": [
        "# DATA LOADING AND MACRO PREP\n",
        "# ============================================================================\n",
        "\n",
        "processed_serrano_path = PROJECT_ROOT / 'processed_serrano.parquet'\n",
        "macro_summary_path = PROJECT_ROOT / 'macro_data' / 'macro_summary.parquet'\n",
        "\n",
        "macro_df = load_macro_data(cache_path=macro_summary_path)\n",
        "print(f\"Macro summary shape: {macro_df.shape}\")\n",
        "\n",
        "serrano_base = load_serrano_base(processed_serrano_path)\n",
        "print(f\"Base Serrano shape: {serrano_base.shape}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "8eeb0f3b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing Stata_2025/serrano*.dta files...\n",
            "Minimal filtering: ser_jurform=49 only\n",
            "Preserving all revenue levels and activity statuses for company history\n",
            "  Processing 1/10: serrano6.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 2/10: serrano7.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 3/10: serrano5.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 4/10: serrano4.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 5/10: serrano1.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 6/10: serrano3.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 7/10: serrano2.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 8/10: serrano9.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 9/10: serrano8.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Processing 10/10: serrano10.dta\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:79: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['company_age'] = df['ser_year'] - df['ser_regdat'].dt.year\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:80: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['credit_event'] = ((df['bol_konkurs'] == 1) | (df['bol_q80dat'].notna())).astype('int8')\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:81: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
            "  df['sme_category'] = df.apply(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Concatenating...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat(df_list, ignore_index=True)\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat(df_list, ignore_index=True)\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat(df_list, ignore_index=True)\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat(df_list, ignore_index=True)\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat(df_list, ignore_index=True)\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat(df_list, ignore_index=True)\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_12132/4006631737.py:108: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  result = pd.concat(df_list, ignore_index=True)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Writing to Parquet...\n",
            "\n",
            "Saved to processed_serrano.parquet!\n",
            "  Rows before: 16,228,555\n",
            "  Rows after: 12,473,668\n",
            "  Reduction: 23.1%\n",
            "Loading processed_serrano.parquet...\n",
            "  Loaded! Shape: (12473668, 116)\n",
            "  Memory usage: 11.13 GB\n",
            "\n",
            "Final shape: (12473668, 116)\n",
            "Categorical columns: ['sme_category']\n",
            "\n",
            "Memory usage: 11.13 GB\n"
          ]
        }
      ],
      "source": [
        "feature_cache_path = PROJECT_ROOT / 'processed_serrano_features.parquet'\n",
        "\n",
        "serrano_df = create_engineered_features(serrano_base, macro_df=macro_df)\n",
        "serrano_df.to_parquet(feature_cache_path, index=False)\n",
        "\n",
        "print(f\"Engineered features shape: {serrano_df.shape}\")\n",
        "print(f\"Engineered columns added: {len([c for c in serrano_df.columns if c in engineered_feature_names])}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "qprdf57578",
      "metadata": {},
      "outputs": [],
      "source": [
        "# FEATURE ENGINEERING EXECUTION PLACEHOLDER\n",
        "# (Functionality provided by src.feature_engineering module.)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "583a86cd",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Remapped ser_stklf: 9 → None\n",
            "ser_stklf missing values: 0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_3622/2517411551.py:85: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  df[f'{col}_yoy_pct'] = group[col].pct_change()\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_3622/2517411551.py:85: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  df[f'{col}_yoy_pct'] = group[col].pct_change()\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_3622/2517411551.py:85: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  df[f'{col}_yoy_pct'] = group[col].pct_change()\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_3622/2517411551.py:90: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  df['ratio_cash_liquidity_yoy_pct'] = group['ratio_cash_liquidity'].pct_change()\n",
            "/var/folders/5c/7nyvkw450d38pmzqgbgq75wc0000gn/T/ipykernel_3622/2517411551.py:92: FutureWarning: The default fill_method='ffill' in SeriesGroupBy.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
            "  df['ratio_ebit_interest_cov_yoy_pct'] = group['ratio_ebit_interest_cov'].pct_change()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dropped raw source columns after engineering: 76 columns\n",
            "\n",
            "Applying modeling filters:\n",
            "  - ser_aktiv == 1 (active companies)\n",
            "  - rr01_ntoms >= 1,000 kSEK\n",
            "  Rows: 12,473,668 → 5,006,332 (40.1% retained)\n",
            "\n",
            "Original data: 5,006,332 rows\n",
            "Valid rows (have next year outcome): 4,413,099 rows\n",
            "Rows excluded: 593,233\n",
            "\n",
            "Data ready for modeling:\n",
            "Shape of X (features): (4413099, 91)\n",
            "Shape of y (target): (4413099,)\n",
            "\n",
            "Target distribution (credit events in NEXT year):\n",
            "target_next_year\n",
            "0    4393627\n",
            "1      19472\n",
            "Name: count, dtype: Int64\n",
            "\n",
            "Class imbalance ratio: 225.6:1\n",
            "\n",
            "Serrano_df retained for lookups: (5006332, 100)\n",
            "Memory usage: 3.75 GB\n"
          ]
        }
      ],
      "source": [
        "filtered_df = apply_modeling_filters(serrano_df, min_revenue_ksek=MIN_REVENUE_KSEK)\n",
        "\n",
        "valid_mask = create_target_variable(filtered_df)\n",
        "\n",
        "X, y = prepare_modeling_data(filtered_df, valid_mask)\n",
        "\n",
        "print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
        "print(f\"Memory usage: {filtered_df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "ilguh9ihmog",
      "metadata": {},
      "outputs": [],
      "source": [
        "# EXPLORATORY DATA ANALYSIS FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def analyze_class_imbalance_by_revenue(df, valid_mask, thresholds=[1000, 5_000, 10_000, 50_000, 100_000, 1_000_000]):\n",
        "    \"\"\"Analyze class imbalance across different revenue thresholds\"\"\"\n",
        "    print(f\"\\n1. Class Imbalance by Revenue Threshold (kSEK = thousands SEK)\")\n",
        "    print(\"-\" * 90)\n",
        "    print(f\"{'Min Revenue (kSEK)':<20} {'Total Rows':<15} {'Credit Events':<15} {'Event Rate %':<15} {'Imbalance':<15}\")\n",
        "    print(\"-\" * 90)\n",
        "    \n",
        "    for threshold in thresholds:\n",
        "        mask = (df['rr01_ntoms'] >= threshold) & valid_mask\n",
        "        n_samples = mask.sum()\n",
        "        n_events = df.loc[mask, 'target_next_year'].sum()\n",
        "        n_no_events = (df.loc[mask, 'target_next_year'] == 0).sum()\n",
        "        \n",
        "        if n_events > 0:\n",
        "            event_rate = 100 * n_events / n_samples\n",
        "            imbalance = n_no_events / n_events\n",
        "            print(f\"{threshold:<20,} {n_samples:<15,} {n_events:<15,} {event_rate:<15.3f} {imbalance:<15.1f}:1\")\n",
        "        else:\n",
        "            print(f\"{threshold:<20,} {n_samples:<15,} {0:<15,} {'0.000':<15} {'N/A':<15}\")\n",
        "\n",
        "\n",
        "def analyze_class_imbalance_by_year(df, valid_mask):\n",
        "    \"\"\"Analyze class imbalance across different years\"\"\"\n",
        "    print(f\"\\n2. Class Imbalance by Year\")\n",
        "    print(\"-\" * 90)\n",
        "    print(f\"{'Year':<10} {'Total Rows':<15} {'Credit Events':<15} {'Event Rate %':<15} {'Imbalance':<15}\")\n",
        "    print(\"-\" * 90)\n",
        "    \n",
        "    years = sorted(df.loc[valid_mask, 'ser_year'].dropna().unique())\n",
        "    \n",
        "    for year in years:\n",
        "        mask = (df['ser_year'] == year) & valid_mask\n",
        "        n_samples = mask.sum()\n",
        "        n_events = df.loc[mask, 'target_next_year'].sum()\n",
        "        n_no_events = (df.loc[mask, 'target_next_year'] == 0).sum()\n",
        "        \n",
        "        if n_events > 0:\n",
        "            event_rate = 100 * n_events / n_samples\n",
        "            imbalance = n_no_events / n_events\n",
        "            print(f\"{int(year):<10} {n_samples:<15,} {n_events:<15,} {event_rate:<15.3f} {imbalance:<15.1f}:1\")\n",
        "\n",
        "\n",
        "def analyze_class_imbalance_by_sme(df, valid_mask):\n",
        "    \"\"\"Analyze class imbalance across SME categories\"\"\"\n",
        "    print(f\"\\n3. STRICT EU SME Classification (employees AND revenue/assets)\")\n",
        "    print(\"-\" * 90)\n",
        "    print(f\"{'SME Category':<40} {'Total Rows':<15} {'Credit Events':<15} {'Event Rate %':<15} {'Imbalance':<15}\")\n",
        "    print(\"-\" * 90)\n",
        "    \n",
        "    for category in sme_categories:\n",
        "        mask = (df['sme_category'] == category) & valid_mask\n",
        "        n_samples = mask.sum()\n",
        "        n_events = df.loc[mask, 'target_next_year'].sum()\n",
        "        n_no_events = (df.loc[mask, 'target_next_year'] == 0).sum()\n",
        "        \n",
        "        if n_samples > 0 and n_events > 0:\n",
        "            event_rate = 100 * n_events / n_samples\n",
        "            imbalance = n_no_events / n_events\n",
        "            print(f\"{category:<40} {n_samples:<15,} {n_events:<15,} {event_rate:<15.3f} {imbalance:<15.1f}:1\")\n",
        "        elif n_samples > 0:\n",
        "            print(f\"{category:<40} {n_samples:<15,} {0:<15,} {'0.000':<15} {'N/A':<15}\")\n",
        "\n",
        "\n",
        "def generate_eda_report(df, valid_mask):\n",
        "    \"\"\"Generate complete EDA report\"\"\"\n",
        "    print(\"DATA EXPLORATION: Revenue, Years, and SME Classification\")\n",
        "    print(\"=\"*90)\n",
        "    \n",
        "    analyze_class_imbalance_by_revenue(df, valid_mask)\n",
        "    analyze_class_imbalance_by_year(df, valid_mask)\n",
        "    analyze_class_imbalance_by_sme(df, valid_mask)\n",
        "    \n",
        "    print(\"\\n\" + \"=\"*90)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "krm4qsi587g",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DATA EXPLORATION: Revenue, Years, and SME Classification\n",
            "==========================================================================================\n",
            "\n",
            "1. Class Imbalance by Revenue Threshold (kSEK = thousands SEK)\n",
            "------------------------------------------------------------------------------------------\n",
            "Min Revenue (kSEK)   Total Rows      Credit Events   Event Rate %    Imbalance      \n",
            "------------------------------------------------------------------------------------------\n",
            "1,000                4,413,099       19,472          0.441           225.6          :1\n",
            "5,000                1,990,887       12,759          0.641           155.0          :1\n",
            "10,000               1,237,787       8,630           0.697           142.4          :1\n",
            "50,000               334,002         2,327           0.697           142.5          :1\n",
            "100,000              180,806         1,114           0.616           161.3          :1\n",
            "1,000,000            19,798          61              0.308           323.6          :1\n",
            "\n",
            "2. Class Imbalance by Year\n",
            "------------------------------------------------------------------------------------------\n",
            "Year       Total Rows      Credit Events   Event Rate %    Imbalance      \n",
            "------------------------------------------------------------------------------------------\n",
            "1998       124,289         403             0.324           307.4          :1\n",
            "1999       128,467         370             0.288           346.2          :1\n",
            "2000       132,710         608             0.458           217.3          :1\n",
            "2001       134,561         613             0.456           218.5          :1\n",
            "2002       135,357         597             0.441           225.7          :1\n",
            "2003       137,279         552             0.402           247.7          :1\n",
            "2004       140,879         501             0.356           280.2          :1\n",
            "2005       145,429         460             0.316           315.1          :1\n",
            "2006       150,806         463             0.307           324.7          :1\n",
            "2007       156,356         734             0.469           212.0          :1\n",
            "2008       159,665         780             0.489           203.7          :1\n",
            "2009       161,848         753             0.465           213.9          :1\n",
            "2010       167,412         748             0.447           222.8          :1\n",
            "2011       175,446         887             0.506           196.8          :1\n",
            "2012       180,399         915             0.507           196.2          :1\n",
            "2013       185,511         833             0.449           221.7          :1\n",
            "2014       192,639         817             0.424           234.8          :1\n",
            "2015       200,656         852             0.425           234.5          :1\n",
            "2016       208,180         906             0.435           228.8          :1\n",
            "2017       215,635         1,006           0.467           213.3          :1\n",
            "2018       222,536         1,022           0.459           216.7          :1\n",
            "2019       227,569         1,094           0.481           207.0          :1\n",
            "2020       231,574         968             0.418           238.2          :1\n",
            "2021       244,029         1,164           0.477           208.6          :1\n",
            "2022       253,867         1,426           0.562           177.0          :1\n",
            "\n",
            "3. STRICT EU SME Classification (employees AND revenue/assets)\n",
            "------------------------------------------------------------------------------------------\n",
            "SME Category                             Total Rows      Credit Events   Event Rate %    Imbalance      \n",
            "------------------------------------------------------------------------------------------\n",
            "Micro                                    3,514,665       11,764          0.335           297.8          :1\n",
            "Small                                    729,889         6,417           0.879           112.7          :1\n",
            "Medium                                   131,122         1,121           0.855           116.0          :1\n",
            "Large                                    37,423          170             0.454           219.1          :1\n",
            "\n",
            "==========================================================================================\n"
          ]
        }
      ],
      "source": [
        "generate_eda_report(filtered_df, valid_mask)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "n37x89rabpi",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Full dataset: 4,413,099 rows × 91 features\n",
            "\n",
            "Train: 3,530,479 rows\n",
            "Validation: 882,620 rows\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Full dataset: {len(X):,} rows × {X.shape[1]} features\")\n",
        "print(f\"\\nTrain: {X_train.shape[0]:,} rows\")\n",
        "print(f\"Validation: {X_val.shape[0]:,} rows\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "7m8kb9oiyrq",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODEL TRAINING FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def train_lightgbm_model(X_train, y_train, X_val, y_val, params=None):\n",
        "    \"\"\"\n",
        "    Train LightGBM model with early stopping.\n",
        "    \n",
        "    Returns:\n",
        "    - model: Trained LightGBM model\n",
        "    - training_time: Time in seconds\n",
        "    \"\"\"\n",
        "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
        "    print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")\n",
        "    \n",
        "    # Default parameters\n",
        "    default_params = {\n",
        "        'n_estimators': 10000,\n",
        "        'learning_rate': 0.05,\n",
        "        'num_leaves': 31,\n",
        "        'subsample': 0.8,\n",
        "        'colsample_bytree': 0.8,\n",
        "        'objective': 'binary',\n",
        "        'is_unbalance': True,\n",
        "        'random_state': 42,\n",
        "        'n_jobs': -1,\n",
        "        'verbose': -1,\n",
        "        'metric': 'auc',\n",
        "        'reg_alpha': 0.1,\n",
        "        'reg_lambda': 0.1\n",
        "    }\n",
        "    \n",
        "    # Override with custom params if provided\n",
        "    if params:\n",
        "        default_params.update(params)\n",
        "    \n",
        "    model = lgb.LGBMClassifier(**default_params)\n",
        "    \n",
        "    print(\"\\nTraining LightGBM model...\")\n",
        "    start_time = time.time()\n",
        "    \n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
        "        eval_metric='auc',\n",
        "        callbacks=[\n",
        "            lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
        "            lgb.log_evaluation(period=50)\n",
        "        ]\n",
        "    )\n",
        "    \n",
        "    training_time = time.time() - start_time\n",
        "    print(f\"\\nLightGBM training completed in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
        "    \n",
        "    return model, training_time\n",
        "\n",
        "\n",
        "def evaluate_model(model, X_val, y_val):\n",
        "    \"\"\"\n",
        "    Evaluate model performance.\n",
        "    \n",
        "    Returns:\n",
        "    - metrics: Dictionary of evaluation metrics\n",
        "    \"\"\"\n",
        "    y_pred = model.predict(X_val)\n",
        "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "    \n",
        "    auc = roc_auc_score(y_val, y_pred_proba)\n",
        "    \n",
        "    print(f\"\\nValidation AUC: {auc:.4f}\")\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(classification_report(y_val, y_pred))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    print(confusion_matrix(y_val, y_pred))\n",
        "    \n",
        "    return {\n",
        "        'auc': auc,\n",
        "        'y_pred': y_pred,\n",
        "        'y_pred_proba': y_pred_proba\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "crtarzlpfn",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Calculated scale_pos_weight: 225.63\n",
            "\n",
            "Training LightGBM model...\n",
            "Training until validation scores don't improve for 50 rounds\n",
            "[50]\ttraining's auc: 0.951089\tvalid_1's auc: 0.935905\n",
            "[100]\ttraining's auc: 0.958727\tvalid_1's auc: 0.940281\n",
            "[150]\ttraining's auc: 0.96394\tvalid_1's auc: 0.942819\n",
            "[200]\ttraining's auc: 0.967653\tvalid_1's auc: 0.94422\n",
            "[250]\ttraining's auc: 0.970632\tvalid_1's auc: 0.945083\n",
            "[300]\ttraining's auc: 0.973338\tvalid_1's auc: 0.945837\n",
            "[350]\ttraining's auc: 0.975707\tvalid_1's auc: 0.946332\n",
            "[400]\ttraining's auc: 0.977753\tvalid_1's auc: 0.946544\n",
            "[450]\ttraining's auc: 0.979581\tvalid_1's auc: 0.946764\n",
            "[500]\ttraining's auc: 0.981193\tvalid_1's auc: 0.946959\n",
            "[550]\ttraining's auc: 0.982659\tvalid_1's auc: 0.947119\n",
            "[600]\ttraining's auc: 0.983929\tvalid_1's auc: 0.947194\n",
            "Early stopping, best iteration is:\n",
            "[581]\ttraining's auc: 0.98351\tvalid_1's auc: 0.947263\n",
            "\n",
            "LightGBM training completed in 171.2s (2.9 min)\n"
          ]
        }
      ],
      "source": [
        "lgb_model, lgb_time = train_lightgbm_model(X_train, y_train, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "0e10ba2d",
      "metadata": {},
      "outputs": [],
      "source": [
        "# MODEL INTERPRETATION FUNCTIONS\n",
        "# ============================================================================\n",
        "\n",
        "def show_feature_importance(model, top_n=20):\n",
        "    \"\"\"Display top N feature importances\"\"\"\n",
        "    print(f\"\\nTop {top_n} Feature Importances:\")\n",
        "    importance_df = pd.DataFrame({\n",
        "        'feature': model.feature_name_,\n",
        "        'importance': model.feature_importances_\n",
        "    }).sort_values('importance', ascending=False).head(top_n)\n",
        "    \n",
        "    print(importance_df.to_string(index=False))\n",
        "    \n",
        "    return importance_df\n",
        "\n",
        "def compute_shap_importance(model, X_val, sample_size=10000):\n",
        "    \"\"\"\n",
        "    Compute TreeSHAP values for feature importance.\n",
        "    \n",
        "    Returns:\n",
        "    - shap_importance: DataFrame with features and mean absolute SHAP values\n",
        "    - shap_values: Raw SHAP values array\n",
        "    - X_sample: Sample used for SHAP computation\n",
        "    \"\"\"\n",
        "    import shap\n",
        "    \n",
        "    print(f\"\\nComputing TreeSHAP values on {sample_size:,} samples...\")\n",
        "    \n",
        "    # Sample for computational efficiency\n",
        "    sample_size = min(sample_size, len(X_val))\n",
        "    X_sample = X_val.sample(n=sample_size, random_state=42)\n",
        "    \n",
        "    # Create SHAP explainer\n",
        "    explainer = shap.TreeExplainer(model)\n",
        "    shap_values = explainer.shap_values(X_sample)\n",
        "    \n",
        "    # Handle binary classification (returns list of [negative_class, positive_class])\n",
        "    if isinstance(shap_values, list):\n",
        "        shap_values = shap_values[1]\n",
        "    \n",
        "    # Calculate mean absolute SHAP values per feature\n",
        "    shap_importance = pd.DataFrame({\n",
        "        'feature': X_sample.columns,\n",
        "        'mean_abs_shap': np.abs(shap_values).mean(axis=0)\n",
        "    }).sort_values('mean_abs_shap', ascending=False)\n",
        "    \n",
        "    print(f\"TreeSHAP computation completed!\")\n",
        "    \n",
        "    return shap_importance, shap_values, X_sample\n",
        "\n",
        "\n",
        "def compute_per_feature_auc(X_val, y_val):\n",
        "    \"\"\"\n",
        "    Train individual models on each feature and compute AUC.\n",
        "    \n",
        "    Returns:\n",
        "    - feature_auc_df: DataFrame with features and their individual AUC scores\n",
        "    \"\"\"\n",
        "    print(f\"\\nComputing per-feature AUC on {len(X_val):,} samples...\")\n",
        "    print(\"This may take several minutes...\")\n",
        "    \n",
        "    feature_aucs = []\n",
        "    \n",
        "    for i, feature in enumerate(X_val.columns, 1):\n",
        "        if i % 20 == 0:\n",
        "            print(f\"  Progress: {i}/{len(X_val.columns)} features processed\")\n",
        "        \n",
        "        # Get non-null values\n",
        "        mask = X_val[feature].notna()\n",
        "        \n",
        "        if mask.sum() < 100:  # Skip if too few samples\n",
        "            continue\n",
        "        \n",
        "        X_feature = X_val.loc[mask, feature].values.reshape(-1, 1)\n",
        "        y_feature = y_val.loc[mask]\n",
        "        \n",
        "        try:\n",
        "            # Train simple model on single feature\n",
        "            temp_model = lgb.LGBMClassifier(\n",
        "                n_estimators=100,\n",
        "                learning_rate=0.1,\n",
        "                num_leaves=7,\n",
        "                random_state=42,\n",
        "                verbose=-1\n",
        "            )\n",
        "            temp_model.fit(X_feature, y_feature)\n",
        "            y_pred_proba = temp_model.predict_proba(X_feature)[:, 1]\n",
        "            \n",
        "            auc = roc_auc_score(y_feature, y_pred_proba)\n",
        "            feature_aucs.append({'feature': feature, 'auc': auc})\n",
        "        except Exception as e:\n",
        "            print(f\"  Skipped {feature}: {str(e)}\")\n",
        "            continue\n",
        "    \n",
        "    # Sort by AUC\n",
        "    feature_auc_df = pd.DataFrame(feature_aucs).sort_values('auc', ascending=False)\n",
        "    \n",
        "    print(f\"\\nPer-feature AUC computation completed!\")\n",
        "    print(f\"  Features with AUC > 0.60: {(feature_auc_df['auc'] > 0.60).sum()}\")\n",
        "    print(f\"  Features with AUC > 0.65: {(feature_auc_df['auc'] > 0.65).sum()}\")\n",
        "    print(f\"  Features with AUC > 0.70: {(feature_auc_df['auc'] > 0.70).sum()}\")\n",
        "    \n",
        "    return feature_auc_df\n",
        "\n",
        "\n",
        "def display_feature_analysis(shap_importance, feature_auc_df, top_n=30):\n",
        "    \"\"\"\n",
        "    Display comprehensive feature importance analysis.\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\"*90)\n",
        "    print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
        "    print(\"=\"*90)\n",
        "    \n",
        "    print(f\"\\n1. TreeSHAP Importance (Top {top_n})\")\n",
        "    print(\"-\"*90)\n",
        "    print(shap_importance.head(top_n).to_string(index=False))\n",
        "    \n",
        "    print(f\"\\n\\n2. Per-Feature AUC (Top {top_n})\")\n",
        "    print(\"-\"*90)\n",
        "    print(feature_auc_df.head(top_n).to_string(index=False))\n",
        "    \n",
        "    # Merge for comparison\n",
        "    comparison = shap_importance.merge(feature_auc_df, on='feature', how='inner')\n",
        "    comparison['shap_rank'] = comparison['mean_abs_shap'].rank(ascending=False)\n",
        "    comparison['auc_rank'] = comparison['auc'].rank(ascending=False)\n",
        "    comparison['avg_rank'] = (comparison['shap_rank'] + comparison['auc_rank']) / 2\n",
        "    comparison = comparison.sort_values('avg_rank')\n",
        "    \n",
        "    print(f\"\\n\\n3. Combined Ranking (SHAP + AUC, Top {top_n})\")\n",
        "    print(\"-\"*90)\n",
        "    print(comparison[['feature', 'mean_abs_shap', 'shap_rank', 'auc', 'auc_rank', 'avg_rank']].head(top_n).to_string(index=False))\n",
        "    \n",
        "    return comparison"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "koka49434cq",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top 20 Feature Importances:\n",
            "                        feature  importance\n",
            "            bransch_sni071_konv         494\n",
            "                       dpo_days         464\n",
            "                    ny_avkegkap         441\n",
            "                     rr01_ntoms         388\n",
            "                     ny_kapomsh         336\n",
            "             ny_skuldgrd_vol_3y         335\n",
            "                ny_foradlvpanst         326\n",
            "ratio_ebit_interest_cov_yoy_pct         321\n",
            "              ny_rormarg_vol_3y         319\n",
            "        ratio_cash_interest_cov         319\n",
            "           ratio_cash_liquidity         312\n",
            "              dso_days_yoy_diff         298\n",
            "   ratio_cash_liquidity_yoy_pct         292\n",
            "                    ny_omspanst         290\n",
            "                     rr15_resar         282\n",
            "              dpo_days_yoy_diff         280\n",
            "                    company_age         273\n",
            "                 assets_cagr_3y         264\n",
            "              dso_days_trend_3y         262\n",
            "                          ny_rs         258\n",
            "\n",
            "Validation AUC: 0.9473\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       1.00      0.91      0.95    878726\n",
            "         1.0       0.04      0.82      0.07      3894\n",
            "\n",
            "    accuracy                           0.91    882620\n",
            "   macro avg       0.52      0.87      0.51    882620\n",
            "weighted avg       0.99      0.91      0.95    882620\n",
            "\n",
            "\n",
            "Confusion Matrix:\n",
            "[[800448  78278]\n",
            " [   697   3197]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{'auc': 0.9472628131672735,\n",
              " 'y_pred': array([0., 0., 1., ..., 0., 0., 0.], shape=(882620,)),\n",
              " 'y_pred_proba': array([0.32859254, 0.00154698, 0.56315761, ..., 0.06410042, 0.0372332 ,\n",
              "        0.00925024], shape=(882620,))}"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "importance_df = show_feature_importance(lgb_model, top_n=20)\n",
        "\n",
        "evaluate_model(lgb_model, X_val, y_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "mbfbt33k8",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Computing TreeSHAP values on 10,000 samples...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/shap/explainers/_tree.py:583: UserWarning: LightGBM binary classifier with TreeExplainer shap values output has changed to a list of ndarray\n",
            "  warnings.warn(\n",
            "Python(11335) MallocStackLogging: can't turn off malloc stack logging because it was not enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TreeSHAP computation completed!\n",
            "\n",
            "Computing per-feature AUC on 882,620 samples...\n",
            "This may take several minutes...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 20/91 features processed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 40/91 features processed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 60/91 features processed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Progress: 80/91 features processed\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n",
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Per-feature AUC computation completed!\n",
            "  Features with AUC > 0.60: 71\n",
            "  Features with AUC > 0.65: 57\n",
            "  Features with AUC > 0.70: 22\n",
            "\n",
            "==========================================================================================\n",
            "FEATURE IMPORTANCE ANALYSIS\n",
            "==========================================================================================\n",
            "\n",
            "1. TreeSHAP Importance (Top 30)\n",
            "------------------------------------------------------------------------------------------\n",
            "                        feature  mean_abs_shap\n",
            "                    ny_avkegkap       0.551273\n",
            "           ratio_cash_liquidity       0.539814\n",
            "                     ny_kapomsh       0.490971\n",
            "          ratio_dividend_payout       0.463969\n",
            "                     rr01_ntoms       0.301023\n",
            "                       ny_solid       0.174451\n",
            "        ratio_depreciation_cost       0.167878\n",
            "              ny_rormarg_vol_3y       0.165339\n",
            "             ny_skuldgrd_vol_3y       0.162818\n",
            "                    company_age       0.161999\n",
            "                    ny_skuldgrd       0.136862\n",
            "            bransch_sni071_konv       0.127688\n",
            "                       dpo_days       0.119116\n",
            "                  bslov_antanst       0.115793\n",
            "                 inventory_days       0.100147\n",
            "                          ny_rs       0.097971\n",
            "                revenue_cagr_3y       0.095860\n",
            "                     rr15_resar       0.093645\n",
            "              dso_days_yoy_diff       0.092792\n",
            "ratio_ebit_interest_cov_yoy_pct       0.091843\n",
            " ratio_retained_earnings_equity       0.089743\n",
            "             rr01_ntoms_yoy_pct       0.086872\n",
            "                ny_foradlvpanst       0.086172\n",
            "              dpo_days_yoy_diff       0.084137\n",
            "        ratio_cash_interest_cov       0.070040\n",
            "                    knc_kncfall       0.067657\n",
            "      ratio_secured_debt_assets       0.066768\n",
            "   ratio_cash_liquidity_yoy_pct       0.065890\n",
            "                 assets_cagr_3y       0.064235\n",
            "                   br07b_kabasu       0.061243\n",
            "\n",
            "\n",
            "2. Per-Feature AUC (Top 30)\n",
            "------------------------------------------------------------------------------------------\n",
            "                       feature      auc\n",
            "          ratio_cash_liquidity 0.768879\n",
            "                  ny_nettomarg 0.765892\n",
            "                    rr15_resar 0.761979\n",
            "                   ny_vinstprc 0.757986\n",
            "                    ny_rormarg 0.754732\n",
            "                   ny_avktokap 0.751454\n",
            "       ratio_ebit_interest_cov 0.746484\n",
            "            ny_skuldgrd_vol_3y 0.737310\n",
            "                   ny_kasslikv 0.736398\n",
            "                 rr07_rorresul 0.735642\n",
            "    ratio_share_capital_equity 0.728053\n",
            "          ny_skuldgrd_trend_3y 0.727439\n",
            "                   ny_avkegkap 0.727417\n",
            "           ratio_ebitda_margin 0.725942\n",
            "          ny_skuldgrd_yoy_diff 0.725809\n",
            "                   ny_skuldgrd 0.717301\n",
            "                      ny_solid 0.716531\n",
            "       ratio_cash_interest_cov 0.712280\n",
            "                    ny_rorkapo 0.712202\n",
            "               ratio_nwc_sales 0.712047\n",
            "ratio_retained_earnings_equity 0.709251\n",
            "     ratio_ebitda_interest_cov 0.705575\n",
            "            rr01_ntoms_yoy_abs 0.698843\n",
            "                     br10_eksu 0.698373\n",
            "         rr07_rorresul_yoy_abs 0.697677\n",
            "   ratio_cash_liquidity_vol_3y 0.693813\n",
            " ratio_cash_liquidity_trend_3y 0.691626\n",
            "                    br13_ksksu 0.688923\n",
            "          last_event_within_1y 0.688750\n",
            "           event_count_last_5y 0.688750\n",
            "\n",
            "\n",
            "3. Combined Ranking (SHAP + AUC, Top 30)\n",
            "------------------------------------------------------------------------------------------\n",
            "                        feature  mean_abs_shap  shap_rank      auc  auc_rank  avg_rank\n",
            "           ratio_cash_liquidity       0.539814        2.0 0.768879       1.0       1.5\n",
            "                    ny_avkegkap       0.551273        1.0 0.727417      13.0       7.0\n",
            "             ny_skuldgrd_vol_3y       0.162818        9.0 0.737310       8.0       8.5\n",
            "                     rr15_resar       0.093645       18.0 0.761979       3.0      10.5\n",
            "                       ny_solid       0.174451        6.0 0.716531      17.0      11.5\n",
            "                    ny_skuldgrd       0.136862       11.0 0.717301      16.0      13.5\n",
            "                   ny_nettomarg       0.057644       34.0 0.765892       2.0      18.0\n",
            " ratio_retained_earnings_equity       0.089743       21.0 0.709251      21.0      21.0\n",
            "        ratio_cash_interest_cov       0.070040       25.0 0.712280      18.0      21.5\n",
            "        ratio_ebit_interest_cov       0.052216       38.0 0.746484       7.0      22.5\n",
            "                    ny_vinstprc       0.046614       41.0 0.757986       4.0      22.5\n",
            "           ny_skuldgrd_trend_3y       0.053482       37.0 0.727439      12.0      24.5\n",
            "                  bslov_antanst       0.115793       14.0 0.680608      38.0      26.0\n",
            "          ratio_dividend_payout       0.463969        4.0 0.663635      48.0      26.0\n",
            "            bransch_sni071_konv       0.127688       12.0 0.673406      41.0      26.5\n",
            "                       dpo_days       0.119116       13.0 0.674955      40.0      26.5\n",
            "                     rr01_ntoms       0.301023        5.0 0.654781      53.0      29.0\n",
            "            ratio_ebitda_margin       0.042067       45.0 0.725942      14.0      29.5\n",
            "    ratio_cash_liquidity_vol_3y       0.060200       33.0 0.693813      26.0      29.5\n",
            "                          ny_rs       0.097971       16.0 0.664900      46.0      31.0\n",
            "             rr01_ntoms_yoy_abs       0.050111       39.0 0.698843      23.0      31.0\n",
            "                    ny_kasslikv       0.030568       57.0 0.736398       9.0      33.0\n",
            "   ratio_cash_liquidity_yoy_pct       0.065890       28.0 0.679530      39.0      33.5\n",
            "                ny_foradlvpanst       0.086172       23.0 0.667731      45.0      34.0\n",
            "ratio_ebit_interest_cov_yoy_pct       0.091843       20.0 0.661471      50.0      35.0\n",
            "                   br07b_kabasu       0.061243       30.0 0.672482      42.0      36.0\n",
            "                     ny_rormarg       0.022267       67.0 0.754732       5.0      36.0\n",
            "              ny_rormarg_vol_3y       0.165339        8.0 0.631015      64.0      36.0\n",
            "                     ny_kapomsh       0.490971        3.0 0.612672      70.0      36.5\n",
            "                    ny_avktokap       0.022261       68.0 0.751454       6.0      37.0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/vilhelmkarlin/Code/HHS/BE451_Thesis/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Compute TreeSHAP importance\n",
        "shap_importance, shap_values, X_sample = compute_shap_importance(lgb_model, X_val, sample_size=10000)\n",
        "\n",
        "# Compute per-feature AUC\n",
        "feature_auc_df = compute_per_feature_auc(X_val, y_val)\n",
        "\n",
        "# Display comprehensive analysis\n",
        "comparison_df = display_feature_analysis(shap_importance, feature_auc_df, top_n=30)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
