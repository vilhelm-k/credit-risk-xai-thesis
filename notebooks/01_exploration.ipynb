{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "331555c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /Users/vilhelmkarlin/Code/HHS/BE451_Thesis/credit-risk-xai-thesis\n",
      "Base cache: /Users/vilhelmkarlin/Code/HHS/BE451_Thesis/credit-risk-xai-thesis/data/interim/serrano_base.parquet\n",
      "Feature cache: /Users/vilhelmkarlin/Code/HHS/BE451_Thesis/credit-risk-xai-thesis/data/processed/serrano_features.parquet\n",
      "Macro cache: /Users/vilhelmkarlin/Code/HHS/BE451_Thesis/credit-risk-xai-thesis/data/interim/macro_annual.parquet\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import xgboost as xgb\n",
    "from xgboost.callback import EarlyStopping\n",
    "import lightgbm as lgb\n",
    "import time\n",
    "\n",
    "# Add project root to path\n",
    "PROJ_ROOT = Path.cwd().parent\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJ_ROOT))\n",
    "\n",
    "# Import from actual project structure\n",
    "from credit_risk_xai.config import (\n",
    "    BASE_CACHE_PATH,\n",
    "    FEATURE_CACHE_PATH,\n",
    "    MACRO_CACHE_PATH,\n",
    "    COLS_TO_LOAD,\n",
    "    FEATURES_FOR_MODEL,\n",
    "    MACRO_FEATURE_NAMES,\n",
    "    MACRO_FEATURE_PRIORITIES,\n",
    "    SME_CATEGORIES,\n",
    "    CATEGORICAL_COLS,\n",
    "    MIN_REVENUE_KSEK,\n",
    "    NY_COLS,\n",
    "    KEPT_RAW_COLS,\n",
    "    RATIO_FEATURE_NAMES,\n",
    "    LIQUIDITY_EFFICIENCY_FEATURES,\n",
    "    TREND_FEATURE_NAMES,\n",
    "    CRISIS_FEATURE_NAMES,\n",
    "    ENGINEERED_FEATURE_NAMES,\n",
    ")\n",
    "\n",
    "from credit_risk_xai.features.engineer import (\n",
    "    create_engineered_features,\n",
    "    apply_modeling_filters,\n",
    "    create_target_variable,\n",
    "    prepare_modeling_data,\n",
    ")\n",
    "\n",
    "print(f\"Project root: {PROJ_ROOT}\")\n",
    "print(f\"Base cache: {BASE_CACHE_PATH}\")\n",
    "print(f\"Feature cache: {FEATURE_CACHE_PATH}\")\n",
    "print(f\"Macro cache: {MACRO_CACHE_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6f2f46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# COLUMN DEFINITIONS\n",
    "# ============================================================================\n",
    "\n",
    "# All column definitions are imported from credit_risk_xai.config\n",
    "# Available variables:\n",
    "# - BASE_COLS, NY_COLS, KEPT_RAW_COLS, RR_SOURCE_COLS, BR_SOURCE_COLS\n",
    "# - COLS_TO_LOAD, CATEGORICAL_COLS, SME_CATEGORIES\n",
    "# - RATIO_FEATURE_NAMES, LIQUIDITY_EFFICIENCY_FEATURES\n",
    "# - TREND_FEATURE_NAMES, CRISIS_FEATURE_NAMES, MACRO_FEATURE_NAMES\n",
    "# - ENGINEERED_FEATURE_NAMES, FEATURES_FOR_MODEL\n",
    "\n",
    "print(f\"Columns to load: {len(COLS_TO_LOAD)}\")\n",
    "print(f\"Total engineered features registered: {len(ENGINEERED_FEATURE_NAMES)}\")\n",
    "print(f\"Features for modeling: {len(FEATURES_FOR_MODEL)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dkdcg1rbthi",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading macro data...\n",
      "✓ Macro summary loaded: (45, 13)\n",
      "  Years covered: 1981-2025\n",
      "\n",
      "Loading Serrano base dataset...\n",
      "✓ Base Serrano loaded: (12473668, 116)\n",
      "  Memory: 11.37 GB\n"
     ]
    }
   ],
   "source": [
    "# DATA LOADING\n",
    "# ============================================================================\n",
    "# Load macro data and interim Serrano base dataset\n",
    "\n",
    "print(\"Loading macro data...\")\n",
    "if MACRO_CACHE_PATH.exists():\n",
    "    macro_df = pd.read_parquet(MACRO_CACHE_PATH)\n",
    "    print(f\"✓ Macro summary loaded: {macro_df.shape}\")\n",
    "    print(f\"  Years covered: {macro_df['ser_year'].min()}-{macro_df['ser_year'].max()}\")\n",
    "else:\n",
    "    print(f\"✗ Macro cache not found at {MACRO_CACHE_PATH}\")\n",
    "    print(\"  Run: python -m credit_risk_xai.data.make_macro\")\n",
    "    macro_df = None\n",
    "\n",
    "print(\"\\nLoading Serrano base dataset...\")\n",
    "if BASE_CACHE_PATH.exists():\n",
    "    serrano_base = pd.read_parquet(BASE_CACHE_PATH)\n",
    "    print(f\"✓ Base Serrano loaded: {serrano_base.shape}\")\n",
    "    print(f\"  Memory: {serrano_base.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "else:\n",
    "    print(f\"✗ Base cache not found at {BASE_CACHE_PATH}\")\n",
    "    print(\"  Run: python -m credit_risk_xai.data.make_dataset\")\n",
    "    serrano_base = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94817690",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORGNR :  Int64\n",
      "ser_namn :  object\n",
      "ser_year :  Int32\n",
      "bol_konkurs :  float64\n",
      "bol_q80dat :  datetime64[ns]\n",
      "ser_stklf :  float64\n",
      "bslov_antanst :  float64\n",
      "ser_aktiv :  float64\n",
      "ser_nystartat :  float64\n",
      "ser_regdat :  datetime64[ns]\n",
      "bransch_sni071_konv :  float64\n",
      "bransch_borsbransch_konv :  float64\n",
      "ser_laen :  float64\n",
      "knc_kncfall :  float64\n",
      "ny_kapomsh :  float64\n",
      "ny_avktokap :  float64\n",
      "ny_rs :  float64\n",
      "ny_skuldgrd :  float64\n",
      "ny_solid :  float64\n",
      "ny_avkegkap :  float64\n",
      "ny_rorkapo :  float64\n",
      "ny_kasslikv :  float64\n",
      "ny_rormarg :  float64\n",
      "ny_nettomarg :  float64\n",
      "ny_vinstprc :  float64\n",
      "ny_omspanst :  float64\n",
      "ny_foradlvpanst :  float64\n",
      "ny_omsf :  float64\n",
      "ny_anstf :  float64\n",
      "rr01_ntoms :  float64\n",
      "br09_tillgsu :  float64\n",
      "br10_eksu :  float64\n",
      "br07b_kabasu :  float64\n",
      "br13_ksksu :  float64\n",
      "br15_lsksu :  float64\n",
      "rr07_rorresul :  float64\n",
      "rr15_resar :  float64\n",
      "rr02_rointov :  float64\n",
      "rr05_avskriv :  float64\n",
      "rr04_perskos :  float64\n",
      "rr03_jfrst :  float64\n",
      "rr06_rorkoov :  float64\n",
      "rr09_finkostn :  float64\n",
      "rr09d_jfrstfin :  float64\n",
      "rr04a_loner :  float64\n",
      "rr04c_foradlv :  float64\n",
      "rr04b_sockostn :  float64\n",
      "rr00_utdbel :  float64\n",
      "rr02a_lagerf :  float64\n",
      "rr02b_aktarb :  float64\n",
      "rr06a_prodkos :  float64\n",
      "rr08d_resand :  float64\n",
      "rr08a_rteinknc :  float64\n",
      "rr08b_rteinext :  float64\n",
      "rr08c_rteinov :  float64\n",
      "rr09a_rtekoknc :  float64\n",
      "rr09b_rtekoext :  float64\n",
      "rr09c_rtekoov :  float64\n",
      "rr08_finintk :  float64\n",
      "rr10_finres_int :  float64\n",
      "rr12_resefin :  float64\n",
      "rr14_skatter :  float64\n",
      "rr13_bsldisp :  float64\n",
      "rr13a_extraint :  float64\n",
      "rr13b_extrakos :  float64\n",
      "rr13c_kncbdr :  float64\n",
      "rr13d_agtsk :  float64\n",
      "rr13e_bsldisp :  float64\n",
      "br01_imanlsu :  float64\n",
      "br03_maskiner :  float64\n",
      "br02_matanlsu :  float64\n",
      "br04_fianltsu :  float64\n",
      "br05_anltsu :  float64\n",
      "br08_omstgsu :  float64\n",
      "br11_obeskres :  float64\n",
      "br12_avssu :  float64\n",
      "br14_kskkrin :  float64\n",
      "br16_lskkrin :  float64\n",
      "br17_eksksu :  float64\n",
      "br06_lagerkford :  float64\n",
      "br07_kplackaba :  float64\n",
      "br06c_lagersu :  float64\n",
      "br06g_kfordsu :  float64\n",
      "br07a_kplacsu :  float64\n",
      "br02a_byggmark :  float64\n",
      "br02b_matanlov :  float64\n",
      "br01a_foubautg :  float64\n",
      "br01b_patlic :  float64\n",
      "br01c_goodwill :  float64\n",
      "br01d_imanlov :  float64\n",
      "br04a_andknc :  float64\n",
      "br04b_lfordknc :  float64\n",
      "br04c_landelag :  float64\n",
      "br04d_fianltov :  float64\n",
      "br06a_pagarb :  float64\n",
      "br06b_lagerov :  float64\n",
      "br06d_kundford :  float64\n",
      "br06e_kfordknc :  float64\n",
      "br06f_kfordov :  float64\n",
      "br10a_aktiekap :  float64\n",
      "br10b_overkurs :  float64\n",
      "br10c_uppskr :  float64\n",
      "br10d_ovrgbkap :  float64\n",
      "br10e_balres :  float64\n",
      "br10f_kncbdrel :  float64\n",
      "br10g_agtskel :  float64\n",
      "br10h_resarb :  float64\n",
      "br13a_ksklev :  float64\n",
      "br13b_kskknc :  float64\n",
      "br13c_kskov :  float64\n",
      "br15a_lskknc :  float64\n",
      "br15b_lskov :  float64\n",
      "br15c_obllan :  float64\n",
      "company_age :  Int32\n",
      "credit_event :  int8\n",
      "sme_category :  category\n"
     ]
    }
   ],
   "source": [
    "for name, row in serrano_base.dtypes.items():\n",
    "    print(name, \":\", row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eeb0f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING\n",
    "# ============================================================================\n",
    "# Option 1: Load pre-computed features (fast)\n",
    "# Option 2: Compute features from base dataset (slow, but fresh)\n",
    "\n",
    "USE_CACHED_FEATURES = True  # Set to False to recompute\n",
    "\n",
    "if USE_CACHED_FEATURES and FEATURE_CACHE_PATH.exists():\n",
    "    print(\"Loading pre-computed feature matrix...\")\n",
    "    serrano_df = pd.read_parquet(FEATURE_CACHE_PATH)\n",
    "    print(f\"✓ Feature matrix loaded: {serrano_df.shape}\")\n",
    "    print(f\"  Memory: {serrano_df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "    \n",
    "elif serrano_base is not None and macro_df is not None:\n",
    "    print(\"Computing features from base dataset...\")\n",
    "    print(\"⚠️  This may take 5-15 minutes for large datasets...\")\n",
    "    \n",
    "    serrano_df = create_engineered_features(serrano_base, macro_df=macro_df)\n",
    "    \n",
    "    # Save for next time\n",
    "    FEATURE_CACHE_PATH.parent.mkdir(parents=True, exist_ok=True)\n",
    "    serrano_df.to_parquet(FEATURE_CACHE_PATH, index=False)\n",
    "    print(f\"✓ Features computed and cached: {serrano_df.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"✗ Cannot compute features - missing base data or macro data\")\n",
    "    print(\"  Run the data loading cell above first\")\n",
    "    serrano_df = None\n",
    "\n",
    "if serrano_df is not None:\n",
    "    engineered_cols = [c for c in serrano_df.columns if c in ENGINEERED_FEATURE_NAMES]\n",
    "    print(f\"\\nEngineered features in dataset: {len(engineered_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qprdf57578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE ENGINEERING SUMMARY\n",
    "# ============================================================================\n",
    "# Features are computed by credit_risk_xai.features.engineer module\n",
    "# See the module for details on:\n",
    "# - Profitability ratios (EBITDA, interest coverage, etc.)\n",
    "# - Liquidity metrics (cash liquidity, DSO, DPO, inventory days)\n",
    "# - Capital structure (debt ratios, equity composition)\n",
    "# - Trends (YoY changes, CAGR, rolling averages/volatility)\n",
    "# - Credit event history (streaks, event counts)\n",
    "# - Macro indicators (GDP growth, interest rates, unemployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583a86cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODELING DATA PREPARATION\n",
    "# ============================================================================\n",
    "\n",
    "if serrano_df is not None:\n",
    "    print(\"Applying modeling filters...\")\n",
    "    filtered_df = apply_modeling_filters(serrano_df, min_revenue_ksek=MIN_REVENUE_KSEK)\n",
    "    \n",
    "    print(\"Creating target variable...\")\n",
    "    valid_mask = create_target_variable(filtered_df)\n",
    "    \n",
    "    print(\"Preparing feature matrix and target...\")\n",
    "    X, y = prepare_modeling_data(filtered_df, valid_mask)\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(\"MODELING DATASET SUMMARY\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Filtered dataset shape: {filtered_df.shape}\")\n",
    "    print(f\"Memory usage: {filtered_df.memory_usage(deep=True).sum() / 1024**3:.2f} GB\")\n",
    "    print(f\"\\nFeature matrix (X): {X.shape}\")\n",
    "    print(f\"Target vector (y): {y.shape}\")\n",
    "    print(f\"\\nTarget distribution:\")\n",
    "    print(y.value_counts().to_string())\n",
    "    print(f\"\\nClass imbalance: {(y==0).sum() / (y==1).sum():.1f}:1\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "else:\n",
    "    print(\"✗ Cannot prepare modeling data - feature matrix not loaded\")\n",
    "    print(\"  Run the feature engineering cell above first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ilguh9ihmog",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXPLORATORY DATA ANALYSIS FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def analyze_class_imbalance_by_revenue(df, valid_mask, thresholds=[1000, 5_000, 10_000, 50_000, 100_000, 1_000_000]):\n",
    "    \"\"\"Analyze class imbalance across different revenue thresholds\"\"\"\n",
    "    print(f\"\\n1. Class Imbalance by Revenue Threshold (kSEK = thousands SEK)\")\n",
    "    print(\"-\" * 90)\n",
    "    print(f\"{'Min Revenue (kSEK)':<20} {'Total Rows':<15} {'Credit Events':<15} {'Event Rate %':<15} {'Imbalance':<15}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for threshold in thresholds:\n",
    "        mask = (df['rr01_ntoms'] >= threshold) & valid_mask\n",
    "        n_samples = mask.sum()\n",
    "        n_events = df.loc[mask, 'target_next_year'].sum()\n",
    "        n_no_events = (df.loc[mask, 'target_next_year'] == 0).sum()\n",
    "        \n",
    "        if n_events > 0:\n",
    "            event_rate = 100 * n_events / n_samples\n",
    "            imbalance = n_no_events / n_events\n",
    "            print(f\"{threshold:<20,} {n_samples:<15,} {n_events:<15,} {event_rate:<15.3f} {imbalance:<15.1f}:1\")\n",
    "        else:\n",
    "            print(f\"{threshold:<20,} {n_samples:<15,} {0:<15,} {'0.000':<15} {'N/A':<15}\")\n",
    "\n",
    "\n",
    "def analyze_class_imbalance_by_year(df, valid_mask):\n",
    "    \"\"\"Analyze class imbalance across different years\"\"\"\n",
    "    print(f\"\\n2. Class Imbalance by Year\")\n",
    "    print(\"-\" * 90)\n",
    "    print(f\"{'Year':<10} {'Total Rows':<15} {'Credit Events':<15} {'Event Rate %':<15} {'Imbalance':<15}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    years = sorted(df.loc[valid_mask, 'ser_year'].dropna().unique())\n",
    "    \n",
    "    for year in years:\n",
    "        mask = (df['ser_year'] == year) & valid_mask\n",
    "        n_samples = mask.sum()\n",
    "        n_events = df.loc[mask, 'target_next_year'].sum()\n",
    "        n_no_events = (df.loc[mask, 'target_next_year'] == 0).sum()\n",
    "        \n",
    "        if n_events > 0:\n",
    "            event_rate = 100 * n_events / n_samples\n",
    "            imbalance = n_no_events / n_events\n",
    "            print(f\"{int(year):<10} {n_samples:<15,} {n_events:<15,} {event_rate:<15.3f} {imbalance:<15.1f}:1\")\n",
    "\n",
    "\n",
    "def analyze_class_imbalance_by_sme(df, valid_mask):\n",
    "    \"\"\"Analyze class imbalance across SME categories\"\"\"\n",
    "    print(f\"\\n3. STRICT EU SME Classification (employees AND revenue/assets)\")\n",
    "    print(\"-\" * 90)\n",
    "    print(f\"{'SME Category':<40} {'Total Rows':<15} {'Credit Events':<15} {'Event Rate %':<15} {'Imbalance':<15}\")\n",
    "    print(\"-\" * 90)\n",
    "    \n",
    "    for category in SME_CATEGORIES:\n",
    "        mask = (df['sme_category'] == category) & valid_mask\n",
    "        n_samples = mask.sum()\n",
    "        n_events = df.loc[mask, 'target_next_year'].sum()\n",
    "        n_no_events = (df.loc[mask, 'target_next_year'] == 0).sum()\n",
    "        \n",
    "        if n_samples > 0 and n_events > 0:\n",
    "            event_rate = 100 * n_events / n_samples\n",
    "            imbalance = n_no_events / n_events\n",
    "            print(f\"{category:<40} {n_samples:<15,} {n_events:<15,} {event_rate:<15.3f} {imbalance:<15.1f}:1\")\n",
    "        elif n_samples > 0:\n",
    "            print(f\"{category:<40} {n_samples:<15,} {0:<15,} {'0.000':<15} {'N/A':<15}\")\n",
    "\n",
    "\n",
    "def generate_eda_report(df, valid_mask):\n",
    "    \"\"\"Generate complete EDA report\"\"\"\n",
    "    print(\"DATA EXPLORATION: Revenue, Years, and SME Classification\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    analyze_class_imbalance_by_revenue(df, valid_mask)\n",
    "    analyze_class_imbalance_by_year(df, valid_mask)\n",
    "    analyze_class_imbalance_by_sme(df, valid_mask)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "krm4qsi587g",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run EDA report\n",
    "if 'filtered_df' in locals() and 'valid_mask' in locals():\n",
    "    generate_eda_report(filtered_df, valid_mask)\n",
    "else:\n",
    "    print(\"✗ Cannot run EDA - prepare the modeling data first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "n37x89rabpi",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN/VAL SPLIT\n",
    "# ============================================================================\n",
    "\n",
    "if 'X' in locals() and 'y' in locals():\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X, y, test_size=0.2, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    print(f\"Full dataset: {len(X):,} rows × {X.shape[1]} features\")\n",
    "    print(f\"\\nTrain: {X_train.shape[0]:,} rows\")\n",
    "    print(f\"Validation: {X_val.shape[0]:,} rows\")\n",
    "else:\n",
    "    print(\"✗ Cannot split data - X and y not available\")\n",
    "    print(\"  Run the modeling data preparation cell above first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7m8kb9oiyrq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def train_lightgbm_model(X_train, y_train, X_val, y_val, params=None):\n",
    "    \"\"\"\n",
    "    Train LightGBM model with early stopping.\n",
    "    \n",
    "    Returns:\n",
    "    - model: Trained LightGBM model\n",
    "    - training_time: Time in seconds\n",
    "    \"\"\"\n",
    "    scale_pos_weight = (y_train == 0).sum() / (y_train == 1).sum()\n",
    "    print(f\"Calculated scale_pos_weight: {scale_pos_weight:.2f}\")\n",
    "    \n",
    "    # Default parameters\n",
    "    default_params = {\n",
    "        'n_estimators': 10000,\n",
    "        'learning_rate': 0.05,\n",
    "        'num_leaves': 31,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'objective': 'binary',\n",
    "        'is_unbalance': True,\n",
    "        'random_state': 42,\n",
    "        'n_jobs': -1,\n",
    "        'verbose': -1,\n",
    "        'metric': 'auc',\n",
    "        'reg_alpha': 0.1,\n",
    "        'reg_lambda': 0.1\n",
    "    }\n",
    "    \n",
    "    # Override with custom params if provided\n",
    "    if params:\n",
    "        default_params.update(params)\n",
    "    \n",
    "    model = lgb.LGBMClassifier(**default_params)\n",
    "    \n",
    "    print(\"\\nTraining LightGBM model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    model.fit(\n",
    "        X_train, y_train,\n",
    "        eval_set=[(X_train, y_train), (X_val, y_val)],\n",
    "        eval_metric='auc',\n",
    "        callbacks=[\n",
    "            lgb.early_stopping(stopping_rounds=50, verbose=True),\n",
    "            lgb.log_evaluation(period=50)\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"\\nLightGBM training completed in {training_time:.1f}s ({training_time/60:.1f} min)\")\n",
    "    \n",
    "    return model, training_time\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Evaluate model performance.\n",
    "    \n",
    "    Returns:\n",
    "    - metrics: Dictionary of evaluation metrics\n",
    "    \"\"\"\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    \n",
    "    print(f\"\\nValidation AUC: {auc:.4f}\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "    print(\"\\nConfusion Matrix:\")\n",
    "    print(confusion_matrix(y_val, y_pred))\n",
    "    \n",
    "    return {\n",
    "        'auc': auc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_proba': y_pred_proba\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "crtarzlpfn",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN LIGHTGBM MODEL\n",
    "# ============================================================================\n",
    "\n",
    "if all(var in locals() for var in ['X_train', 'y_train', 'X_val', 'y_val']):\n",
    "    lgb_model, lgb_time = train_lightgbm_model(X_train, y_train, X_val, y_val)\n",
    "else:\n",
    "    print(\"✗ Cannot train model - train/val split not available\")\n",
    "    print(\"  Run the train/val split cell above first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e10ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL INTERPRETATION FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def show_feature_importance(model, top_n=20):\n",
    "    \"\"\"Display top N feature importances\"\"\"\n",
    "    print(f\"\\nTop {top_n} Feature Importances:\")\n",
    "    importance_df = pd.DataFrame({\n",
    "        'feature': model.feature_name_,\n",
    "        'importance': model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False).head(top_n)\n",
    "    \n",
    "    print(importance_df.to_string(index=False))\n",
    "    \n",
    "    return importance_df\n",
    "\n",
    "def compute_shap_importance(model, X_val, sample_size=10000):\n",
    "    \"\"\"\n",
    "    Compute TreeSHAP values for feature importance.\n",
    "    \n",
    "    Returns:\n",
    "    - shap_importance: DataFrame with features and mean absolute SHAP values\n",
    "    - shap_values: Raw SHAP values array\n",
    "    - X_sample: Sample used for SHAP computation\n",
    "    \"\"\"\n",
    "    import shap\n",
    "    \n",
    "    print(f\"\\nComputing TreeSHAP values on {sample_size:,} samples...\")\n",
    "    \n",
    "    # Sample for computational efficiency\n",
    "    sample_size = min(sample_size, len(X_val))\n",
    "    X_sample = X_val.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Create SHAP explainer\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    shap_values = explainer.shap_values(X_sample)\n",
    "    \n",
    "    # Handle binary classification (returns list of [negative_class, positive_class])\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]\n",
    "    \n",
    "    # Calculate mean absolute SHAP values per feature\n",
    "    shap_importance = pd.DataFrame({\n",
    "        'feature': X_sample.columns,\n",
    "        'mean_abs_shap': np.abs(shap_values).mean(axis=0)\n",
    "    }).sort_values('mean_abs_shap', ascending=False)\n",
    "    \n",
    "    print(f\"TreeSHAP computation completed!\")\n",
    "    \n",
    "    return shap_importance, shap_values, X_sample\n",
    "\n",
    "\n",
    "def compute_per_feature_auc(X_val, y_val):\n",
    "    \"\"\"\n",
    "    Train individual models on each feature and compute AUC.\n",
    "    \n",
    "    Returns:\n",
    "    - feature_auc_df: DataFrame with features and their individual AUC scores\n",
    "    \"\"\"\n",
    "    print(f\"\\nComputing per-feature AUC on {len(X_val):,} samples...\")\n",
    "    print(\"This may take several minutes...\")\n",
    "    \n",
    "    feature_aucs = []\n",
    "    \n",
    "    for i, feature in enumerate(X_val.columns, 1):\n",
    "        if i % 20 == 0:\n",
    "            print(f\"  Progress: {i}/{len(X_val.columns)} features processed\")\n",
    "        \n",
    "        # Get non-null values\n",
    "        mask = X_val[feature].notna()\n",
    "        \n",
    "        if mask.sum() < 100:  # Skip if too few samples\n",
    "            continue\n",
    "        \n",
    "        X_feature = X_val.loc[mask, feature].values.reshape(-1, 1)\n",
    "        y_feature = y_val.loc[mask]\n",
    "        \n",
    "        try:\n",
    "            # Train simple model on single feature\n",
    "            temp_model = lgb.LGBMClassifier(\n",
    "                n_estimators=100,\n",
    "                learning_rate=0.1,\n",
    "                num_leaves=7,\n",
    "                random_state=42,\n",
    "                verbose=-1\n",
    "            )\n",
    "            temp_model.fit(X_feature, y_feature)\n",
    "            y_pred_proba = temp_model.predict_proba(X_feature)[:, 1]\n",
    "            \n",
    "            auc = roc_auc_score(y_feature, y_pred_proba)\n",
    "            feature_aucs.append({'feature': feature, 'auc': auc})\n",
    "        except Exception as e:\n",
    "            print(f\"  Skipped {feature}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    # Sort by AUC\n",
    "    feature_auc_df = pd.DataFrame(feature_aucs).sort_values('auc', ascending=False)\n",
    "    \n",
    "    print(f\"\\nPer-feature AUC computation completed!\")\n",
    "    print(f\"  Features with AUC > 0.60: {(feature_auc_df['auc'] > 0.60).sum()}\")\n",
    "    print(f\"  Features with AUC > 0.65: {(feature_auc_df['auc'] > 0.65).sum()}\")\n",
    "    print(f\"  Features with AUC > 0.70: {(feature_auc_df['auc'] > 0.70).sum()}\")\n",
    "    \n",
    "    return feature_auc_df\n",
    "\n",
    "\n",
    "def display_feature_analysis(shap_importance, feature_auc_df, top_n=30):\n",
    "    \"\"\"\n",
    "    Display comprehensive feature importance analysis.\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*90)\n",
    "    print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "    print(\"=\"*90)\n",
    "    \n",
    "    print(f\"\\n1. TreeSHAP Importance (Top {top_n})\")\n",
    "    print(\"-\"*90)\n",
    "    print(shap_importance.head(top_n).to_string(index=False))\n",
    "    \n",
    "    print(f\"\\n\\n2. Per-Feature AUC (Top {top_n})\")\n",
    "    print(\"-\"*90)\n",
    "    print(feature_auc_df.head(top_n).to_string(index=False))\n",
    "    \n",
    "    # Merge for comparison\n",
    "    comparison = shap_importance.merge(feature_auc_df, on='feature', how='inner')\n",
    "    comparison['shap_rank'] = comparison['mean_abs_shap'].rank(ascending=False)\n",
    "    comparison['auc_rank'] = comparison['auc'].rank(ascending=False)\n",
    "    comparison['avg_rank'] = (comparison['shap_rank'] + comparison['auc_rank']) / 2\n",
    "    comparison = comparison.sort_values('avg_rank')\n",
    "    \n",
    "    print(f\"\\n\\n3. Combined Ranking (SHAP + AUC, Top {top_n})\")\n",
    "    print(\"-\"*90)\n",
    "    print(comparison[['feature', 'mean_abs_shap', 'shap_rank', 'auc', 'auc_rank', 'avg_rank']].head(top_n).to_string(index=False))\n",
    "    \n",
    "    return comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "koka49434cq",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EVALUATE MODEL\n",
    "# ============================================================================\n",
    "\n",
    "if 'lgb_model' in locals():\n",
    "    importance_df = show_feature_importance(lgb_model, top_n=20)\n",
    "    metrics = evaluate_model(lgb_model, X_val, y_val)\n",
    "else:\n",
    "    print(\"✗ Cannot evaluate - model not trained\")\n",
    "    print(\"  Run the model training cell above first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mbfbt33k8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEATURE IMPORTANCE ANALYSIS\n",
    "# ============================================================================\n",
    "\n",
    "if 'lgb_model' in locals() and 'X_val' in locals():\n",
    "    # Compute TreeSHAP importance\n",
    "    shap_importance, shap_values, X_sample = compute_shap_importance(lgb_model, X_val, sample_size=10000)\n",
    "    \n",
    "    # Compute per-feature AUC\n",
    "    feature_auc_df = compute_per_feature_auc(X_val, y_val)\n",
    "    \n",
    "    # Display comprehensive analysis\n",
    "    comparison_df = display_feature_analysis(shap_importance, feature_auc_df, top_n=30)\n",
    "else:\n",
    "    print(\"✗ Cannot analyze features - model or validation data not available\")\n",
    "    print(\"  Run the model training and evaluation cells above first\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
