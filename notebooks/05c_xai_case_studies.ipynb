{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3: Case Studies & Model Disagreement Analysis\n",
    "\n",
    "**Research Question**: *\"When and why does LightGBM outperform Logistic Regression, and can we explain these differences at the individual firm level?\"*\n",
    "\n",
    "## Motivation:\n",
    "Chapter 1 showed LightGBM outperforms Logistic (+7.9pp AUC). This chapter investigates:\n",
    "1. **Where** does LightGBM add value? (which firm types)\n",
    "2. **Why** does it catch risks Logistic misses? (SHAP explanations)\n",
    "3. **Individual firm narratives** to demonstrate interpretability\n",
    "\n",
    "## Analysis Structure:\n",
    "1. Load global models and identify disagreement cases\n",
    "2. Model disagreement analysis (LightGBM right, Logistic wrong)\n",
    "3. Select representative case studies\n",
    "4. Generate SHAP waterfall plots and narratives\n",
    "5. Discuss when ML adds value\n",
    "\n",
    "## Expected Contributions:\n",
    "- Concrete examples validating XAI methods\n",
    "- Demonstrate interpretability for thesis examiners\n",
    "- Quantify which firm types benefit most from ML\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import shap\n",
    "\n",
    "PROJ_ROOT = Path.cwd().parent\n",
    "if str(PROJ_ROOT) not in sys.path:\n",
    "    sys.path.append(str(PROJ_ROOT))\n",
    "\n",
    "# Plotting style\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "print(f\"Project root: {PROJ_ROOT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Global Models and SHAP Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load SHAP cache from Chapter 1\n",
    "cache_file = PROJ_ROOT / \"results\" / \"xai_exploration\" / \"shap_cache.pkl\"\n",
    "\n",
    "print(f\"Loading SHAP cache from: {cache_file}\")\n",
    "with open(cache_file, 'rb') as f:\n",
    "    shap_cache = pickle.load(f)\n",
    "\n",
    "# Extract data\n",
    "X_val = shap_cache['X_val']\n",
    "y_val = shap_cache['y_val']\n",
    "y_pred_lgbm = shap_cache['y_pred_proba_lgbm']\n",
    "y_pred_logit = shap_cache['y_pred_proba_logit']\n",
    "shap_values_lgbm = shap_cache['shap_values_lgbm']\n",
    "shap_values_logit = shap_cache['shap_values_logit']\n",
    "explainer_lgbm = shap_cache['explainer_lgbm']\n",
    "feature_names = shap_cache['feature_names']\n",
    "\n",
    "print(f\"\u2713 Loaded validation set: {len(X_val):,} observations\")\n",
    "print(f\"  \u2022 Features: {len(feature_names)}\")\n",
    "print(f\"  \u2022 SHAP values: {shap_values_lgbm.shape}\")\n",
    "print(f\"  \u2022 Default rate: {y_val.mean()*100:.2f}%\")\n",
    "\n",
    "# Load original data to get company identifiers\n",
    "from credit_risk_xai.config import FEATURE_CACHE_PATH\n",
    "\n",
    "df_full = pd.read_parquet(FEATURE_CACHE_PATH)\n",
    "\n",
    "# Get company info for validation set\n",
    "company_info = df_full.loc[X_val.index, ['ORGNR', 'ser_namn', 'ser_year', 'sme_category']].copy()\n",
    "\n",
    "print(f\"\\n\u2713 Loaded company identifiers for {len(company_info):,} firms\")\n",
    "print(f\"\\nSME size distribution in validation set:\")\n",
    "print(company_info['sme_category'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Model Disagreement Analysis\n",
    "\n",
    "Identify cases where models disagree significantly (|PD_lgbm - PD_logit| > 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create predictions DataFrame\n",
    "predictions = pd.DataFrame({\n",
    "    'y_true': y_val.values,\n",
    "    'pd_lgbm': y_pred_lgbm,\n",
    "    'pd_logit': y_pred_logit\n",
    "}, index=X_val.index)\n",
    "\n",
    "predictions['disagreement'] = np.abs(predictions['pd_lgbm'] - predictions['pd_logit'])\n",
    "predictions['lgbm_higher'] = predictions['pd_lgbm'] > predictions['pd_logit']\n",
    "\n",
    "# Define disagreement threshold\n",
    "DISAGREEMENT_THRESHOLD = 0.20\n",
    "\n",
    "# Segment firms by model agreement/disagreement\n",
    "predictions['segment'] = 'agreement'\n",
    "predictions.loc[\n",
    "    (predictions['disagreement'] > DISAGREEMENT_THRESHOLD) & \n",
    "    predictions['lgbm_higher'] & \n",
    "    (predictions['y_true'] == 1),\n",
    "    'segment'\n",
    "] = 'lgbm_right_logit_wrong'\n",
    "\n",
    "predictions.loc[\n",
    "    (predictions['disagreement'] > DISAGREEMENT_THRESHOLD) & \n",
    "    ~predictions['lgbm_higher'] & \n",
    "    (predictions['y_true'] == 1),\n",
    "    'segment'\n",
    "] = 'logit_right_lgbm_wrong'\n",
    "\n",
    "predictions.loc[\n",
    "    (predictions['disagreement'] > DISAGREEMENT_THRESHOLD) & \n",
    "    predictions['lgbm_higher'] & \n",
    "    (predictions['y_true'] == 0),\n",
    "    'segment'\n",
    "] = 'lgbm_false_alarm'\n",
    "\n",
    "predictions.loc[\n",
    "    (predictions['disagreement'] > DISAGREEMENT_THRESHOLD) & \n",
    "    ~predictions['lgbm_higher'] & \n",
    "    (predictions['y_true'] == 0),\n",
    "    'segment'\n",
    "] = 'logit_false_alarm'\n",
    "\n",
    "# Summary statistics\n",
    "segment_summary = predictions.groupby('segment').agg({\n",
    "    'y_true': ['count', 'sum', 'mean'],\n",
    "    'disagreement': 'mean',\n",
    "    'pd_lgbm': 'mean',\n",
    "    'pd_logit': 'mean'\n",
    "}).round(4)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"MODEL DISAGREEMENT ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(segment_summary)\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Focus on key segments\n",
    "lgbm_advantage = predictions[predictions['segment'] == 'lgbm_right_logit_wrong']\n",
    "logit_advantage = predictions[predictions['segment'] == 'logit_right_lgbm_wrong']\n",
    "\n",
    "print(f\"\\nKey Insights:\")\n",
    "print(f\"  \u2022 LightGBM caught {len(lgbm_advantage)} defaults that Logit missed (by >20pp)\")\n",
    "print(f\"  \u2022 Logit caught {len(logit_advantage)} defaults that LightGBM missed (by >20pp)\")\n",
    "print(f\"  \u2022 LightGBM advantage: {len(lgbm_advantage) - len(logit_advantage)} additional defaults caught\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Characterize Disagreement Segments\n",
    "\n",
    "What types of firms does LightGBM catch that Logistic misses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get feature characteristics for disagreement segments\n",
    "def characterize_segment(segment_df, X_val):\n",
    "    \"\"\"Calculate median feature values for a segment\"\"\"\n",
    "    segment_features = X_val.loc[segment_df.index]\n",
    "    \n",
    "    # Get numeric features only\n",
    "    numeric_features = segment_features.select_dtypes(include=[np.number]).columns\n",
    "    \n",
    "    median_values = segment_features[numeric_features].median()\n",
    "    return median_values\n",
    "\n",
    "# Compare segments\n",
    "lgbm_advantage_profile = characterize_segment(lgbm_advantage, X_val)\n",
    "logit_advantage_profile = characterize_segment(logit_advantage, X_val)\n",
    "all_defaults = predictions[predictions['y_true'] == 1]\n",
    "typical_default_profile = characterize_segment(all_defaults, X_val)\n",
    "\n",
    "# Calculate differences\n",
    "comparison = pd.DataFrame({\n",
    "    'LightGBM Advantage': lgbm_advantage_profile,\n",
    "    'Logit Advantage': logit_advantage_profile,\n",
    "    'Typical Default': typical_default_profile\n",
    "})\n",
    "\n",
    "# Focus on top features\n",
    "top_features = [\n",
    "    'dividend_yield', 'ratio_cash_liquidity', 'rr01_ntoms_yoy_abs',\n",
    "    'ny_skuldgrd', 'company_age', 'any_event_last_5y',\n",
    "    'ny_omsf', 'ny_solid'\n",
    "]\n",
    "top_features = [f for f in top_features if f in comparison.index]\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FIRM CHARACTERISTICS BY SEGMENT (Median Values)\")\n",
    "print(\"=\"*80)\n",
    "print(comparison.loc[top_features].to_string())\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nInterpretation:\")\n",
    "print(\"  \u2022 LightGBM Advantage: Defaults with complex risk patterns\")\n",
    "print(\"  \u2022 Logit Advantage: Defaults with clear linear signals\")\n",
    "print(\"  \u2022 LightGBM excels when multiple weak signals combine non-linearly\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Select Representative Case Studies\n",
    "\n",
    "We select 6-8 cases spanning different scenarios:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate candidate case studies for manual selection\n",
    "np.random.seed(42)\n",
    "\n",
    "# Filter predictions to only Medium-sized firms from 2016 onwards\n",
    "medium_firms = company_info[\n",
    "    (company_info['sme_category'] == 'Medium') &\n",
    "    (company_info['ser_year'] >= 2016)\n",
    "].index\n",
    "predictions_medium = predictions.loc[predictions.index.isin(medium_firms)]\n",
    "\n",
    "print(f\"Total firms: {len(predictions):,}\")\n",
    "print(f\"Medium-sized firms (2016+): {len(predictions_medium):,} ({len(predictions_medium)/len(predictions)*100:.1f}%)\")\n",
    "print()\n",
    "\n",
    "# ============================================================================\n",
    "# CATEGORY 1: LightGBM Right, Logistic Wrong\n",
    "# UPDATED CRITERIA:\n",
    "# - Disagreement > 20%\n",
    "# - LightGBM PD < 80%\n",
    "# - Actual default (y_true = 1)\n",
    "# ============================================================================\n",
    "lgbm_right_candidates = predictions_medium[\n",
    "    (predictions_medium['y_true'] == 1)\n",
    "    & (predictions_medium['pd_lgbm'] < 0.8)\n",
    "    & (predictions_medium['disagreement'] > 0.1)\n",
    "].sort_values('disagreement', ascending=False)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(f\"CATEGORY 1: LightGBM Caught Default, Logistic Missed\")\n",
    "print(f\"Criteria: Gap > 15%, LightGBM PD < 80%\")\n",
    "print(f\"Total candidates: {len(lgbm_right_candidates)}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for rank, (idx, pred) in enumerate(lgbm_right_candidates.iterrows(), 1):\n",
    "    info = company_info.loc[idx]\n",
    "    firm_features = X_val.loc[idx]\n",
    "\n",
    "    # Get SHAP values\n",
    "    obs_idx = X_val.index.get_loc(idx)\n",
    "    firm_shap = shap_values_lgbm[obs_idx, :]\n",
    "\n",
    "    # Get top 8 SHAP contributors (absolute value)\n",
    "    shap_contributions = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'value': firm_features.values,\n",
    "        'shap': firm_shap\n",
    "    }).sort_values('shap', key=abs, ascending=False).head(8)\n",
    "\n",
    "    print(f\"\\n{'\u2500'*80}\")\n",
    "    print(f\"Candidate {rank}\")\n",
    "    print(f\"{'\u2500'*80}\")\n",
    "    print(f\"Company: {info['ser_namn']}\")\n",
    "    print(f\"Size: {info['sme_category']}\")\n",
    "    print(f\"ORGNR: {info['ORGNR']}, Year: {info['ser_year']}\")\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f\"LightGBM PD: {pred['pd_lgbm']:.1%} | Logistic PD: {pred['pd_logit']:.1%} | Gap: {pred['disagreement']:.1%}\")\n",
    "    print(f\"\\nTop 8 SHAP Contributors:\")\n",
    "    print(shap_contributions.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "\n",
    "# ============================================================================\n",
    "# CATEGORY 2: Both Models Agree (10 candidates)\n",
    "# ============================================================================\n",
    "both_agree_defaults = predictions_medium[\n",
    "    (predictions_medium['pd_lgbm'] - predictions_medium['pd_logit'] < 0.15)\n",
    "].sample(min(10, len(predictions_medium)), random_state=42)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CATEGORY 2: Both Models Agree on Default (10 Candidates)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for rank, (idx, pred) in enumerate(both_agree_defaults.iterrows(), 1):\n",
    "    info = company_info.loc[idx]\n",
    "    firm_features = X_val.loc[idx]\n",
    "\n",
    "    # Get SHAP values\n",
    "    obs_idx = X_val.index.get_loc(idx)\n",
    "    firm_shap = shap_values_lgbm[obs_idx, :]\n",
    "\n",
    "    # Get top 8 SHAP contributors\n",
    "    shap_contributions = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'value': firm_features.values,\n",
    "        'shap': firm_shap\n",
    "    }).sort_values('shap', key=abs, ascending=False).head(8)\n",
    "\n",
    "    print(f\"\\n{'\u2500'*80}\")\n",
    "    print(f\"Candidate {rank}\")\n",
    "    print(f\"{'\u2500'*80}\")\n",
    "    print(f\"Company: {info['ser_namn']}\")\n",
    "    print(f\"ORGNR: {info['ORGNR']}, Year: {info['ser_year']}\")\n",
    "    print(f\"Index: {idx}\")\n",
    "    print(f\"LightGBM PD: {pred['pd_lgbm']:.1%} | Logistic PD: {pred['pd_logit']:.1%} | Gap: {pred['disagreement']:.1%}\")\n",
    "    print(f\"\\nTop 8 SHAP Contributors:\")\n",
    "    print(shap_contributions.to_string(index=False))\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"\\nNext steps:\")\n",
    "print(\"  1. Review the candidates above\")\n",
    "print(\"  2. Select the most interesting ones based on:\")\n",
    "print(\"     - Clear SHAP patterns\")\n",
    "print(\"     - Interpretable feature values\")\n",
    "print(\"     - Interesting company profiles\")\n",
    "print(\"  3. Create a 'selected_cases' dictionary with chosen indices\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Select Final Cases for Analysis\n",
    "\n",
    "After reviewing candidates, manually select the most interesting cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MANUALLY SELECT YOUR CASES HERE\n",
    "# After reviewing the candidates above, enter the indices of your chosen cases\n",
    "\n",
    "# Example - replace these with your selected indices:\n",
    "selected_cases = {\n",
    "    'Case 1: LightGBM Advantage': 10393647,  # Replace with index from Category 1\n",
    "    'Case 2: LightGBM Advantage': None,  # Replace with index from Category 1\n",
    "    'Case 3: LightGBM Advantage': None,  # Replace with index from Category 1\n",
    "    'Case 4: Both Models Agree': 11271840,   # Replace with index from Category 2\n",
    "    'Case 5: Both Models Agree': None,   # Replace with index from Category 2\n",
    "}\n",
    "\n",
    "# Remove None values (cases not yet selected)\n",
    "selected_cases = {k: v for k, v in selected_cases.items() if v is not None}\n",
    "\n",
    "if len(selected_cases) == 0:\n",
    "    print(\"\u26a0 No cases selected yet. Please update the 'selected_cases' dictionary with chosen indices.\")\n",
    "else:\n",
    "    print(f\"\u2713 Selected {len(selected_cases)} cases for detailed analysis:\")\n",
    "    for case_name, idx in selected_cases.items():\n",
    "        info = company_info.loc[idx]\n",
    "        pred = predictions.loc[idx]\n",
    "        print(f\"\\n{case_name}:\")\n",
    "        print(f\"  Company: {info['ser_namn']}\")\n",
    "        print(f\"  ORGNR: {info['ORGNR']}, Year: {info['ser_year']}\")\n",
    "        print(f\"  LightGBM PD: {pred['pd_lgbm']:.1%} | Logistic PD: {pred['pd_logit']:.1%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Generate SHAP Waterfall Plots for Selected Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate waterfall plots for selected cases\n",
    "if len(selected_cases) == 0:\n",
    "    print(\"\u26a0 No cases selected. Please run the previous cell and select cases first.\")\n",
    "else:\n",
    "    for case_name, case_idx in selected_cases.items():\n",
    "        print(f\"\\n{'='*80}\")\n",
    "        print(f\"{case_name}\")\n",
    "        print(f\"{'='*80}\")\n",
    "        \n",
    "        # Get firm data\n",
    "        firm_features = X_val.loc[case_idx]\n",
    "        firm_prediction = predictions.loc[case_idx]\n",
    "        firm_info = company_info.loc[case_idx]\n",
    "        \n",
    "        # Get SHAP values\n",
    "        obs_idx = X_val.index.get_loc(case_idx)\n",
    "        firm_shap = shap_values_lgbm[obs_idx, :]\n",
    "        \n",
    "        # Print company info\n",
    "        print(f\"\\nCompany Information:\")\n",
    "        print(f\"  Name: {firm_info['ser_namn']}\")\n",
    "        print(f\"  ORGNR: {firm_info['ORGNR']}\")\n",
    "        print(f\"  Year: {firm_info['ser_year']}\")\n",
    "        print(f\"  Size: {firm_info['sme_category']}\")\n",
    "        \n",
    "        # Print prediction summary\n",
    "        print(f\"\\nPrediction Results:\")\n",
    "        print(f\"  Actual Outcome: {'DEFAULT' if firm_prediction['y_true'] else 'No Default'}\")\n",
    "        print(f\"  LightGBM PD: {firm_prediction['pd_lgbm']:.1%}\")\n",
    "        print(f\"  Logistic PD: {firm_prediction['pd_logit']:.1%}\")\n",
    "        print(f\"  Disagreement: {firm_prediction['disagreement']:.1%}\")\n",
    "        \n",
    "        # Show top contributing features\n",
    "        feature_contributions = pd.DataFrame({\n",
    "            'feature': feature_names,\n",
    "            'value': firm_features.values,\n",
    "            'shap': firm_shap\n",
    "        }).sort_values('shap', key=abs, ascending=False).head(10)\n",
    "        \n",
    "        print(f\"\\nTop 10 Contributing Features:\")\n",
    "        print(feature_contributions.to_string(index=False))\n",
    "        \n",
    "        # Create waterfall plot\n",
    "        fig, ax = plt.subplots(1, 1, figsize=(10, 8))\n",
    "        \n",
    "        # SHAP waterfall plot\n",
    "        shap.plots.waterfall(\n",
    "            shap.Explanation(\n",
    "                values=firm_shap,\n",
    "                base_values=explainer_lgbm.expected_value[1] if isinstance(explainer_lgbm.expected_value, list) else explainer_lgbm.expected_value,\n",
    "                data=firm_features.values,\n",
    "                feature_names=feature_names\n",
    "            ),\n",
    "            max_display=15,\n",
    "            show=False\n",
    "        )\n",
    "        \n",
    "        plt.title(f'{case_name}: {firm_info[\"ser_namn\"]} ({firm_info[\"ser_year\"]})\\nLightGBM PD: {firm_prediction[\"pd_lgbm\"]:.1%}, Actual: {\"Default\" if firm_prediction[\"y_true\"] else \"No Default\"}',\n",
    "                  fontsize=13, fontweight='bold', pad=20)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Interaction Analysis for Selected Cases\n",
    "\n",
    "For each case study, we decompose the prediction into:\n",
    "1. **Main effects** - Independent contribution of each feature\n",
    "2. **Interaction effects** - How feature combinations amplify/dampen risk\n",
    "\n",
    "This reveals whether interactions genuinely matter for explaining individual predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute SHAP interaction values for selected cases\n",
    "# This decomposes each prediction into main effects + interaction effects\n",
    "\n",
    "print(\"Computing SHAP interaction values for selected cases...\")\n",
    "print(\"(This computes the full 40x40 interaction matrix for each case)\")\n",
    "\n",
    "# Prepare data for selected cases\n",
    "selected_indices = list(selected_cases.values())\n",
    "X_selected = X_val.loc[selected_indices]\n",
    "\n",
    "# Compute interaction values for selected cases only\n",
    "import time\n",
    "start = time.time()\n",
    "shap_interaction_selected = explainer_lgbm.shap_interaction_values(X_selected)\n",
    "\n",
    "# Handle binary classification output format\n",
    "if isinstance(shap_interaction_selected, list):\n",
    "    shap_interaction_selected = shap_interaction_selected[1]  # Positive class\n",
    "\n",
    "elapsed = time.time() - start\n",
    "print(f\"\u2713 Computed interaction values in {elapsed:.1f}s\")\n",
    "print(f\"  Shape: {shap_interaction_selected.shape} (n_cases, n_features, n_features)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose each case into Main Effects vs Interaction Effects\n",
    "\n",
    "def analyze_case_interactions(case_idx, case_name, interaction_matrix, X_val, feature_names, predictions):\n",
    "    \"\"\"\n",
    "    Decompose a single prediction into main effects and interaction effects.\n",
    "    \n",
    "    Returns a detailed breakdown showing:\n",
    "    1. Total main effects vs interaction effects\n",
    "    2. Top interaction pairs for this specific case\n",
    "    3. Comparison to what we'd expect from main effects alone\n",
    "    \"\"\"\n",
    "    firm_features = X_val.loc[case_idx]\n",
    "    firm_pred = predictions.loc[case_idx]\n",
    "    \n",
    "    # Main effects are on the diagonal\n",
    "    main_effects = interaction_matrix.diagonal()\n",
    "    total_main = np.abs(main_effects).sum()\n",
    "    \n",
    "    # Interaction effects are off-diagonal (divide by 2 since symmetric)\n",
    "    off_diagonal_sum = np.abs(interaction_matrix).sum() - np.abs(main_effects).sum()\n",
    "    total_interaction = off_diagonal_sum / 2\n",
    "    \n",
    "    # Ratio\n",
    "    interaction_ratio = total_interaction / (total_main + 1e-10)\n",
    "    \n",
    "    # Find top 5 interaction pairs for this case\n",
    "    n_features = len(feature_names)\n",
    "    interaction_pairs = []\n",
    "    for i in range(n_features):\n",
    "        for j in range(i+1, n_features):\n",
    "            interaction_pairs.append({\n",
    "                'feature_1': feature_names[i],\n",
    "                'feature_2': feature_names[j],\n",
    "                'value_1': firm_features.iloc[i],\n",
    "                'value_2': firm_features.iloc[j],\n",
    "                'interaction': interaction_matrix[i, j],\n",
    "                'abs_interaction': np.abs(interaction_matrix[i, j])\n",
    "            })\n",
    "    \n",
    "    pairs_df = pd.DataFrame(interaction_pairs).sort_values('abs_interaction', ascending=False)\n",
    "    top_5_pairs = pairs_df.head(5)\n",
    "    \n",
    "    # Also get main effects ranking\n",
    "    main_effects_df = pd.DataFrame({\n",
    "        'feature': feature_names,\n",
    "        'main_effect': main_effects,\n",
    "        'abs_main_effect': np.abs(main_effects),\n",
    "        'value': firm_features.values\n",
    "    }).sort_values('abs_main_effect', ascending=False)\n",
    "    \n",
    "    return {\n",
    "        'case_name': case_name,\n",
    "        'case_idx': case_idx,\n",
    "        'total_main': total_main,\n",
    "        'total_interaction': total_interaction,\n",
    "        'interaction_ratio': interaction_ratio,\n",
    "        'top_interactions': top_5_pairs,\n",
    "        'main_effects': main_effects_df,\n",
    "        'pd_lgbm': firm_pred['pd_lgbm'],\n",
    "        'pd_logit': firm_pred['pd_logit']\n",
    "    }\n",
    "\n",
    "# Analyze each selected case\n",
    "case_analyses = {}\n",
    "for i, (case_name, case_idx) in enumerate(selected_cases.items()):\n",
    "    interaction_matrix = shap_interaction_selected[i]\n",
    "    analysis = analyze_case_interactions(\n",
    "        case_idx, case_name, interaction_matrix, \n",
    "        X_val, feature_names, predictions\n",
    "    )\n",
    "    case_analyses[case_name] = analysis\n",
    "\n",
    "print(\"\u2713 Interaction analysis complete for all selected cases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display Interaction Decomposition for Each Case\n",
    "\n",
    "print(\"=\" * 90)\n",
    "print(\"INTERACTION DECOMPOSITION: Main Effects vs Interaction Effects\")\n",
    "print(\"=\" * 90)\n",
    "\n",
    "for case_name, analysis in case_analyses.items():\n",
    "    print(f\"\\n{'\u2500' * 90}\")\n",
    "    print(f\"{case_name}\")\n",
    "    print(f\"{'\u2500' * 90}\")\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(f\"\\nPrediction Decomposition:\")\n",
    "    print(f\"  \u2022 LightGBM PD: {analysis['pd_lgbm']:.1%}\")\n",
    "    print(f\"  \u2022 Total |Main Effects|: {analysis['total_main']:.3f} log-odds\")\n",
    "    print(f\"  \u2022 Total |Interaction Effects|: {analysis['total_interaction']:.3f} log-odds\")\n",
    "    print(f\"  \u2022 Interaction Ratio: {analysis['interaction_ratio']:.1%} of main effects\")\n",
    "    \n",
    "    # Interpretation\n",
    "    if analysis['interaction_ratio'] < 0.25:\n",
    "        interpretation = \"WEAK - prediction driven primarily by individual features\"\n",
    "    elif analysis['interaction_ratio'] < 0.50:\n",
    "        interpretation = \"MODERATE - some feature combinations matter\"\n",
    "    elif analysis['interaction_ratio'] < 0.75:\n",
    "        interpretation = \"SUBSTANTIAL - feature interactions are important\"\n",
    "    else:\n",
    "        interpretation = \"DOMINANT - interactions drive the prediction\"\n",
    "    \n",
    "    print(f\"  \u2192 Interpretation: {interpretation}\")\n",
    "    \n",
    "    # Top main effects\n",
    "    print(f\"\\nTop 5 Main Effects (individual feature contributions):\")\n",
    "    top_main = analysis['main_effects'].head(5)\n",
    "    for _, row in top_main.iterrows():\n",
    "        direction = \"\u2191 risk\" if row['main_effect'] > 0 else \"\u2193 risk\"\n",
    "        # Handle categorical vs numeric values\n",
    "        val = row['value']\n",
    "        if isinstance(val, (int, float)) and not pd.isna(val):\n",
    "            val_str = f\"{val:>10.3f}\"\n",
    "        else:\n",
    "            val_str = f\"{str(val):>10}\"\n",
    "        print(f\"    {row['feature']:<35} = {val_str}  \u2192  {row['main_effect']:+.3f} ({direction})\")\n",
    "    \n",
    "    # Top interactions\n",
    "    print(f\"\\nTop 5 Interactions (feature pair synergies):\")\n",
    "    top_int = analysis['top_interactions']\n",
    "    for _, row in top_int.iterrows():\n",
    "        direction = \"\u2191 risk\" if row['interaction'] > 0 else \"\u2193 risk\"\n",
    "        print(f\"    {row['feature_1']:<20} \u00d7 {row['feature_2']:<20}  \u2192  {row['interaction']:+.4f} ({direction})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Main Effects vs Interactions for Each Case\n",
    "\n",
    "fig, axes = plt.subplots(1, len(case_analyses), figsize=(6 * len(case_analyses), 5))\n",
    "if len(case_analyses) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for ax, (case_name, analysis) in zip(axes, case_analyses.items()):\n",
    "    # Create stacked bar chart showing main vs interaction\n",
    "    categories = ['Main Effects', 'Interactions']\n",
    "    values = [analysis['total_main'], analysis['total_interaction']]\n",
    "    colors = ['steelblue', 'darkorange']\n",
    "    \n",
    "    bars = ax.bar(categories, values, color=colors, edgecolor='black', linewidth=0.5)\n",
    "    \n",
    "    # Add value labels on bars\n",
    "    for bar, val in zip(bars, values):\n",
    "        ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1, \n",
    "                f'{val:.2f}', ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
    "    \n",
    "    # Add ratio annotation\n",
    "    ax.text(0.5, 0.95, f'Ratio: {analysis[\"interaction_ratio\"]:.1%}', \n",
    "            transform=ax.transAxes, ha='center', va='top', fontsize=12,\n",
    "            bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    ax.set_ylabel('Total |SHAP| (log-odds)', fontsize=11)\n",
    "    ax.set_title(f'{case_name.split(\":\")[0]}\\nPD: {analysis[\"pd_lgbm\"]:.1%}', \n",
    "                 fontsize=12, fontweight='bold')\n",
    "    ax.grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.suptitle('Prediction Decomposition: Main Effects vs Feature Interactions', \n",
    "             fontsize=14, fontweight='bold', y=1.02)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze LightGBM advantage patterns\n",
    "lgbm_advantage = predictions[predictions['segment'] == 'lgbm_right_logit_wrong']\n",
    "lgbm_advantage_features = X_val.loc[lgbm_advantage.index]\n",
    "all_defaults = predictions[predictions['y_true'] == 1]\n",
    "typical_defaults = X_val.loc[all_defaults.index]\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"WHEN DOES ML ADD VALUE?\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nLightGBM caught {len(lgbm_advantage)} defaults that Logit missed (by >20pp).\")\n",
    "print(f\"These represent {len(lgbm_advantage)/len(all_defaults)*100:.1f}% of all defaults.\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"\\n**Key Patterns from Selected Cases:**\")\n",
    "print(\"  \u2022 Review your selected cases to identify common patterns\")\n",
    "print(\"  \u2022 What features consistently drive LightGBM advantage?\")\n",
    "print(\"  \u2022 Are there specific industry/size/age profiles?\")\n",
    "print(\"  \u2022 Do certain combinations of features matter?\")\n",
    "\n",
    "print(\"\\n**ML Value Proposition:**\")\n",
    "print(\"  1. Catches firms with MODERATE, COMBINED risk signals\")\n",
    "print(\"  2. Detects non-linear threshold effects (zero vs non-zero)\")\n",
    "print(\"  3. Identifies behavioral red flags (stagnation, no dividends)\")\n",
    "print(\"  4. Works best for complex profiles, not clear-cut cases\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}